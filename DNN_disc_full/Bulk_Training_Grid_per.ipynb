{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perc98SubjectF1andFold1\n",
      "191434\n",
      "61461\n",
      "Train on 171044 samples, validate on 55415 samples\n",
      "Epoch 1/100\n",
      "171044/171044 [==============================] - 7s 40us/step - loss: 0.0559 - val_loss: 0.0501\n",
      "Epoch 2/100\n",
      "171044/171044 [==============================] - 6s 37us/step - loss: 0.0469 - val_loss: 0.0485\n",
      "Epoch 3/100\n",
      "171044/171044 [==============================] - 6s 38us/step - loss: 0.0445 - val_loss: 0.0472\n",
      "Epoch 4/100\n",
      "171044/171044 [==============================] - 6s 37us/step - loss: 0.0429 - val_loss: 0.0445\n",
      "Epoch 5/100\n",
      "171044/171044 [==============================] - 6s 38us/step - loss: 0.0416 - val_loss: 0.0436\n",
      "Epoch 6/100\n",
      "171044/171044 [==============================] - 6s 36us/step - loss: 0.0405 - val_loss: 0.0446\n",
      "Epoch 7/100\n",
      "171044/171044 [==============================] - 6s 37us/step - loss: 0.0395 - val_loss: 0.0419\n",
      "Epoch 8/100\n",
      "171044/171044 [==============================] - 6s 35us/step - loss: 0.0388 - val_loss: 0.0422\n",
      "Epoch 9/100\n",
      "171044/171044 [==============================] - 6s 37us/step - loss: 0.0382 - val_loss: 0.0414\n",
      "Epoch 10/100\n",
      "171044/171044 [==============================] - 6s 34us/step - loss: 0.0376 - val_loss: 0.0412\n",
      "Epoch 11/100\n",
      "171044/171044 [==============================] - 6s 36us/step - loss: 0.0370 - val_loss: 0.0405\n",
      "Epoch 12/100\n",
      "171044/171044 [==============================] - 6s 37us/step - loss: 0.0365 - val_loss: 0.0399\n",
      "Epoch 13/100\n",
      "171044/171044 [==============================] - 7s 38us/step - loss: 0.0359 - val_loss: 0.0392\n",
      "Epoch 14/100\n",
      "171044/171044 [==============================] - 7s 38us/step - loss: 0.0356 - val_loss: 0.0382\n",
      "Epoch 15/100\n",
      "171044/171044 [==============================] - 6s 37us/step - loss: 0.0353 - val_loss: 0.0386\n",
      "Epoch 16/100\n",
      "171044/171044 [==============================] - 6s 36us/step - loss: 0.0349 - val_loss: 0.0378\n",
      "Epoch 17/100\n",
      "171044/171044 [==============================] - 6s 37us/step - loss: 0.0346 - val_loss: 0.0388\n",
      "Epoch 18/100\n",
      "171044/171044 [==============================] - 6s 38us/step - loss: 0.0343 - val_loss: 0.0386\n",
      "Epoch 19/100\n",
      "171044/171044 [==============================] - 7s 38us/step - loss: 0.0341 - val_loss: 0.0371\n",
      "Epoch 20/100\n",
      "171044/171044 [==============================] - 7s 38us/step - loss: 0.0337 - val_loss: 0.0369\n",
      "Epoch 21/100\n",
      "171044/171044 [==============================] - 7s 39us/step - loss: 0.0336 - val_loss: 0.0382\n",
      "Epoch 22/100\n",
      "171044/171044 [==============================] - 6s 38us/step - loss: 0.0333 - val_loss: 0.0369\n",
      "Epoch 23/100\n",
      "171044/171044 [==============================] - 6s 38us/step - loss: 0.0332 - val_loss: 0.0363\n",
      "Epoch 24/100\n",
      "171044/171044 [==============================] - 7s 39us/step - loss: 0.0329 - val_loss: 0.0361\n",
      "Epoch 25/100\n",
      "171044/171044 [==============================] - 7s 41us/step - loss: 0.0329 - val_loss: 0.0363\n",
      "Epoch 26/100\n",
      "171044/171044 [==============================] - 7s 40us/step - loss: 0.0327 - val_loss: 0.0365\n",
      "Epoch 27/100\n",
      "171044/171044 [==============================] - 7s 41us/step - loss: 0.0325 - val_loss: 0.0363\n",
      "Epoch 28/100\n",
      "171044/171044 [==============================] - 7s 39us/step - loss: 0.0324 - val_loss: 0.0357\n",
      "Epoch 29/100\n",
      "171044/171044 [==============================] - 7s 40us/step - loss: 0.0322 - val_loss: 0.0356\n",
      "Epoch 30/100\n",
      "171044/171044 [==============================] - 7s 41us/step - loss: 0.0321 - val_loss: 0.0357\n",
      "Epoch 31/100\n",
      "171044/171044 [==============================] - 7s 41us/step - loss: 0.0318 - val_loss: 0.0356\n",
      "Epoch 32/100\n",
      "171044/171044 [==============================] - 7s 41us/step - loss: 0.0318 - val_loss: 0.0354\n",
      "Epoch 33/100\n",
      "171044/171044 [==============================] - 7s 41us/step - loss: 0.0317 - val_loss: 0.0354\n",
      "Epoch 34/100\n",
      "171044/171044 [==============================] - 7s 40us/step - loss: 0.0315 - val_loss: 0.0356\n",
      "Epoch 35/100\n",
      "171044/171044 [==============================] - 7s 38us/step - loss: 0.0314 - val_loss: 0.0348\n",
      "Epoch 36/100\n",
      "171044/171044 [==============================] - 6s 33us/step - loss: 0.0313 - val_loss: 0.0347\n",
      "Epoch 37/100\n",
      "171044/171044 [==============================] - 5s 32us/step - loss: 0.0313 - val_loss: 0.0348\n",
      "Epoch 38/100\n",
      "171044/171044 [==============================] - 6s 35us/step - loss: 0.0313 - val_loss: 0.0352\n",
      "Epoch 39/100\n",
      "171044/171044 [==============================] - 6s 37us/step - loss: 0.0312 - val_loss: 0.0346\n",
      "Epoch 40/100\n",
      "171044/171044 [==============================] - 6s 38us/step - loss: 0.0310 - val_loss: 0.0346\n",
      "Epoch 41/100\n",
      "171044/171044 [==============================] - 7s 41us/step - loss: 0.0308 - val_loss: 0.0344\n",
      "Epoch 42/100\n",
      "171044/171044 [==============================] - 7s 43us/step - loss: 0.0308 - val_loss: 0.0352\n",
      "Epoch 43/100\n",
      "171044/171044 [==============================] - 7s 41us/step - loss: 0.0308 - val_loss: 0.0338\n",
      "Epoch 44/100\n",
      "171044/171044 [==============================] - 8s 45us/step - loss: 0.0307 - val_loss: 0.0348\n",
      "Epoch 45/100\n",
      "171044/171044 [==============================] - 7s 42us/step - loss: 0.0305 - val_loss: 0.0347\n",
      "Epoch 46/100\n",
      "171044/171044 [==============================] - 7s 43us/step - loss: 0.0305 - val_loss: 0.0344\n",
      "Epoch 47/100\n",
      "171044/171044 [==============================] - 8s 44us/step - loss: 0.0305 - val_loss: 0.0343\n",
      "perc98SubjectF1andFold2\n",
      "241790\n",
      "80123\n",
      "Train on 88237 samples, validate on 27993 samples\n",
      "Epoch 1/100\n",
      "88237/88237 [==============================] - 6s 65us/step - loss: 0.0668 - val_loss: 0.0539\n",
      "Epoch 2/100\n",
      "88237/88237 [==============================] - 5s 56us/step - loss: 0.0504 - val_loss: 0.0470\n",
      "Epoch 3/100\n",
      "88237/88237 [==============================] - 5s 57us/step - loss: 0.0443 - val_loss: 0.0433\n",
      "Epoch 4/100\n",
      "88237/88237 [==============================] - 5s 56us/step - loss: 0.0402 - val_loss: 0.0412\n",
      "Epoch 5/100\n",
      "88237/88237 [==============================] - 5s 55us/step - loss: 0.0374 - val_loss: 0.0427\n",
      "Epoch 6/100\n",
      "88237/88237 [==============================] - 5s 55us/step - loss: 0.0354 - val_loss: 0.0381\n",
      "Epoch 7/100\n",
      "88237/88237 [==============================] - 5s 56us/step - loss: 0.0342 - val_loss: 0.0361\n",
      "Epoch 8/100\n",
      "88237/88237 [==============================] - 5s 57us/step - loss: 0.0332 - val_loss: 0.0370\n",
      "Epoch 9/100\n",
      "88237/88237 [==============================] - 5s 61us/step - loss: 0.0325 - val_loss: 0.0376\n",
      "Epoch 10/100\n",
      "88237/88237 [==============================] - 5s 60us/step - loss: 0.0314 - val_loss: 0.0346\n",
      "Epoch 11/100\n",
      "88237/88237 [==============================] - 5s 56us/step - loss: 0.0307 - val_loss: 0.0362\n",
      "Epoch 12/100\n",
      "88237/88237 [==============================] - 5s 56us/step - loss: 0.0300 - val_loss: 0.0349\n",
      "Epoch 13/100\n",
      "88237/88237 [==============================] - 5s 57us/step - loss: 0.0293 - val_loss: 0.0330\n",
      "Epoch 14/100\n",
      "88237/88237 [==============================] - 5s 56us/step - loss: 0.0290 - val_loss: 0.0330\n",
      "Epoch 15/100\n",
      "88237/88237 [==============================] - 5s 55us/step - loss: 0.0283 - val_loss: 0.0323\n",
      "Epoch 16/100\n",
      "88237/88237 [==============================] - 5s 56us/step - loss: 0.0280 - val_loss: 0.0327\n",
      "Epoch 17/100\n",
      "88237/88237 [==============================] - 5s 55us/step - loss: 0.0275 - val_loss: 0.0315\n",
      "Epoch 18/100\n",
      "88237/88237 [==============================] - 5s 55us/step - loss: 0.0270 - val_loss: 0.0328\n",
      "Epoch 19/100\n",
      "88237/88237 [==============================] - 5s 62us/step - loss: 0.0267 - val_loss: 0.0313\n",
      "Epoch 20/100\n",
      "88237/88237 [==============================] - 6s 63us/step - loss: 0.0263 - val_loss: 0.0301\n",
      "Epoch 21/100\n",
      "88237/88237 [==============================] - 6s 64us/step - loss: 0.0260 - val_loss: 0.0300\n",
      "Epoch 22/100\n",
      "88237/88237 [==============================] - 6s 66us/step - loss: 0.0259 - val_loss: 0.0304\n",
      "Epoch 23/100\n",
      "88237/88237 [==============================] - 6s 64us/step - loss: 0.0255 - val_loss: 0.0295\n",
      "Epoch 24/100\n",
      "88237/88237 [==============================] - 6s 66us/step - loss: 0.0252 - val_loss: 0.0303\n",
      "Epoch 25/100\n",
      "88237/88237 [==============================] - 5s 62us/step - loss: 0.0249 - val_loss: 0.0299\n",
      "Epoch 26/100\n",
      "88237/88237 [==============================] - 6s 63us/step - loss: 0.0246 - val_loss: 0.0295\n",
      "Epoch 27/100\n",
      "88237/88237 [==============================] - 5s 61us/step - loss: 0.0243 - val_loss: 0.0282\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88237/88237 [==============================] - 5s 62us/step - loss: 0.0240 - val_loss: 0.0291\n",
      "Epoch 29/100\n",
      "88237/88237 [==============================] - 6s 62us/step - loss: 0.0239 - val_loss: 0.0281\n",
      "Epoch 30/100\n",
      "88237/88237 [==============================] - 6s 70us/step - loss: 0.0238 - val_loss: 0.0296\n",
      "Epoch 31/100\n",
      "88237/88237 [==============================] - 7s 75us/step - loss: 0.0236 - val_loss: 0.0286\n",
      "Epoch 32/100\n",
      "88237/88237 [==============================] - 6s 70us/step - loss: 0.0234 - val_loss: 0.0279\n",
      "Epoch 33/100\n",
      "88237/88237 [==============================] - 6s 68us/step - loss: 0.0231 - val_loss: 0.0279\n",
      "Epoch 34/100\n",
      "88237/88237 [==============================] - 6s 70us/step - loss: 0.0228 - val_loss: 0.0299\n",
      "Epoch 35/100\n",
      "88237/88237 [==============================] - 7s 76us/step - loss: 0.0229 - val_loss: 0.0278\n",
      "Epoch 36/100\n",
      "88237/88237 [==============================] - 6s 73us/step - loss: 0.0227 - val_loss: 0.0278\n",
      "Epoch 37/100\n",
      "88237/88237 [==============================] - 6s 70us/step - loss: 0.0225 - val_loss: 0.0292\n",
      "Epoch 38/100\n",
      "88237/88237 [==============================] - 6s 68us/step - loss: 0.0224 - val_loss: 0.0275\n",
      "Epoch 39/100\n",
      "88237/88237 [==============================] - 6s 67us/step - loss: 0.0222 - val_loss: 0.0284\n",
      "Epoch 40/100\n",
      "88237/88237 [==============================] - 6s 70us/step - loss: 0.0220 - val_loss: 0.0282\n",
      "Epoch 41/100\n",
      "88237/88237 [==============================] - 7s 77us/step - loss: 0.0220 - val_loss: 0.0276\n",
      "Epoch 42/100\n",
      "88237/88237 [==============================] - 6s 70us/step - loss: 0.0219 - val_loss: 0.0269\n",
      "Epoch 43/100\n",
      "88237/88237 [==============================] - 6s 67us/step - loss: 0.0217 - val_loss: 0.0264\n",
      "Epoch 44/100\n",
      "88237/88237 [==============================] - 6s 68us/step - loss: 0.0216 - val_loss: 0.0272\n",
      "Epoch 45/100\n",
      "88237/88237 [==============================] - 6s 67us/step - loss: 0.0217 - val_loss: 0.0273\n",
      "Epoch 46/100\n",
      "88237/88237 [==============================] - 6s 67us/step - loss: 0.0214 - val_loss: 0.0268\n",
      "Epoch 47/100\n",
      "88237/88237 [==============================] - 6s 69us/step - loss: 0.0214 - val_loss: 0.0269\n",
      "perc98SubjectF1andFold3\n",
      "187307\n",
      "61454\n",
      "Train on 167061 samples, validate on 54733 samples\n",
      "Epoch 1/100\n",
      "167061/167061 [==============================] - 11s 69us/step - loss: 0.0569 - val_loss: 0.0462\n",
      "Epoch 2/100\n",
      "167061/167061 [==============================] - 11s 65us/step - loss: 0.0473 - val_loss: 0.0443\n",
      "Epoch 3/100\n",
      "167061/167061 [==============================] - 11s 64us/step - loss: 0.0451 - val_loss: 0.0424\n",
      "Epoch 4/100\n",
      "167061/167061 [==============================] - 11s 64us/step - loss: 0.0435 - val_loss: 0.0423\n",
      "Epoch 5/100\n",
      "167061/167061 [==============================] - 10s 62us/step - loss: 0.0425 - val_loss: 0.0401\n",
      "Epoch 6/100\n",
      "167061/167061 [==============================] - 10s 62us/step - loss: 0.0413 - val_loss: 0.0412\n",
      "Epoch 7/100\n",
      "167061/167061 [==============================] - 10s 60us/step - loss: 0.0405 - val_loss: 0.0404\n",
      "Epoch 8/100\n",
      "167061/167061 [==============================] - 9s 53us/step - loss: 0.0398 - val_loss: 0.0387\n",
      "Epoch 9/100\n",
      "167061/167061 [==============================] - 9s 55us/step - loss: 0.0390 - val_loss: 0.0373\n",
      "Epoch 10/100\n",
      "167061/167061 [==============================] - 8s 47us/step - loss: 0.0384 - val_loss: 0.0382\n",
      "Epoch 11/100\n",
      "167061/167061 [==============================] - 8s 48us/step - loss: 0.0378 - val_loss: 0.0367\n",
      "Epoch 12/100\n",
      "167061/167061 [==============================] - 8s 49us/step - loss: 0.0373 - val_loss: 0.0360\n",
      "Epoch 13/100\n",
      "167061/167061 [==============================] - 8s 50us/step - loss: 0.0370 - val_loss: 0.0383\n",
      "Epoch 14/100\n",
      "167061/167061 [==============================] - 9s 54us/step - loss: 0.0364 - val_loss: 0.0357\n",
      "Epoch 15/100\n",
      "167061/167061 [==============================] - 8s 49us/step - loss: 0.0363 - val_loss: 0.0359\n",
      "Epoch 16/100\n",
      "167061/167061 [==============================] - 8s 49us/step - loss: 0.0359 - val_loss: 0.0342\n",
      "Epoch 17/100\n",
      "167061/167061 [==============================] - 9s 51us/step - loss: 0.0356 - val_loss: 0.0348\n",
      "Epoch 18/100\n",
      "167061/167061 [==============================] - 8s 49us/step - loss: 0.0353 - val_loss: 0.0365\n",
      "Epoch 19/100\n",
      "167061/167061 [==============================] - 9s 51us/step - loss: 0.0352 - val_loss: 0.0340\n",
      "Epoch 20/100\n",
      "167061/167061 [==============================] - 9s 53us/step - loss: 0.0348 - val_loss: 0.0351\n",
      "Epoch 21/100\n",
      "167061/167061 [==============================] - 9s 55us/step - loss: 0.0344 - val_loss: 0.0354\n",
      "Epoch 22/100\n",
      "167061/167061 [==============================] - 9s 52us/step - loss: 0.0344 - val_loss: 0.0336\n",
      "Epoch 23/100\n",
      "167061/167061 [==============================] - 9s 54us/step - loss: 0.0341 - val_loss: 0.0337\n",
      "Epoch 24/100\n",
      "167061/167061 [==============================] - 9s 51us/step - loss: 0.0342 - val_loss: 0.0326\n",
      "Epoch 25/100\n",
      "167061/167061 [==============================] - 9s 53us/step - loss: 0.0339 - val_loss: 0.0327\n",
      "Epoch 26/100\n",
      "167061/167061 [==============================] - 9s 53us/step - loss: 0.0337 - val_loss: 0.0328\n",
      "Epoch 27/100\n",
      "167061/167061 [==============================] - 9s 53us/step - loss: 0.0336 - val_loss: 0.0338\n",
      "Epoch 28/100\n",
      "167061/167061 [==============================] - 9s 53us/step - loss: 0.0334 - val_loss: 0.0334\n",
      "perc98SubjectF1andFold4\n",
      "158425\n",
      "53227\n",
      "Train on 78930 samples, validate on 26070 samples\n",
      "Epoch 1/100\n",
      "78930/78930 [==============================] - 5s 64us/step - loss: 0.0652 - val_loss: 0.0515\n",
      "Epoch 2/100\n",
      "78930/78930 [==============================] - 4s 55us/step - loss: 0.0485 - val_loss: 0.0492\n",
      "Epoch 3/100\n",
      "78930/78930 [==============================] - 4s 51us/step - loss: 0.0453 - val_loss: 0.0449\n",
      "Epoch 4/100\n",
      "78930/78930 [==============================] - 4s 54us/step - loss: 0.0422 - val_loss: 0.0440\n",
      "Epoch 5/100\n",
      "78930/78930 [==============================] - 4s 53us/step - loss: 0.0401 - val_loss: 0.0420\n",
      "Epoch 6/100\n",
      "78930/78930 [==============================] - 4s 55us/step - loss: 0.0386 - val_loss: 0.0401\n",
      "Epoch 7/100\n",
      "78930/78930 [==============================] - 4s 51us/step - loss: 0.0372 - val_loss: 0.0390\n",
      "Epoch 8/100\n",
      "78930/78930 [==============================] - 4s 51us/step - loss: 0.0364 - val_loss: 0.0396\n",
      "Epoch 9/100\n",
      "78930/78930 [==============================] - 4s 50us/step - loss: 0.0356 - val_loss: 0.0383\n",
      "Epoch 10/100\n",
      "78930/78930 [==============================] - 4s 51us/step - loss: 0.0349 - val_loss: 0.0386\n",
      "Epoch 11/100\n",
      "78930/78930 [==============================] - 4s 50us/step - loss: 0.0343 - val_loss: 0.0380\n",
      "Epoch 12/100\n",
      "78930/78930 [==============================] - 4s 54us/step - loss: 0.0338 - val_loss: 0.0375\n",
      "Epoch 13/100\n",
      "78930/78930 [==============================] - 4s 48us/step - loss: 0.0333 - val_loss: 0.0361\n",
      "Epoch 14/100\n",
      "78930/78930 [==============================] - 4s 57us/step - loss: 0.0328 - val_loss: 0.0360\n",
      "Epoch 15/100\n",
      "78930/78930 [==============================] - 4s 54us/step - loss: 0.0325 - val_loss: 0.0358\n",
      "Epoch 16/100\n",
      "78930/78930 [==============================] - 4s 49us/step - loss: 0.0320 - val_loss: 0.0349\n",
      "Epoch 17/100\n",
      "78930/78930 [==============================] - 4s 49us/step - loss: 0.0317 - val_loss: 0.0352\n",
      "Epoch 18/100\n",
      "78930/78930 [==============================] - 4s 50us/step - loss: 0.0314 - val_loss: 0.0364\n",
      "Epoch 19/100\n",
      "78930/78930 [==============================] - 4s 50us/step - loss: 0.0311 - val_loss: 0.0361\n",
      "Epoch 20/100\n",
      "78930/78930 [==============================] - 4s 51us/step - loss: 0.0308 - val_loss: 0.0346\n",
      "Epoch 21/100\n",
      "78930/78930 [==============================] - 4s 50us/step - loss: 0.0306 - val_loss: 0.0342\n",
      "Epoch 22/100\n",
      "78930/78930 [==============================] - 4s 50us/step - loss: 0.0306 - val_loss: 0.0339\n",
      "Epoch 23/100\n",
      "78930/78930 [==============================] - 4s 50us/step - loss: 0.0301 - val_loss: 0.0333\n",
      "Epoch 24/100\n",
      "78930/78930 [==============================] - 4s 50us/step - loss: 0.0299 - val_loss: 0.0332\n",
      "Epoch 25/100\n",
      "78930/78930 [==============================] - 4s 52us/step - loss: 0.0299 - val_loss: 0.0345\n",
      "Epoch 26/100\n",
      "78930/78930 [==============================] - 4s 49us/step - loss: 0.0296 - val_loss: 0.0331\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78930/78930 [==============================] - 4s 51us/step - loss: 0.0293 - val_loss: 0.0324\n",
      "Epoch 28/100\n",
      "78930/78930 [==============================] - 4s 50us/step - loss: 0.0292 - val_loss: 0.0329\n",
      "Epoch 29/100\n",
      "78930/78930 [==============================] - 4s 51us/step - loss: 0.0290 - val_loss: 0.0321\n",
      "Epoch 30/100\n",
      "78930/78930 [==============================] - 4s 49us/step - loss: 0.0290 - val_loss: 0.0336\n",
      "Epoch 31/100\n",
      "78930/78930 [==============================] - 4s 50us/step - loss: 0.0286 - val_loss: 0.0322\n",
      "Epoch 32/100\n",
      "78930/78930 [==============================] - 4s 48us/step - loss: 0.0288 - val_loss: 0.0334\n",
      "Epoch 33/100\n",
      "78930/78930 [==============================] - 4s 49us/step - loss: 0.0285 - val_loss: 0.0326\n",
      "perc98SubjectF2andFold1\n",
      "196543\n",
      "63204\n",
      "Train on 120867 samples, validate on 39082 samples\n",
      "Epoch 1/100\n",
      "120867/120867 [==============================] - 8s 65us/step - loss: 0.0548 - val_loss: 0.0433\n",
      "Epoch 2/100\n",
      "120867/120867 [==============================] - 7s 59us/step - loss: 0.0436 - val_loss: 0.0430\n",
      "Epoch 3/100\n",
      "120867/120867 [==============================] - 7s 60us/step - loss: 0.0420 - val_loss: 0.0416\n",
      "Epoch 4/100\n",
      "120867/120867 [==============================] - 7s 59us/step - loss: 0.0412 - val_loss: 0.0405\n",
      "Epoch 5/100\n",
      "120867/120867 [==============================] - 7s 60us/step - loss: 0.0405 - val_loss: 0.0399\n",
      "Epoch 6/100\n",
      "120867/120867 [==============================] - 7s 60us/step - loss: 0.0399 - val_loss: 0.0390\n",
      "Epoch 7/100\n",
      "120867/120867 [==============================] - 7s 58us/step - loss: 0.0393 - val_loss: 0.0394\n",
      "Epoch 8/100\n",
      "120867/120867 [==============================] - 7s 60us/step - loss: 0.0389 - val_loss: 0.0393\n",
      "Epoch 9/100\n",
      "120867/120867 [==============================] - 7s 58us/step - loss: 0.0386 - val_loss: 0.0391\n",
      "Epoch 10/100\n",
      "120867/120867 [==============================] - 7s 60us/step - loss: 0.0381 - val_loss: 0.0377\n",
      "Epoch 11/100\n",
      "120867/120867 [==============================] - 7s 57us/step - loss: 0.0378 - val_loss: 0.0378\n",
      "Epoch 12/100\n",
      "120867/120867 [==============================] - 7s 58us/step - loss: 0.0374 - val_loss: 0.0369\n",
      "Epoch 13/100\n",
      "120867/120867 [==============================] - 7s 59us/step - loss: 0.0371 - val_loss: 0.0368\n",
      "Epoch 14/100\n",
      "120867/120867 [==============================] - 7s 57us/step - loss: 0.0368 - val_loss: 0.0368\n",
      "Epoch 15/100\n",
      "120867/120867 [==============================] - 7s 56us/step - loss: 0.0363 - val_loss: 0.0364\n",
      "Epoch 16/100\n",
      "120867/120867 [==============================] - 7s 58us/step - loss: 0.0360 - val_loss: 0.0358\n",
      "Epoch 17/100\n",
      "120867/120867 [==============================] - 7s 60us/step - loss: 0.0358 - val_loss: 0.0359\n",
      "Epoch 18/100\n",
      "120867/120867 [==============================] - 7s 59us/step - loss: 0.0354 - val_loss: 0.0360\n",
      "Epoch 19/100\n",
      "120867/120867 [==============================] - 7s 61us/step - loss: 0.0352 - val_loss: 0.0355\n",
      "Epoch 20/100\n",
      "120867/120867 [==============================] - 9s 72us/step - loss: 0.0350 - val_loss: 0.0350\n",
      "Epoch 21/100\n",
      "120867/120867 [==============================] - 9s 71us/step - loss: 0.0349 - val_loss: 0.0350\n",
      "Epoch 22/100\n",
      "120867/120867 [==============================] - 9s 70us/step - loss: 0.0348 - val_loss: 0.0349\n",
      "Epoch 23/100\n",
      "120867/120867 [==============================] - 9s 71us/step - loss: 0.0345 - val_loss: 0.0350\n",
      "Epoch 24/100\n",
      "120867/120867 [==============================] - 8s 70us/step - loss: 0.0342 - val_loss: 0.0345\n",
      "Epoch 25/100\n",
      "120867/120867 [==============================] - 8s 69us/step - loss: 0.0341 - val_loss: 0.0345\n",
      "Epoch 26/100\n",
      "120867/120867 [==============================] - 8s 69us/step - loss: 0.0340 - val_loss: 0.0344\n",
      "Epoch 27/100\n",
      "120867/120867 [==============================] - 9s 72us/step - loss: 0.0338 - val_loss: 0.0342\n",
      "Epoch 28/100\n",
      "120867/120867 [==============================] - 9s 70us/step - loss: 0.0336 - val_loss: 0.0346\n",
      "Epoch 29/100\n",
      "120867/120867 [==============================] - 8s 70us/step - loss: 0.0336 - val_loss: 0.0342\n",
      "Epoch 30/100\n",
      "120867/120867 [==============================] - 9s 70us/step - loss: 0.0335 - val_loss: 0.0339\n",
      "Epoch 31/100\n",
      "120867/120867 [==============================] - 9s 71us/step - loss: 0.0334 - val_loss: 0.0349\n",
      "Epoch 32/100\n",
      "120867/120867 [==============================] - 9s 71us/step - loss: 0.0332 - val_loss: 0.0341\n",
      "Epoch 33/100\n",
      "120867/120867 [==============================] - 9s 71us/step - loss: 0.0332 - val_loss: 0.0338\n",
      "Epoch 34/100\n",
      "120867/120867 [==============================] - 9s 71us/step - loss: 0.0331 - val_loss: 0.0339\n",
      "Epoch 35/100\n",
      "120867/120867 [==============================] - 8s 69us/step - loss: 0.0329 - val_loss: 0.0334\n",
      "Epoch 36/100\n",
      "120867/120867 [==============================] - 9s 71us/step - loss: 0.0328 - val_loss: 0.0338\n",
      "Epoch 37/100\n",
      "120867/120867 [==============================] - 8s 70us/step - loss: 0.0327 - val_loss: 0.0333\n",
      "Epoch 38/100\n",
      "120867/120867 [==============================] - 9s 71us/step - loss: 0.0327 - val_loss: 0.0334\n",
      "Epoch 39/100\n",
      "120867/120867 [==============================] - 9s 71us/step - loss: 0.0325 - val_loss: 0.0334\n",
      "Epoch 40/100\n",
      "120867/120867 [==============================] - 9s 71us/step - loss: 0.0325 - val_loss: 0.0332\n",
      "Epoch 41/100\n",
      "120867/120867 [==============================] - 8s 70us/step - loss: 0.0324 - val_loss: 0.0335\n",
      "Epoch 42/100\n",
      "120867/120867 [==============================] - 8s 70us/step - loss: 0.0323 - val_loss: 0.0331\n",
      "Epoch 43/100\n",
      "120867/120867 [==============================] - 9s 72us/step - loss: 0.0323 - val_loss: 0.0330\n",
      "Epoch 44/100\n",
      "120867/120867 [==============================] - 8s 70us/step - loss: 0.0321 - val_loss: 0.0330\n",
      "Epoch 45/100\n",
      "120867/120867 [==============================] - 9s 75us/step - loss: 0.0321 - val_loss: 0.0331\n",
      "Epoch 46/100\n",
      "120867/120867 [==============================] - 8s 70us/step - loss: 0.0319 - val_loss: 0.0332\n",
      "Epoch 47/100\n",
      "120867/120867 [==============================] - 9s 72us/step - loss: 0.0320 - val_loss: 0.0331\n",
      "perc98SubjectF2andFold2\n",
      "231198\n",
      "78804\n",
      "Train on 140117 samples, validate on 48442 samples\n",
      "Epoch 1/100\n",
      "140117/140117 [==============================] - 12s 88us/step - loss: 0.0509 - val_loss: 0.0408\n",
      "Epoch 2/100\n",
      "140117/140117 [==============================] - 11s 79us/step - loss: 0.0409 - val_loss: 0.0376\n",
      "Epoch 3/100\n",
      "140117/140117 [==============================] - 11s 79us/step - loss: 0.0396 - val_loss: 0.0367\n",
      "Epoch 4/100\n",
      "140117/140117 [==============================] - 11s 79us/step - loss: 0.0387 - val_loss: 0.0367\n",
      "Epoch 5/100\n",
      "140117/140117 [==============================] - 11s 78us/step - loss: 0.0381 - val_loss: 0.0378\n",
      "Epoch 6/100\n",
      "140117/140117 [==============================] - 11s 78us/step - loss: 0.0375 - val_loss: 0.0352\n",
      "Epoch 7/100\n",
      "140117/140117 [==============================] - 11s 79us/step - loss: 0.0371 - val_loss: 0.0349\n",
      "Epoch 8/100\n",
      "140117/140117 [==============================] - 11s 79us/step - loss: 0.0364 - val_loss: 0.0347\n",
      "Epoch 9/100\n",
      "140117/140117 [==============================] - 11s 80us/step - loss: 0.0359 - val_loss: 0.0345\n",
      "Epoch 10/100\n",
      "140117/140117 [==============================] - 11s 81us/step - loss: 0.0353 - val_loss: 0.0334\n",
      "Epoch 11/100\n",
      "140117/140117 [==============================] - 11s 79us/step - loss: 0.0348 - val_loss: 0.0326\n",
      "Epoch 12/100\n",
      "140117/140117 [==============================] - 11s 82us/step - loss: 0.0343 - val_loss: 0.0326\n",
      "Epoch 13/100\n",
      "140117/140117 [==============================] - 11s 80us/step - loss: 0.0339 - val_loss: 0.0321\n",
      "Epoch 14/100\n",
      "140117/140117 [==============================] - 11s 80us/step - loss: 0.0335 - val_loss: 0.0319\n",
      "Epoch 15/100\n",
      "140117/140117 [==============================] - 11s 81us/step - loss: 0.0331 - val_loss: 0.0317\n",
      "Epoch 16/100\n",
      "140117/140117 [==============================] - 11s 80us/step - loss: 0.0329 - val_loss: 0.0319\n",
      "Epoch 17/100\n",
      "140117/140117 [==============================] - 11s 80us/step - loss: 0.0325 - val_loss: 0.0313\n",
      "Epoch 18/100\n",
      "140117/140117 [==============================] - 11s 80us/step - loss: 0.0323 - val_loss: 0.0312\n",
      "Epoch 19/100\n",
      "140117/140117 [==============================] - 12s 84us/step - loss: 0.0319 - val_loss: 0.0312\n",
      "Epoch 20/100\n",
      "140117/140117 [==============================] - 12s 83us/step - loss: 0.0318 - val_loss: 0.0304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "140117/140117 [==============================] - 12s 85us/step - loss: 0.0315 - val_loss: 0.0311\n",
      "Epoch 22/100\n",
      "140117/140117 [==============================] - 12s 84us/step - loss: 0.0314 - val_loss: 0.0298\n",
      "Epoch 23/100\n",
      "140117/140117 [==============================] - 12s 83us/step - loss: 0.0311 - val_loss: 0.0304\n",
      "Epoch 24/100\n",
      "140117/140117 [==============================] - 12s 82us/step - loss: 0.0309 - val_loss: 0.0297\n",
      "Epoch 25/100\n",
      "140117/140117 [==============================] - 12s 83us/step - loss: 0.0307 - val_loss: 0.0300\n",
      "Epoch 26/100\n",
      "140117/140117 [==============================] - 12s 83us/step - loss: 0.0305 - val_loss: 0.0301\n",
      "Epoch 27/100\n",
      "140117/140117 [==============================] - 12s 83us/step - loss: 0.0304 - val_loss: 0.0299\n",
      "Epoch 28/100\n",
      "140117/140117 [==============================] - 12s 83us/step - loss: 0.0302 - val_loss: 0.0302\n",
      "perc98SubjectF2andFold3\n",
      "188684\n",
      "61062\n",
      "Train on 116871 samples, validate on 37532 samples\n",
      "Epoch 1/100\n",
      "116871/116871 [==============================] - 9s 81us/step - loss: 0.0561 - val_loss: 0.0422\n",
      "Epoch 2/100\n",
      "116871/116871 [==============================] - 9s 73us/step - loss: 0.0466 - val_loss: 0.0422\n",
      "Epoch 3/100\n",
      "116871/116871 [==============================] - 9s 73us/step - loss: 0.0449 - val_loss: 0.0403\n",
      "Epoch 4/100\n",
      "116871/116871 [==============================] - 8s 73us/step - loss: 0.0440 - val_loss: 0.0408\n",
      "Epoch 5/100\n",
      "116871/116871 [==============================] - 9s 73us/step - loss: 0.0433 - val_loss: 0.0406\n",
      "Epoch 6/100\n",
      "116871/116871 [==============================] - 9s 73us/step - loss: 0.0428 - val_loss: 0.0370\n",
      "Epoch 7/100\n",
      "116871/116871 [==============================] - 9s 73us/step - loss: 0.0423 - val_loss: 0.0368\n",
      "Epoch 8/100\n",
      "116871/116871 [==============================] - 8s 71us/step - loss: 0.0420 - val_loss: 0.0375\n",
      "Epoch 9/100\n",
      "116871/116871 [==============================] - 8s 68us/step - loss: 0.0418 - val_loss: 0.0374\n",
      "Epoch 10/100\n",
      "116871/116871 [==============================] - 8s 72us/step - loss: 0.0415 - val_loss: 0.0379\n",
      "Epoch 11/100\n",
      "116871/116871 [==============================] - 8s 72us/step - loss: 0.0411 - val_loss: 0.0376\n",
      "perc98SubjectF2andFold4\n",
      "178211\n",
      "61173\n",
      "Train on 105662 samples, validate on 35598 samples\n",
      "Epoch 1/100\n",
      "105662/105662 [==============================] - 8s 79us/step - loss: 0.0517 - val_loss: 0.0431\n",
      "Epoch 2/100\n",
      "105662/105662 [==============================] - 7s 70us/step - loss: 0.0395 - val_loss: 0.0409\n",
      "Epoch 3/100\n",
      "105662/105662 [==============================] - 7s 68us/step - loss: 0.0378 - val_loss: 0.0407\n",
      "Epoch 4/100\n",
      "105662/105662 [==============================] - 7s 70us/step - loss: 0.0367 - val_loss: 0.0398\n",
      "Epoch 5/100\n",
      "105662/105662 [==============================] - 7s 70us/step - loss: 0.0360 - val_loss: 0.0380\n",
      "Epoch 6/100\n",
      "105662/105662 [==============================] - 8s 72us/step - loss: 0.0354 - val_loss: 0.0384\n",
      "Epoch 7/100\n",
      "105662/105662 [==============================] - 8s 71us/step - loss: 0.0345 - val_loss: 0.0371\n",
      "Epoch 8/100\n",
      "105662/105662 [==============================] - 7s 68us/step - loss: 0.0341 - val_loss: 0.0371\n",
      "Epoch 9/100\n",
      "105662/105662 [==============================] - 5s 51us/step - loss: 0.0335 - val_loss: 0.0374\n",
      "Epoch 10/100\n",
      "105662/105662 [==============================] - 6s 52us/step - loss: 0.0330 - val_loss: 0.0356\n",
      "Epoch 11/100\n",
      "105662/105662 [==============================] - 6s 53us/step - loss: 0.0326 - val_loss: 0.0357\n",
      "Epoch 12/100\n",
      "105662/105662 [==============================] - 6s 54us/step - loss: 0.0323 - val_loss: 0.0355\n",
      "Epoch 13/100\n",
      "105662/105662 [==============================] - 6s 53us/step - loss: 0.0319 - val_loss: 0.0354\n",
      "Epoch 14/100\n",
      "105662/105662 [==============================] - 6s 54us/step - loss: 0.0315 - val_loss: 0.0343\n",
      "Epoch 15/100\n",
      "105662/105662 [==============================] - 6s 53us/step - loss: 0.0314 - val_loss: 0.0351\n",
      "Epoch 16/100\n",
      "105662/105662 [==============================] - 6s 54us/step - loss: 0.0310 - val_loss: 0.0357\n",
      "Epoch 17/100\n",
      "105662/105662 [==============================] - 6s 53us/step - loss: 0.0309 - val_loss: 0.0338\n",
      "Epoch 18/100\n",
      "105662/105662 [==============================] - 6s 54us/step - loss: 0.0305 - val_loss: 0.0349\n",
      "Epoch 19/100\n",
      "105662/105662 [==============================] - 6s 54us/step - loss: 0.0304 - val_loss: 0.0330\n",
      "Epoch 20/100\n",
      "105662/105662 [==============================] - 5s 51us/step - loss: 0.0302 - val_loss: 0.0346\n",
      "Epoch 21/100\n",
      "105662/105662 [==============================] - 6s 52us/step - loss: 0.0299 - val_loss: 0.0335\n",
      "Epoch 22/100\n",
      "105662/105662 [==============================] - 5s 52us/step - loss: 0.0300 - val_loss: 0.0333\n",
      "Epoch 23/100\n",
      "105662/105662 [==============================] - 6s 53us/step - loss: 0.0296 - val_loss: 0.0344\n",
      "perc98SubjectM1andFold1\n",
      "259459\n",
      "86801\n",
      "Train on 218830 samples, validate on 73707 samples\n",
      "Epoch 1/100\n",
      "218830/218830 [==============================] - 16s 74us/step - loss: 0.0548 - val_loss: 0.0494\n",
      "Epoch 2/100\n",
      "218830/218830 [==============================] - 15s 69us/step - loss: 0.0467 - val_loss: 0.0454\n",
      "Epoch 3/100\n",
      "218830/218830 [==============================] - 15s 70us/step - loss: 0.0450 - val_loss: 0.0439\n",
      "Epoch 4/100\n",
      "218830/218830 [==============================] - 17s 76us/step - loss: 0.0435 - val_loss: 0.0438\n",
      "Epoch 5/100\n",
      "218830/218830 [==============================] - 16s 75us/step - loss: 0.0425 - val_loss: 0.0416\n",
      "Epoch 6/100\n",
      "218830/218830 [==============================] - 17s 76us/step - loss: 0.0417 - val_loss: 0.0417\n",
      "Epoch 7/100\n",
      "218830/218830 [==============================] - 16s 75us/step - loss: 0.0410 - val_loss: 0.0400\n",
      "Epoch 8/100\n",
      "218830/218830 [==============================] - 16s 75us/step - loss: 0.0403 - val_loss: 0.0409\n",
      "Epoch 9/100\n",
      "218830/218830 [==============================] - 16s 72us/step - loss: 0.0397 - val_loss: 0.0396\n",
      "Epoch 10/100\n",
      "218830/218830 [==============================] - 15s 70us/step - loss: 0.0392 - val_loss: 0.0387\n",
      "Epoch 11/100\n",
      "218830/218830 [==============================] - 15s 71us/step - loss: 0.0387 - val_loss: 0.0386\n",
      "Epoch 12/100\n",
      "218830/218830 [==============================] - 15s 70us/step - loss: 0.0382 - val_loss: 0.0381\n",
      "Epoch 13/100\n",
      "218830/218830 [==============================] - 16s 73us/step - loss: 0.0378 - val_loss: 0.0377\n",
      "Epoch 14/100\n",
      "218830/218830 [==============================] - 15s 71us/step - loss: 0.0375 - val_loss: 0.0368\n",
      "Epoch 15/100\n",
      "218830/218830 [==============================] - 15s 70us/step - loss: 0.0372 - val_loss: 0.0372\n",
      "Epoch 16/100\n",
      "218830/218830 [==============================] - 15s 69us/step - loss: 0.0368 - val_loss: 0.0364\n",
      "Epoch 17/100\n",
      "218830/218830 [==============================] - 16s 75us/step - loss: 0.0366 - val_loss: 0.0357\n",
      "Epoch 18/100\n",
      "218830/218830 [==============================] - 16s 75us/step - loss: 0.0363 - val_loss: 0.0359\n",
      "Epoch 19/100\n",
      "218830/218830 [==============================] - 17s 76us/step - loss: 0.0359 - val_loss: 0.0357\n",
      "Epoch 20/100\n",
      "218830/218830 [==============================] - 16s 75us/step - loss: 0.0357 - val_loss: 0.0352\n",
      "Epoch 21/100\n",
      "218830/218830 [==============================] - 17s 76us/step - loss: 0.0355 - val_loss: 0.0355\n",
      "Epoch 22/100\n",
      "218830/218830 [==============================] - 17s 76us/step - loss: 0.0352 - val_loss: 0.0343\n",
      "Epoch 23/100\n",
      "218830/218830 [==============================] - 16s 75us/step - loss: 0.0350 - val_loss: 0.0353\n",
      "Epoch 24/100\n",
      "218830/218830 [==============================] - 16s 75us/step - loss: 0.0348 - val_loss: 0.0346\n",
      "Epoch 25/100\n",
      "218830/218830 [==============================] - 16s 74us/step - loss: 0.0347 - val_loss: 0.0341\n",
      "Epoch 26/100\n",
      "218830/218830 [==============================] - 16s 74us/step - loss: 0.0344 - val_loss: 0.0342\n",
      "Epoch 27/100\n",
      "218830/218830 [==============================] - 16s 75us/step - loss: 0.0343 - val_loss: 0.0339\n",
      "Epoch 28/100\n",
      "218830/218830 [==============================] - 16s 71us/step - loss: 0.0342 - val_loss: 0.0337\n",
      "Epoch 29/100\n",
      "218830/218830 [==============================] - 15s 67us/step - loss: 0.0341 - val_loss: 0.0339\n",
      "Epoch 30/100\n",
      "218830/218830 [==============================] - 14s 62us/step - loss: 0.0340 - val_loss: 0.0339\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218830/218830 [==============================] - 14s 65us/step - loss: 0.0337 - val_loss: 0.0335\n",
      "Epoch 32/100\n",
      "218830/218830 [==============================] - 14s 63us/step - loss: 0.0335 - val_loss: 0.0333\n",
      "Epoch 33/100\n",
      "218830/218830 [==============================] - 14s 63us/step - loss: 0.0336 - val_loss: 0.0338\n",
      "Epoch 34/100\n",
      "218830/218830 [==============================] - 14s 63us/step - loss: 0.0334 - val_loss: 0.0332\n",
      "Epoch 35/100\n",
      "218830/218830 [==============================] - 14s 62us/step - loss: 0.0332 - val_loss: 0.0333\n",
      "Epoch 36/100\n",
      "218830/218830 [==============================] - 14s 64us/step - loss: 0.0330 - val_loss: 0.0330\n",
      "Epoch 37/100\n",
      "218830/218830 [==============================] - 14s 63us/step - loss: 0.0330 - val_loss: 0.0330\n",
      "Epoch 38/100\n",
      "218830/218830 [==============================] - 14s 63us/step - loss: 0.0329 - val_loss: 0.0333\n",
      "Epoch 39/100\n",
      "218830/218830 [==============================] - 13s 62us/step - loss: 0.0329 - val_loss: 0.0325\n",
      "Epoch 40/100\n",
      "218830/218830 [==============================] - 14s 65us/step - loss: 0.0327 - val_loss: 0.0326\n",
      "Epoch 41/100\n",
      "218830/218830 [==============================] - 14s 65us/step - loss: 0.0326 - val_loss: 0.0329\n",
      "Epoch 42/100\n",
      "218830/218830 [==============================] - 14s 65us/step - loss: 0.0325 - val_loss: 0.0332\n",
      "Epoch 43/100\n",
      "218830/218830 [==============================] - 14s 64us/step - loss: 0.0324 - val_loss: 0.0325\n",
      "perc98SubjectM1andFold2\n",
      "269088\n",
      "89267\n",
      "Train on 115328 samples, validate on 37092 samples\n",
      "Epoch 1/100\n",
      "115328/115328 [==============================] - 9s 78us/step - loss: 0.0565 - val_loss: 0.0427\n",
      "Epoch 2/100\n",
      "115328/115328 [==============================] - 8s 69us/step - loss: 0.0422 - val_loss: 0.0361\n",
      "Epoch 3/100\n",
      "115328/115328 [==============================] - 8s 68us/step - loss: 0.0390 - val_loss: 0.0343\n",
      "Epoch 4/100\n",
      "115328/115328 [==============================] - 8s 69us/step - loss: 0.0370 - val_loss: 0.0328\n",
      "Epoch 5/100\n",
      "115328/115328 [==============================] - 8s 68us/step - loss: 0.0355 - val_loss: 0.0319\n",
      "Epoch 6/100\n",
      "115328/115328 [==============================] - 8s 66us/step - loss: 0.0344 - val_loss: 0.0314\n",
      "Epoch 7/100\n",
      "115328/115328 [==============================] - 7s 62us/step - loss: 0.0333 - val_loss: 0.0314\n",
      "Epoch 8/100\n",
      "115328/115328 [==============================] - 7s 63us/step - loss: 0.0325 - val_loss: 0.0293\n",
      "Epoch 9/100\n",
      "115328/115328 [==============================] - 7s 64us/step - loss: 0.0320 - val_loss: 0.0285\n",
      "Epoch 10/100\n",
      "115328/115328 [==============================] - 7s 64us/step - loss: 0.0315 - val_loss: 0.0290\n",
      "Epoch 11/100\n",
      "115328/115328 [==============================] - 7s 65us/step - loss: 0.0309 - val_loss: 0.0283\n",
      "Epoch 12/100\n",
      "115328/115328 [==============================] - 7s 64us/step - loss: 0.0303 - val_loss: 0.0291\n",
      "Epoch 13/100\n",
      "115328/115328 [==============================] - 7s 65us/step - loss: 0.0299 - val_loss: 0.0274\n",
      "Epoch 14/100\n",
      "115328/115328 [==============================] - 8s 66us/step - loss: 0.0295 - val_loss: 0.0279\n",
      "Epoch 15/100\n",
      "115328/115328 [==============================] - 8s 66us/step - loss: 0.0291 - val_loss: 0.0270\n",
      "Epoch 16/100\n",
      "115328/115328 [==============================] - 7s 63us/step - loss: 0.0287 - val_loss: 0.0267\n",
      "Epoch 17/100\n",
      "115328/115328 [==============================] - 7s 57us/step - loss: 0.0283 - val_loss: 0.0265\n",
      "Epoch 18/100\n",
      "115328/115328 [==============================] - 7s 57us/step - loss: 0.0283 - val_loss: 0.0262\n",
      "Epoch 19/100\n",
      "115328/115328 [==============================] - 7s 59us/step - loss: 0.0278 - val_loss: 0.0259\n",
      "Epoch 20/100\n",
      "115328/115328 [==============================] - 7s 58us/step - loss: 0.0277 - val_loss: 0.0257\n",
      "Epoch 21/100\n",
      "115328/115328 [==============================] - 7s 59us/step - loss: 0.0274 - val_loss: 0.0251\n",
      "Epoch 22/100\n",
      "115328/115328 [==============================] - 7s 60us/step - loss: 0.0272 - val_loss: 0.0253\n",
      "Epoch 23/100\n",
      "115328/115328 [==============================] - 7s 59us/step - loss: 0.0269 - val_loss: 0.0250\n",
      "Epoch 24/100\n",
      "115328/115328 [==============================] - 7s 57us/step - loss: 0.0267 - val_loss: 0.0248\n",
      "Epoch 25/100\n",
      "115328/115328 [==============================] - 7s 58us/step - loss: 0.0266 - val_loss: 0.0254\n",
      "Epoch 26/100\n",
      "115328/115328 [==============================] - 7s 56us/step - loss: 0.0264 - val_loss: 0.0249\n",
      "Epoch 27/100\n",
      "115328/115328 [==============================] - 7s 62us/step - loss: 0.0261 - val_loss: 0.0247\n",
      "Epoch 28/100\n",
      "115328/115328 [==============================] - 7s 63us/step - loss: 0.0261 - val_loss: 0.0240\n",
      "Epoch 29/100\n",
      "115328/115328 [==============================] - 8s 65us/step - loss: 0.0258 - val_loss: 0.0241\n",
      "Epoch 30/100\n",
      "115328/115328 [==============================] - 7s 65us/step - loss: 0.0257 - val_loss: 0.0244\n",
      "Epoch 31/100\n",
      "115328/115328 [==============================] - 7s 64us/step - loss: 0.0256 - val_loss: 0.0239\n",
      "Epoch 32/100\n",
      "115328/115328 [==============================] - 8s 66us/step - loss: 0.0254 - val_loss: 0.0241\n",
      "Epoch 33/100\n",
      "115328/115328 [==============================] - 8s 67us/step - loss: 0.0253 - val_loss: 0.0242\n",
      "Epoch 34/100\n",
      "115328/115328 [==============================] - 8s 67us/step - loss: 0.0251 - val_loss: 0.0247\n",
      "Epoch 35/100\n",
      "115328/115328 [==============================] - 8s 68us/step - loss: 0.0251 - val_loss: 0.0240\n",
      "perc98SubjectM1andFold3\n",
      "226040\n",
      "74590\n",
      "Train on 140161 samples, validate on 43797 samples\n",
      "Epoch 1/100\n",
      "140161/140161 [==============================] - 10s 73us/step - loss: 0.0558 - val_loss: 0.0381\n",
      "Epoch 2/100\n",
      "140161/140161 [==============================] - 9s 64us/step - loss: 0.0441 - val_loss: 0.0353\n",
      "Epoch 3/100\n",
      "140161/140161 [==============================] - 9s 64us/step - loss: 0.0417 - val_loss: 0.0338\n",
      "Epoch 4/100\n",
      "140161/140161 [==============================] - 9s 64us/step - loss: 0.0406 - val_loss: 0.0333\n",
      "Epoch 5/100\n",
      "140161/140161 [==============================] - 9s 64us/step - loss: 0.0394 - val_loss: 0.0326\n",
      "Epoch 6/100\n",
      "140161/140161 [==============================] - 9s 64us/step - loss: 0.0385 - val_loss: 0.0318\n",
      "Epoch 7/100\n",
      "140161/140161 [==============================] - 9s 64us/step - loss: 0.0377 - val_loss: 0.0302\n",
      "Epoch 8/100\n",
      "140161/140161 [==============================] - 9s 63us/step - loss: 0.0372 - val_loss: 0.0305\n",
      "Epoch 9/100\n",
      "140161/140161 [==============================] - 9s 64us/step - loss: 0.0366 - val_loss: 0.0298\n",
      "Epoch 10/100\n",
      "140161/140161 [==============================] - 9s 63us/step - loss: 0.0362 - val_loss: 0.0299\n",
      "Epoch 11/100\n",
      "140161/140161 [==============================] - 8s 60us/step - loss: 0.0359 - val_loss: 0.0300\n",
      "Epoch 12/100\n",
      "140161/140161 [==============================] - 8s 55us/step - loss: 0.0354 - val_loss: 0.0280\n",
      "Epoch 13/100\n",
      "140161/140161 [==============================] - 8s 57us/step - loss: 0.0352 - val_loss: 0.0294\n",
      "Epoch 14/100\n",
      "140161/140161 [==============================] - 8s 57us/step - loss: 0.0347 - val_loss: 0.0289\n",
      "Epoch 15/100\n",
      "140161/140161 [==============================] - 8s 59us/step - loss: 0.0345 - val_loss: 0.0300\n",
      "Epoch 16/100\n",
      "140161/140161 [==============================] - 9s 62us/step - loss: 0.0342 - val_loss: 0.0279\n",
      "Epoch 17/100\n",
      "140161/140161 [==============================] - 8s 60us/step - loss: 0.0340 - val_loss: 0.0293\n",
      "Epoch 18/100\n",
      "140161/140161 [==============================] - 8s 57us/step - loss: 0.0338 - val_loss: 0.0283\n",
      "Epoch 19/100\n",
      "140161/140161 [==============================] - 8s 57us/step - loss: 0.0336 - val_loss: 0.0271\n",
      "Epoch 20/100\n",
      "140161/140161 [==============================] - 8s 57us/step - loss: 0.0334 - val_loss: 0.0284\n",
      "Epoch 21/100\n",
      "140161/140161 [==============================] - 8s 57us/step - loss: 0.0332 - val_loss: 0.0273\n",
      "Epoch 22/100\n",
      "140161/140161 [==============================] - 8s 56us/step - loss: 0.0331 - val_loss: 0.0283\n",
      "Epoch 23/100\n",
      "140161/140161 [==============================] - 8s 58us/step - loss: 0.0328 - val_loss: 0.0270\n",
      "Epoch 24/100\n",
      "140161/140161 [==============================] - 8s 55us/step - loss: 0.0328 - val_loss: 0.0277\n",
      "Epoch 25/100\n",
      "140161/140161 [==============================] - 8s 54us/step - loss: 0.0325 - val_loss: 0.0286\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140161/140161 [==============================] - 8s 55us/step - loss: 0.0326 - val_loss: 0.0285\n",
      "Epoch 27/100\n",
      "140161/140161 [==============================] - 9s 64us/step - loss: 0.0324 - val_loss: 0.0272\n",
      "perc98SubjectM1andFold4\n",
      "236266\n",
      "78511\n",
      "Train on 132544 samples, validate on 42974 samples\n",
      "Epoch 1/100\n",
      "132544/132544 [==============================] - 10s 77us/step - loss: 0.0505 - val_loss: 0.0374\n",
      "Epoch 2/100\n",
      "132544/132544 [==============================] - 9s 67us/step - loss: 0.0376 - val_loss: 0.0338\n",
      "Epoch 3/100\n",
      "132544/132544 [==============================] - 9s 68us/step - loss: 0.0352 - val_loss: 0.0325\n",
      "Epoch 4/100\n",
      "132544/132544 [==============================] - 9s 67us/step - loss: 0.0340 - val_loss: 0.0330\n",
      "Epoch 5/100\n",
      "132544/132544 [==============================] - 9s 68us/step - loss: 0.0329 - val_loss: 0.0310\n",
      "Epoch 6/100\n",
      "132544/132544 [==============================] - 9s 67us/step - loss: 0.0319 - val_loss: 0.0306\n",
      "Epoch 7/100\n",
      "132544/132544 [==============================] - 9s 68us/step - loss: 0.0312 - val_loss: 0.0288\n",
      "Epoch 8/100\n",
      "132544/132544 [==============================] - 9s 68us/step - loss: 0.0305 - val_loss: 0.0282\n",
      "Epoch 9/100\n",
      "132544/132544 [==============================] - 9s 66us/step - loss: 0.0300 - val_loss: 0.0296\n",
      "Epoch 10/100\n",
      "132544/132544 [==============================] - 9s 67us/step - loss: 0.0294 - val_loss: 0.0275\n",
      "Epoch 11/100\n",
      "132544/132544 [==============================] - 9s 69us/step - loss: 0.0291 - val_loss: 0.0279\n",
      "Epoch 12/100\n",
      "132544/132544 [==============================] - 9s 69us/step - loss: 0.0288 - val_loss: 0.0276\n",
      "Epoch 13/100\n",
      "132544/132544 [==============================] - 9s 70us/step - loss: 0.0283 - val_loss: 0.0269\n",
      "Epoch 14/100\n",
      "132544/132544 [==============================] - 9s 70us/step - loss: 0.0282 - val_loss: 0.0265\n",
      "Epoch 15/100\n",
      "132544/132544 [==============================] - 9s 70us/step - loss: 0.0279 - val_loss: 0.0258\n",
      "Epoch 16/100\n",
      "132544/132544 [==============================] - 9s 71us/step - loss: 0.0276 - val_loss: 0.0264\n",
      "Epoch 17/100\n",
      "132544/132544 [==============================] - 9s 71us/step - loss: 0.0274 - val_loss: 0.0267\n",
      "Epoch 18/100\n",
      "132544/132544 [==============================] - 9s 66us/step - loss: 0.0271 - val_loss: 0.0267\n",
      "Epoch 19/100\n",
      "132544/132544 [==============================] - 8s 62us/step - loss: 0.0270 - val_loss: 0.0261\n",
      "perc98SubjectM2andFold1\n",
      "221229\n",
      "69351\n",
      "Train on 198878 samples, validate on 62970 samples\n",
      "Epoch 1/100\n",
      "198878/198878 [==============================] - 15s 77us/step - loss: 0.0598 - val_loss: 0.0508\n",
      "Epoch 2/100\n",
      "198878/198878 [==============================] - 12s 63us/step - loss: 0.0513 - val_loss: 0.0488\n",
      "Epoch 3/100\n",
      "198878/198878 [==============================] - 12s 59us/step - loss: 0.0487 - val_loss: 0.0459\n",
      "Epoch 4/100\n",
      "198878/198878 [==============================] - 12s 58us/step - loss: 0.0470 - val_loss: 0.0448\n",
      "Epoch 5/100\n",
      "198878/198878 [==============================] - 12s 61us/step - loss: 0.0457 - val_loss: 0.0436\n",
      "Epoch 6/100\n",
      "198878/198878 [==============================] - 12s 62us/step - loss: 0.0445 - val_loss: 0.0437\n",
      "Epoch 7/100\n",
      "198878/198878 [==============================] - 12s 61us/step - loss: 0.0436 - val_loss: 0.0424\n",
      "Epoch 8/100\n",
      "198878/198878 [==============================] - 13s 63us/step - loss: 0.0427 - val_loss: 0.0417\n",
      "Epoch 9/100\n",
      "198878/198878 [==============================] - 13s 65us/step - loss: 0.0420 - val_loss: 0.0406\n",
      "Epoch 10/100\n",
      "198878/198878 [==============================] - 13s 63us/step - loss: 0.0414 - val_loss: 0.0404\n",
      "Epoch 11/100\n",
      "198878/198878 [==============================] - 13s 64us/step - loss: 0.0409 - val_loss: 0.0400\n",
      "Epoch 12/100\n",
      "198878/198878 [==============================] - 13s 64us/step - loss: 0.0403 - val_loss: 0.0408\n",
      "Epoch 13/100\n",
      "198878/198878 [==============================] - 13s 64us/step - loss: 0.0400 - val_loss: 0.0394\n",
      "Epoch 14/100\n",
      "198878/198878 [==============================] - 13s 64us/step - loss: 0.0395 - val_loss: 0.0394\n",
      "Epoch 15/100\n",
      "198878/198878 [==============================] - 13s 63us/step - loss: 0.0390 - val_loss: 0.0393\n",
      "Epoch 16/100\n",
      "198878/198878 [==============================] - 13s 64us/step - loss: 0.0387 - val_loss: 0.0390\n",
      "Epoch 17/100\n",
      "198878/198878 [==============================] - 13s 64us/step - loss: 0.0384 - val_loss: 0.0384\n",
      "Epoch 18/100\n",
      "198878/198878 [==============================] - 13s 63us/step - loss: 0.0381 - val_loss: 0.0381\n",
      "Epoch 19/100\n",
      "198878/198878 [==============================] - 12s 62us/step - loss: 0.0377 - val_loss: 0.0376\n",
      "Epoch 20/100\n",
      "198878/198878 [==============================] - 12s 62us/step - loss: 0.0376 - val_loss: 0.0375\n",
      "Epoch 21/100\n",
      "198878/198878 [==============================] - 13s 64us/step - loss: 0.0373 - val_loss: 0.0374\n",
      "Epoch 22/100\n",
      "198878/198878 [==============================] - 13s 64us/step - loss: 0.0371 - val_loss: 0.0371\n",
      "Epoch 23/100\n",
      "198878/198878 [==============================] - 13s 64us/step - loss: 0.0370 - val_loss: 0.0364\n",
      "Epoch 24/100\n",
      "198878/198878 [==============================] - 13s 64us/step - loss: 0.0368 - val_loss: 0.0368\n",
      "Epoch 25/100\n",
      "198878/198878 [==============================] - 13s 65us/step - loss: 0.0365 - val_loss: 0.0369\n",
      "Epoch 26/100\n",
      "198878/198878 [==============================] - 13s 64us/step - loss: 0.0363 - val_loss: 0.0363\n",
      "Epoch 27/100\n",
      "198878/198878 [==============================] - 13s 65us/step - loss: 0.0361 - val_loss: 0.0367\n",
      "Epoch 28/100\n",
      "198878/198878 [==============================] - 13s 64us/step - loss: 0.0361 - val_loss: 0.0366\n",
      "Epoch 29/100\n",
      "198878/198878 [==============================] - 12s 62us/step - loss: 0.0357 - val_loss: 0.0360\n",
      "Epoch 30/100\n",
      "198878/198878 [==============================] - 12s 61us/step - loss: 0.0357 - val_loss: 0.0359\n",
      "Epoch 31/100\n",
      "198878/198878 [==============================] - 12s 58us/step - loss: 0.0356 - val_loss: 0.0358\n",
      "Epoch 32/100\n",
      "198878/198878 [==============================] - 12s 59us/step - loss: 0.0354 - val_loss: 0.0360\n",
      "Epoch 33/100\n",
      "198878/198878 [==============================] - 12s 62us/step - loss: 0.0353 - val_loss: 0.0361\n",
      "Epoch 34/100\n",
      "198878/198878 [==============================] - 12s 59us/step - loss: 0.0352 - val_loss: 0.0360\n",
      "Epoch 35/100\n",
      "198878/198878 [==============================] - 12s 59us/step - loss: 0.0350 - val_loss: 0.0355\n",
      "Epoch 36/100\n",
      "198878/198878 [==============================] - 12s 60us/step - loss: 0.0349 - val_loss: 0.0355\n",
      "Epoch 37/100\n",
      "198878/198878 [==============================] - 12s 60us/step - loss: 0.0348 - val_loss: 0.0354\n",
      "Epoch 38/100\n",
      "198878/198878 [==============================] - 12s 60us/step - loss: 0.0348 - val_loss: 0.0358\n",
      "Epoch 39/100\n",
      "198878/198878 [==============================] - 11s 58us/step - loss: 0.0347 - val_loss: 0.0352\n",
      "Epoch 40/100\n",
      "198878/198878 [==============================] - 12s 59us/step - loss: 0.0345 - val_loss: 0.0352\n",
      "Epoch 41/100\n",
      "198878/198878 [==============================] - 13s 64us/step - loss: 0.0344 - val_loss: 0.0348\n",
      "Epoch 42/100\n",
      "198878/198878 [==============================] - 13s 64us/step - loss: 0.0344 - val_loss: 0.0351\n",
      "Epoch 43/100\n",
      "198878/198878 [==============================] - 13s 64us/step - loss: 0.0343 - val_loss: 0.0349\n",
      "Epoch 44/100\n",
      "198878/198878 [==============================] - 13s 64us/step - loss: 0.0342 - val_loss: 0.0348\n",
      "Epoch 45/100\n",
      "198878/198878 [==============================] - 13s 64us/step - loss: 0.0340 - val_loss: 0.0349\n",
      "perc98SubjectM2andFold2\n",
      "228394\n",
      "77034\n",
      "Train on 143090 samples, validate on 46946 samples\n",
      "Epoch 1/100\n",
      "143090/143090 [==============================] - 11s 74us/step - loss: 0.0538 - val_loss: 0.0438\n",
      "Epoch 2/100\n",
      "143090/143090 [==============================] - 9s 63us/step - loss: 0.0417 - val_loss: 0.0391\n",
      "Epoch 3/100\n",
      "143090/143090 [==============================] - 9s 62us/step - loss: 0.0381 - val_loss: 0.0384\n",
      "Epoch 4/100\n",
      "143090/143090 [==============================] - 9s 62us/step - loss: 0.0363 - val_loss: 0.0358\n",
      "Epoch 5/100\n",
      "143090/143090 [==============================] - 9s 61us/step - loss: 0.0347 - val_loss: 0.0351\n",
      "Epoch 6/100\n",
      "143090/143090 [==============================] - 9s 62us/step - loss: 0.0336 - val_loss: 0.0330\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143090/143090 [==============================] - 9s 62us/step - loss: 0.0327 - val_loss: 0.0323\n",
      "Epoch 8/100\n",
      "143090/143090 [==============================] - 9s 62us/step - loss: 0.0317 - val_loss: 0.0323\n",
      "Epoch 9/100\n",
      "143090/143090 [==============================] - 9s 63us/step - loss: 0.0310 - val_loss: 0.0315\n",
      "Epoch 10/100\n",
      "143090/143090 [==============================] - 9s 62us/step - loss: 0.0304 - val_loss: 0.0299\n",
      "Epoch 11/100\n",
      "143090/143090 [==============================] - 9s 63us/step - loss: 0.0300 - val_loss: 0.0301\n",
      "Epoch 12/100\n",
      "143090/143090 [==============================] - 9s 63us/step - loss: 0.0295 - val_loss: 0.0296\n",
      "Epoch 13/100\n",
      "143090/143090 [==============================] - 9s 62us/step - loss: 0.0290 - val_loss: 0.0287\n",
      "Epoch 14/100\n",
      "143090/143090 [==============================] - 9s 62us/step - loss: 0.0286 - val_loss: 0.0296\n",
      "Epoch 15/100\n",
      "143090/143090 [==============================] - 9s 61us/step - loss: 0.0284 - val_loss: 0.0293\n",
      "Epoch 16/100\n",
      "143090/143090 [==============================] - 11s 80us/step - loss: 0.0278 - val_loss: 0.0277\n",
      "Epoch 17/100\n",
      "143090/143090 [==============================] - 11s 80us/step - loss: 0.0277 - val_loss: 0.0280\n",
      "Epoch 18/100\n",
      "143090/143090 [==============================] - 11s 80us/step - loss: 0.0272 - val_loss: 0.0277\n",
      "Epoch 19/100\n",
      "143090/143090 [==============================] - 11s 80us/step - loss: 0.0270 - val_loss: 0.0279\n",
      "Epoch 20/100\n",
      "143090/143090 [==============================] - 12s 81us/step - loss: 0.0268 - val_loss: 0.0273\n",
      "Epoch 21/100\n",
      "143090/143090 [==============================] - 11s 79us/step - loss: 0.0264 - val_loss: 0.0271\n",
      "Epoch 22/100\n",
      "143090/143090 [==============================] - 11s 78us/step - loss: 0.0262 - val_loss: 0.0260\n",
      "Epoch 23/100\n",
      "143090/143090 [==============================] - 12s 81us/step - loss: 0.0261 - val_loss: 0.0265\n",
      "Epoch 24/100\n",
      "143090/143090 [==============================] - 11s 79us/step - loss: 0.0257 - val_loss: 0.0269\n",
      "Epoch 25/100\n",
      "143090/143090 [==============================] - 11s 80us/step - loss: 0.0256 - val_loss: 0.0259\n",
      "Epoch 26/100\n",
      "143090/143090 [==============================] - 12s 82us/step - loss: 0.0254 - val_loss: 0.0260\n",
      "Epoch 27/100\n",
      "143090/143090 [==============================] - 11s 76us/step - loss: 0.0253 - val_loss: 0.0260\n",
      "Epoch 28/100\n",
      "143090/143090 [==============================] - 11s 79us/step - loss: 0.0251 - val_loss: 0.0253\n",
      "Epoch 29/100\n",
      "143090/143090 [==============================] - 11s 79us/step - loss: 0.0249 - val_loss: 0.0256\n",
      "Epoch 30/100\n",
      "143090/143090 [==============================] - 11s 79us/step - loss: 0.0248 - val_loss: 0.0253\n",
      "Epoch 31/100\n",
      "143090/143090 [==============================] - 11s 78us/step - loss: 0.0246 - val_loss: 0.0255\n",
      "Epoch 32/100\n",
      "143090/143090 [==============================] - 11s 78us/step - loss: 0.0246 - val_loss: 0.0255\n",
      "Epoch 33/100\n",
      "143090/143090 [==============================] - 11s 75us/step - loss: 0.0245 - val_loss: 0.0253\n",
      "Epoch 34/100\n",
      "143090/143090 [==============================] - 12s 81us/step - loss: 0.0242 - val_loss: 0.0259\n",
      "Epoch 35/100\n",
      "143090/143090 [==============================] - 12s 82us/step - loss: 0.0241 - val_loss: 0.0248\n",
      "Epoch 36/100\n",
      "143090/143090 [==============================] - 11s 79us/step - loss: 0.0240 - val_loss: 0.0242\n",
      "Epoch 37/100\n",
      "143090/143090 [==============================] - 12s 81us/step - loss: 0.0239 - val_loss: 0.0248\n",
      "Epoch 38/100\n",
      "143090/143090 [==============================] - 11s 80us/step - loss: 0.0238 - val_loss: 0.0244\n",
      "Epoch 39/100\n",
      "143090/143090 [==============================] - 11s 79us/step - loss: 0.0238 - val_loss: 0.0247\n",
      "Epoch 40/100\n",
      "143090/143090 [==============================] - 12s 82us/step - loss: 0.0238 - val_loss: 0.0241\n",
      "Epoch 41/100\n",
      "143090/143090 [==============================] - 12s 82us/step - loss: 0.0234 - val_loss: 0.0244\n",
      "Epoch 42/100\n",
      "143090/143090 [==============================] - 12s 82us/step - loss: 0.0235 - val_loss: 0.0245\n",
      "Epoch 43/100\n",
      "143090/143090 [==============================] - 12s 82us/step - loss: 0.0234 - val_loss: 0.0243\n",
      "Epoch 44/100\n",
      "143090/143090 [==============================] - 11s 80us/step - loss: 0.0231 - val_loss: 0.0240\n",
      "Epoch 45/100\n",
      "143090/143090 [==============================] - 12s 82us/step - loss: 0.0232 - val_loss: 0.0245\n",
      "Epoch 46/100\n",
      "143090/143090 [==============================] - 12s 81us/step - loss: 0.0231 - val_loss: 0.0239\n",
      "Epoch 47/100\n",
      "143090/143090 [==============================] - 12s 84us/step - loss: 0.0230 - val_loss: 0.0238\n",
      "Epoch 48/100\n",
      "143090/143090 [==============================] - 12s 83us/step - loss: 0.0229 - val_loss: 0.0236\n",
      "Epoch 49/100\n",
      "143090/143090 [==============================] - 12s 82us/step - loss: 0.0229 - val_loss: 0.0239\n",
      "Epoch 50/100\n",
      "143090/143090 [==============================] - 11s 78us/step - loss: 0.0227 - val_loss: 0.0234\n",
      "Epoch 51/100\n",
      "143090/143090 [==============================] - 12s 81us/step - loss: 0.0227 - val_loss: 0.0237\n",
      "Epoch 52/100\n",
      "143090/143090 [==============================] - 12s 81us/step - loss: 0.0227 - val_loss: 0.0234\n",
      "Epoch 53/100\n",
      "143090/143090 [==============================] - 12s 81us/step - loss: 0.0226 - val_loss: 0.0233\n",
      "Epoch 54/100\n",
      "143090/143090 [==============================] - 12s 82us/step - loss: 0.0225 - val_loss: 0.0237\n",
      "Epoch 55/100\n",
      "143090/143090 [==============================] - 12s 82us/step - loss: 0.0226 - val_loss: 0.0239\n",
      "Epoch 56/100\n",
      "143090/143090 [==============================] - 11s 80us/step - loss: 0.0224 - val_loss: 0.0233\n",
      "Epoch 57/100\n",
      "143090/143090 [==============================] - 12s 82us/step - loss: 0.0224 - val_loss: 0.0234\n",
      "perc98SubjectM2andFold3\n",
      "205911\n",
      "68142\n",
      "Train on 136055 samples, validate on 45300 samples\n",
      "Epoch 1/100\n",
      "136055/136055 [==============================] - 12s 92us/step - loss: 0.0625 - val_loss: 0.0488\n",
      "Epoch 2/100\n",
      "136055/136055 [==============================] - 11s 79us/step - loss: 0.0519 - val_loss: 0.0451\n",
      "Epoch 3/100\n",
      "136055/136055 [==============================] - 11s 81us/step - loss: 0.0489 - val_loss: 0.0425\n",
      "Epoch 4/100\n",
      "136055/136055 [==============================] - 11s 80us/step - loss: 0.0469 - val_loss: 0.0415\n",
      "Epoch 5/100\n",
      "136055/136055 [==============================] - 11s 82us/step - loss: 0.0455 - val_loss: 0.0403\n",
      "Epoch 6/100\n",
      "136055/136055 [==============================] - 11s 82us/step - loss: 0.0440 - val_loss: 0.0398\n",
      "Epoch 7/100\n",
      "136055/136055 [==============================] - 12s 88us/step - loss: 0.0431 - val_loss: 0.0377\n",
      "Epoch 8/100\n",
      "136055/136055 [==============================] - 12s 91us/step - loss: 0.0422 - val_loss: 0.0376\n",
      "Epoch 9/100\n",
      "136055/136055 [==============================] - 12s 90us/step - loss: 0.0415 - val_loss: 0.0360\n",
      "Epoch 10/100\n",
      "136055/136055 [==============================] - 13s 98us/step - loss: 0.0409 - val_loss: 0.0383\n",
      "Epoch 11/100\n",
      "136055/136055 [==============================] - 13s 96us/step - loss: 0.0403 - val_loss: 0.0358\n",
      "Epoch 12/100\n",
      "136055/136055 [==============================] - 12s 92us/step - loss: 0.0396 - val_loss: 0.0354\n",
      "Epoch 13/100\n",
      "136055/136055 [==============================] - 12s 89us/step - loss: 0.0391 - val_loss: 0.0343\n",
      "Epoch 14/100\n",
      "136055/136055 [==============================] - 12s 87us/step - loss: 0.0387 - val_loss: 0.0341\n",
      "Epoch 15/100\n",
      "136055/136055 [==============================] - 12s 91us/step - loss: 0.0383 - val_loss: 0.0342\n",
      "Epoch 16/100\n",
      "136055/136055 [==============================] - 12s 90us/step - loss: 0.0381 - val_loss: 0.0340\n",
      "Epoch 17/100\n",
      "136055/136055 [==============================] - 12s 91us/step - loss: 0.0377 - val_loss: 0.0353\n",
      "Epoch 18/100\n",
      "136055/136055 [==============================] - 12s 91us/step - loss: 0.0372 - val_loss: 0.0327\n",
      "Epoch 19/100\n",
      "136055/136055 [==============================] - 13s 93us/step - loss: 0.0370 - val_loss: 0.0338\n",
      "Epoch 20/100\n",
      "136055/136055 [==============================] - 13s 93us/step - loss: 0.0368 - val_loss: 0.0327\n",
      "Epoch 21/100\n",
      "136055/136055 [==============================] - 12s 92us/step - loss: 0.0364 - val_loss: 0.0319\n",
      "Epoch 22/100\n",
      "136055/136055 [==============================] - 13s 92us/step - loss: 0.0363 - val_loss: 0.0321\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136055/136055 [==============================] - 13s 93us/step - loss: 0.0359 - val_loss: 0.0317\n",
      "Epoch 24/100\n",
      "136055/136055 [==============================] - 12s 91us/step - loss: 0.0357 - val_loss: 0.0313\n",
      "Epoch 25/100\n",
      "136055/136055 [==============================] - 13s 94us/step - loss: 0.0354 - val_loss: 0.0333\n",
      "Epoch 26/100\n",
      "136055/136055 [==============================] - 13s 92us/step - loss: 0.0354 - val_loss: 0.0317\n",
      "Epoch 27/100\n",
      "136055/136055 [==============================] - 13s 92us/step - loss: 0.0350 - val_loss: 0.0311\n",
      "Epoch 28/100\n",
      "136055/136055 [==============================] - 13s 92us/step - loss: 0.0349 - val_loss: 0.0317\n",
      "Epoch 29/100\n",
      "136055/136055 [==============================] - 12s 92us/step - loss: 0.0347 - val_loss: 0.0308\n",
      "Epoch 30/100\n",
      "136055/136055 [==============================] - 13s 92us/step - loss: 0.0346 - val_loss: 0.0314\n",
      "Epoch 31/100\n",
      "136055/136055 [==============================] - 13s 93us/step - loss: 0.0344 - val_loss: 0.0305\n",
      "Epoch 32/100\n",
      "136055/136055 [==============================] - 12s 91us/step - loss: 0.0343 - val_loss: 0.0307\n",
      "Epoch 33/100\n",
      "136055/136055 [==============================] - 13s 93us/step - loss: 0.0341 - val_loss: 0.0309\n",
      "Epoch 34/100\n",
      "136055/136055 [==============================] - 12s 90us/step - loss: 0.0340 - val_loss: 0.0311\n",
      "Epoch 35/100\n",
      "136055/136055 [==============================] - 12s 91us/step - loss: 0.0338 - val_loss: 0.0309\n",
      "perc98SubjectM2andFold4\n",
      "202981\n",
      "67176\n",
      "Train on 136243 samples, validate on 44228 samples\n",
      "Epoch 1/100\n",
      "136243/136243 [==============================] - 14s 102us/step - loss: 0.0574 - val_loss: 0.0439\n",
      "Epoch 2/100\n",
      "136243/136243 [==============================] - 13s 93us/step - loss: 0.0465 - val_loss: 0.0400\n",
      "Epoch 3/100\n",
      "136243/136243 [==============================] - 13s 92us/step - loss: 0.0429 - val_loss: 0.0388\n",
      "Epoch 4/100\n",
      "136243/136243 [==============================] - 13s 93us/step - loss: 0.0407 - val_loss: 0.0380\n",
      "Epoch 5/100\n",
      "136243/136243 [==============================] - 13s 93us/step - loss: 0.0392 - val_loss: 0.0374\n",
      "Epoch 6/100\n",
      "136243/136243 [==============================] - 12s 91us/step - loss: 0.0379 - val_loss: 0.0342\n",
      "Epoch 7/100\n",
      "136243/136243 [==============================] - 12s 90us/step - loss: 0.0370 - val_loss: 0.0338\n",
      "Epoch 8/100\n",
      "136243/136243 [==============================] - 13s 95us/step - loss: 0.0358 - val_loss: 0.0325\n",
      "Epoch 9/100\n",
      "136243/136243 [==============================] - 13s 95us/step - loss: 0.0352 - val_loss: 0.0321\n",
      "Epoch 10/100\n",
      "136243/136243 [==============================] - 13s 92us/step - loss: 0.0345 - val_loss: 0.0318\n",
      "Epoch 11/100\n",
      "136243/136243 [==============================] - 12s 92us/step - loss: 0.0339 - val_loss: 0.0310\n",
      "Epoch 12/100\n",
      "136243/136243 [==============================] - 13s 94us/step - loss: 0.0332 - val_loss: 0.0311\n",
      "Epoch 13/100\n",
      "136243/136243 [==============================] - 12s 90us/step - loss: 0.0329 - val_loss: 0.0304\n",
      "Epoch 14/100\n",
      "136243/136243 [==============================] - 12s 90us/step - loss: 0.0323 - val_loss: 0.0307\n",
      "Epoch 15/100\n",
      "136243/136243 [==============================] - 12s 91us/step - loss: 0.0318 - val_loss: 0.0302\n",
      "Epoch 16/100\n",
      "136243/136243 [==============================] - 12s 91us/step - loss: 0.0316 - val_loss: 0.0299\n",
      "Epoch 17/100\n",
      "136243/136243 [==============================] - 12s 90us/step - loss: 0.0312 - val_loss: 0.0298\n",
      "Epoch 18/100\n",
      "136243/136243 [==============================] - 12s 91us/step - loss: 0.0308 - val_loss: 0.0291\n",
      "Epoch 19/100\n",
      "136243/136243 [==============================] - 12s 91us/step - loss: 0.0304 - val_loss: 0.0289\n",
      "Epoch 20/100\n",
      "136243/136243 [==============================] - 12s 89us/step - loss: 0.0301 - val_loss: 0.0303\n",
      "Epoch 21/100\n",
      "136243/136243 [==============================] - 13s 92us/step - loss: 0.0301 - val_loss: 0.0287\n",
      "Epoch 22/100\n",
      "136243/136243 [==============================] - 12s 92us/step - loss: 0.0297 - val_loss: 0.0291\n",
      "Epoch 23/100\n",
      "136243/136243 [==============================] - 12s 91us/step - loss: 0.0294 - val_loss: 0.0288\n",
      "Epoch 24/100\n",
      "136243/136243 [==============================] - 12s 92us/step - loss: 0.0293 - val_loss: 0.0279\n",
      "Epoch 25/100\n",
      "136243/136243 [==============================] - 13s 93us/step - loss: 0.0291 - val_loss: 0.0287\n",
      "Epoch 26/100\n",
      "136243/136243 [==============================] - 12s 91us/step - loss: 0.0289 - val_loss: 0.0288\n",
      "Epoch 27/100\n",
      "136243/136243 [==============================] - 12s 89us/step - loss: 0.0287 - val_loss: 0.0280\n",
      "Epoch 28/100\n",
      "136243/136243 [==============================] - 13s 92us/step - loss: 0.0286 - val_loss: 0.0286\n",
      "perc99SubjectF1andFold1\n",
      "228888\n",
      "73562\n",
      "Train on 204569 samples, validate on 66343 samples\n",
      "Epoch 1/100\n",
      "204569/204569 [==============================] - 18s 89us/step - loss: 0.0539 - val_loss: 0.0478\n",
      "Epoch 2/100\n",
      "204569/204569 [==============================] - 17s 81us/step - loss: 0.0443 - val_loss: 0.0445\n",
      "Epoch 3/100\n",
      "204569/204569 [==============================] - 17s 82us/step - loss: 0.0419 - val_loss: 0.0431\n",
      "Epoch 4/100\n",
      "204569/204569 [==============================] - 16s 80us/step - loss: 0.0401 - val_loss: 0.0416\n",
      "Epoch 5/100\n",
      "204569/204569 [==============================] - 17s 81us/step - loss: 0.0386 - val_loss: 0.0416\n",
      "Epoch 6/100\n",
      "204569/204569 [==============================] - 17s 82us/step - loss: 0.0374 - val_loss: 0.0385\n",
      "Epoch 7/100\n",
      "204569/204569 [==============================] - 16s 80us/step - loss: 0.0365 - val_loss: 0.0382\n",
      "Epoch 8/100\n",
      "204569/204569 [==============================] - 17s 81us/step - loss: 0.0357 - val_loss: 0.0368\n",
      "Epoch 9/100\n",
      "204569/204569 [==============================] - 16s 80us/step - loss: 0.0351 - val_loss: 0.0364\n",
      "Epoch 10/100\n",
      "204569/204569 [==============================] - 16s 79us/step - loss: 0.0343 - val_loss: 0.0366\n",
      "Epoch 11/100\n",
      "204569/204569 [==============================] - 16s 79us/step - loss: 0.0338 - val_loss: 0.0363\n",
      "Epoch 12/100\n",
      "204569/204569 [==============================] - 16s 79us/step - loss: 0.0332 - val_loss: 0.0348\n",
      "Epoch 13/100\n",
      "204569/204569 [==============================] - 16s 80us/step - loss: 0.0326 - val_loss: 0.0343\n",
      "Epoch 14/100\n",
      "204569/204569 [==============================] - 16s 77us/step - loss: 0.0322 - val_loss: 0.0341\n",
      "Epoch 15/100\n",
      "204569/204569 [==============================] - 15s 75us/step - loss: 0.0319 - val_loss: 0.0338\n",
      "Epoch 16/100\n",
      "204569/204569 [==============================] - 16s 79us/step - loss: 0.0315 - val_loss: 0.0337\n",
      "Epoch 17/100\n",
      "204569/204569 [==============================] - 16s 80us/step - loss: 0.0312 - val_loss: 0.0335\n",
      "Epoch 18/100\n",
      "204569/204569 [==============================] - 16s 80us/step - loss: 0.0309 - val_loss: 0.0330\n",
      "Epoch 19/100\n",
      "204569/204569 [==============================] - 16s 76us/step - loss: 0.0306 - val_loss: 0.0333\n",
      "Epoch 20/100\n",
      "204569/204569 [==============================] - 18s 88us/step - loss: 0.0304 - val_loss: 0.0326\n",
      "Epoch 21/100\n",
      "204569/204569 [==============================] - 17s 83us/step - loss: 0.0301 - val_loss: 0.0325\n",
      "Epoch 22/100\n",
      "204569/204569 [==============================] - 16s 79us/step - loss: 0.0298 - val_loss: 0.0322\n",
      "Epoch 23/100\n",
      "204569/204569 [==============================] - 16s 79us/step - loss: 0.0296 - val_loss: 0.0327\n",
      "Epoch 24/100\n",
      "204569/204569 [==============================] - 16s 80us/step - loss: 0.0294 - val_loss: 0.0321\n",
      "Epoch 25/100\n",
      "204569/204569 [==============================] - 17s 81us/step - loss: 0.0292 - val_loss: 0.0327\n",
      "Epoch 26/100\n",
      "204569/204569 [==============================] - 16s 80us/step - loss: 0.0290 - val_loss: 0.0318\n",
      "Epoch 27/100\n",
      "204569/204569 [==============================] - 16s 80us/step - loss: 0.0289 - val_loss: 0.0316\n",
      "Epoch 28/100\n",
      "204569/204569 [==============================] - 17s 82us/step - loss: 0.0288 - val_loss: 0.0312\n",
      "Epoch 29/100\n",
      "204569/204569 [==============================] - 17s 81us/step - loss: 0.0285 - val_loss: 0.0307\n",
      "Epoch 30/100\n",
      "204569/204569 [==============================] - 16s 81us/step - loss: 0.0283 - val_loss: 0.0319\n",
      "Epoch 31/100\n",
      "204569/204569 [==============================] - 16s 78us/step - loss: 0.0283 - val_loss: 0.0314\n",
      "Epoch 32/100\n",
      "204569/204569 [==============================] - 16s 80us/step - loss: 0.0281 - val_loss: 0.0311\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204569/204569 [==============================] - 17s 81us/step - loss: 0.0281 - val_loss: 0.0309\n",
      "perc99SubjectF1andFold2\n",
      "246157\n",
      "81493\n",
      "Train on 89643 samples, validate on 28434 samples\n",
      "Epoch 1/100\n",
      "89643/89643 [==============================] - 9s 96us/step - loss: 0.0656 - val_loss: 0.0513\n",
      "Epoch 2/100\n",
      "89643/89643 [==============================] - 8s 91us/step - loss: 0.0492 - val_loss: 0.0467\n",
      "Epoch 3/100\n",
      "89643/89643 [==============================] - 9s 95us/step - loss: 0.0442 - val_loss: 0.0434\n",
      "Epoch 4/100\n",
      "89643/89643 [==============================] - 8s 85us/step - loss: 0.0397 - val_loss: 0.0385\n",
      "Epoch 5/100\n",
      "89643/89643 [==============================] - 7s 82us/step - loss: 0.0371 - val_loss: 0.0367\n",
      "Epoch 6/100\n",
      "89643/89643 [==============================] - 8s 86us/step - loss: 0.0350 - val_loss: 0.0350\n",
      "Epoch 7/100\n",
      "89643/89643 [==============================] - 8s 84us/step - loss: 0.0338 - val_loss: 0.0388\n",
      "Epoch 8/100\n",
      "89643/89643 [==============================] - 7s 83us/step - loss: 0.0326 - val_loss: 0.0336\n",
      "Epoch 9/100\n",
      "89643/89643 [==============================] - 8s 84us/step - loss: 0.0317 - val_loss: 0.0324\n",
      "Epoch 10/100\n",
      "89643/89643 [==============================] - 7s 79us/step - loss: 0.0308 - val_loss: 0.0333\n",
      "Epoch 11/100\n",
      "89643/89643 [==============================] - 8s 84us/step - loss: 0.0299 - val_loss: 0.0333\n",
      "Epoch 12/100\n",
      "89643/89643 [==============================] - 8s 84us/step - loss: 0.0293 - val_loss: 0.0325\n",
      "Epoch 13/100\n",
      "89643/89643 [==============================] - 8s 84us/step - loss: 0.0287 - val_loss: 0.0305\n",
      "Epoch 14/100\n",
      "89643/89643 [==============================] - 8s 84us/step - loss: 0.0281 - val_loss: 0.0321\n",
      "Epoch 15/100\n",
      "89643/89643 [==============================] - 7s 84us/step - loss: 0.0276 - val_loss: 0.0299\n",
      "Epoch 16/100\n",
      "89643/89643 [==============================] - 7s 83us/step - loss: 0.0270 - val_loss: 0.0317\n",
      "Epoch 17/100\n",
      "89643/89643 [==============================] - 7s 81us/step - loss: 0.0266 - val_loss: 0.0296\n",
      "Epoch 18/100\n",
      "89643/89643 [==============================] - 8s 84us/step - loss: 0.0260 - val_loss: 0.0290\n",
      "Epoch 19/100\n",
      "89643/89643 [==============================] - 7s 81us/step - loss: 0.0258 - val_loss: 0.0286\n",
      "Epoch 20/100\n",
      "89643/89643 [==============================] - 7s 79us/step - loss: 0.0254 - val_loss: 0.0297\n",
      "Epoch 21/100\n",
      "89643/89643 [==============================] - 7s 83us/step - loss: 0.0252 - val_loss: 0.0290\n",
      "Epoch 22/100\n",
      "89643/89643 [==============================] - 7s 82us/step - loss: 0.0249 - val_loss: 0.0280\n",
      "Epoch 23/100\n",
      "89643/89643 [==============================] - 7s 83us/step - loss: 0.0249 - val_loss: 0.0277\n",
      "Epoch 24/100\n",
      "89643/89643 [==============================] - 7s 81us/step - loss: 0.0245 - val_loss: 0.0271\n",
      "Epoch 25/100\n",
      "89643/89643 [==============================] - 8s 85us/step - loss: 0.0241 - val_loss: 0.0280\n",
      "Epoch 26/100\n",
      "89643/89643 [==============================] - 7s 83us/step - loss: 0.0240 - val_loss: 0.0286\n",
      "Epoch 27/100\n",
      "89643/89643 [==============================] - 8s 85us/step - loss: 0.0235 - val_loss: 0.0271\n",
      "Epoch 28/100\n",
      "89643/89643 [==============================] - 8s 84us/step - loss: 0.0236 - val_loss: 0.0286\n",
      "perc99SubjectF1andFold3\n",
      "189956\n",
      "62411\n",
      "Train on 169215 samples, validate on 55520 samples\n",
      "Epoch 1/100\n",
      "169215/169215 [==============================] - 15s 86us/step - loss: 0.0557 - val_loss: 0.0430\n",
      "Epoch 2/100\n",
      "169215/169215 [==============================] - 13s 77us/step - loss: 0.0457 - val_loss: 0.0403\n",
      "Epoch 3/100\n",
      "169215/169215 [==============================] - 13s 77us/step - loss: 0.0433 - val_loss: 0.0408\n",
      "Epoch 4/100\n",
      "169215/169215 [==============================] - 16s 96us/step - loss: 0.0418 - val_loss: 0.0397\n",
      "Epoch 5/100\n",
      "169215/169215 [==============================] - 16s 94us/step - loss: 0.0406 - val_loss: 0.0391\n",
      "Epoch 6/100\n",
      "169215/169215 [==============================] - 16s 94us/step - loss: 0.0396 - val_loss: 0.0368\n",
      "Epoch 7/100\n",
      "169215/169215 [==============================] - 16s 95us/step - loss: 0.0388 - val_loss: 0.0365\n",
      "Epoch 8/100\n",
      "169215/169215 [==============================] - 16s 93us/step - loss: 0.0381 - val_loss: 0.0362\n",
      "Epoch 9/100\n",
      "169215/169215 [==============================] - 15s 89us/step - loss: 0.0375 - val_loss: 0.0356\n",
      "Epoch 10/100\n",
      "169215/169215 [==============================] - 15s 90us/step - loss: 0.0370 - val_loss: 0.0352\n",
      "Epoch 11/100\n",
      "169215/169215 [==============================] - 16s 95us/step - loss: 0.0364 - val_loss: 0.0360\n",
      "Epoch 12/100\n",
      "169215/169215 [==============================] - 15s 89us/step - loss: 0.0360 - val_loss: 0.0353\n",
      "Epoch 13/100\n",
      "169215/169215 [==============================] - 15s 91us/step - loss: 0.0357 - val_loss: 0.0347\n",
      "Epoch 14/100\n",
      "169215/169215 [==============================] - 15s 90us/step - loss: 0.0353 - val_loss: 0.0334\n",
      "Epoch 15/100\n",
      "169215/169215 [==============================] - 15s 91us/step - loss: 0.0348 - val_loss: 0.0333\n",
      "Epoch 16/100\n",
      "169215/169215 [==============================] - 15s 90us/step - loss: 0.0345 - val_loss: 0.0351\n",
      "Epoch 17/100\n",
      "169215/169215 [==============================] - 15s 91us/step - loss: 0.0343 - val_loss: 0.0335\n",
      "Epoch 18/100\n",
      "169215/169215 [==============================] - 15s 91us/step - loss: 0.0338 - val_loss: 0.0334\n",
      "Epoch 19/100\n",
      "169215/169215 [==============================] - 16s 92us/step - loss: 0.0338 - val_loss: 0.0330\n",
      "Epoch 20/100\n",
      "169215/169215 [==============================] - 16s 94us/step - loss: 0.0334 - val_loss: 0.0341\n",
      "Epoch 21/100\n",
      "169215/169215 [==============================] - 16s 95us/step - loss: 0.0333 - val_loss: 0.0314\n",
      "Epoch 22/100\n",
      "169215/169215 [==============================] - 16s 93us/step - loss: 0.0330 - val_loss: 0.0342\n",
      "Epoch 23/100\n",
      "169215/169215 [==============================] - 16s 94us/step - loss: 0.0328 - val_loss: 0.0321\n",
      "Epoch 24/100\n",
      "169215/169215 [==============================] - 16s 94us/step - loss: 0.0325 - val_loss: 0.0321\n",
      "Epoch 25/100\n",
      "169215/169215 [==============================] - 16s 92us/step - loss: 0.0324 - val_loss: 0.0320\n",
      "perc99SubjectF1andFold4\n",
      "190603\n",
      "64006\n",
      "Train on 94769 samples, validate on 31363 samples\n",
      "Epoch 1/100\n",
      "94769/94769 [==============================] - 10s 105us/step - loss: 0.0596 - val_loss: 0.0487\n",
      "Epoch 2/100\n",
      "94769/94769 [==============================] - 9s 91us/step - loss: 0.0450 - val_loss: 0.0444\n",
      "Epoch 3/100\n",
      "94769/94769 [==============================] - 9s 93us/step - loss: 0.0408 - val_loss: 0.0417\n",
      "Epoch 4/100\n",
      "94769/94769 [==============================] - 9s 92us/step - loss: 0.0386 - val_loss: 0.0413\n",
      "Epoch 5/100\n",
      "94769/94769 [==============================] - 9s 91us/step - loss: 0.0369 - val_loss: 0.0391\n",
      "Epoch 6/100\n",
      "94769/94769 [==============================] - 9s 93us/step - loss: 0.0357 - val_loss: 0.0366\n",
      "Epoch 7/100\n",
      "94769/94769 [==============================] - 9s 93us/step - loss: 0.0346 - val_loss: 0.0360\n",
      "Epoch 8/100\n",
      "94769/94769 [==============================] - 9s 90us/step - loss: 0.0337 - val_loss: 0.0352\n",
      "Epoch 9/100\n",
      "94769/94769 [==============================] - 9s 91us/step - loss: 0.0329 - val_loss: 0.0348\n",
      "Epoch 10/100\n",
      "94769/94769 [==============================] - 9s 92us/step - loss: 0.0322 - val_loss: 0.0341\n",
      "Epoch 11/100\n",
      "94769/94769 [==============================] - 9s 92us/step - loss: 0.0318 - val_loss: 0.0339\n",
      "Epoch 12/100\n",
      "94769/94769 [==============================] - 9s 91us/step - loss: 0.0313 - val_loss: 0.0336\n",
      "Epoch 13/100\n",
      "94769/94769 [==============================] - 9s 91us/step - loss: 0.0306 - val_loss: 0.0321\n",
      "Epoch 14/100\n",
      "94769/94769 [==============================] - 9s 91us/step - loss: 0.0304 - val_loss: 0.0322\n",
      "Epoch 15/100\n",
      "94769/94769 [==============================] - 8s 90us/step - loss: 0.0299 - val_loss: 0.0337\n",
      "Epoch 16/100\n",
      "94769/94769 [==============================] - 8s 88us/step - loss: 0.0295 - val_loss: 0.0322\n",
      "Epoch 17/100\n",
      "94769/94769 [==============================] - 8s 86us/step - loss: 0.0292 - val_loss: 0.0347\n",
      "perc99SubjectF2andFold1\n",
      "199237\n",
      "64180\n",
      "Train on 122419 samples, validate on 39581 samples\n",
      "Epoch 1/100\n",
      "122419/122419 [==============================] - 13s 107us/step - loss: 0.0527 - val_loss: 0.0415\n",
      "Epoch 2/100\n",
      "122419/122419 [==============================] - 11s 92us/step - loss: 0.0420 - val_loss: 0.0408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      "122419/122419 [==============================] - 11s 90us/step - loss: 0.0404 - val_loss: 0.0386\n",
      "Epoch 4/100\n",
      "122419/122419 [==============================] - 11s 92us/step - loss: 0.0397 - val_loss: 0.0396\n",
      "Epoch 5/100\n",
      "122419/122419 [==============================] - 11s 90us/step - loss: 0.0388 - val_loss: 0.0374\n",
      "Epoch 6/100\n",
      "122419/122419 [==============================] - 11s 89us/step - loss: 0.0384 - val_loss: 0.0383\n",
      "Epoch 7/100\n",
      "122419/122419 [==============================] - 11s 93us/step - loss: 0.0376 - val_loss: 0.0367\n",
      "Epoch 8/100\n",
      "122419/122419 [==============================] - 12s 95us/step - loss: 0.0371 - val_loss: 0.0361\n",
      "Epoch 9/100\n",
      "122419/122419 [==============================] - 11s 91us/step - loss: 0.0364 - val_loss: 0.0355\n",
      "Epoch 10/100\n",
      "122419/122419 [==============================] - 12s 95us/step - loss: 0.0358 - val_loss: 0.0348\n",
      "Epoch 11/100\n",
      "122419/122419 [==============================] - 12s 96us/step - loss: 0.0352 - val_loss: 0.0344\n",
      "Epoch 12/100\n",
      "122419/122419 [==============================] - 12s 99us/step - loss: 0.0347 - val_loss: 0.0344\n",
      "Epoch 13/100\n",
      "122419/122419 [==============================] - 12s 97us/step - loss: 0.0342 - val_loss: 0.0336\n",
      "Epoch 14/100\n",
      "122419/122419 [==============================] - 12s 99us/step - loss: 0.0339 - val_loss: 0.0330\n",
      "Epoch 15/100\n",
      "122419/122419 [==============================] - 12s 95us/step - loss: 0.0334 - val_loss: 0.0330\n",
      "Epoch 16/100\n",
      "122419/122419 [==============================] - 11s 93us/step - loss: 0.0332 - val_loss: 0.0329\n",
      "Epoch 17/100\n",
      "122419/122419 [==============================] - 11s 90us/step - loss: 0.0330 - val_loss: 0.0329\n",
      "Epoch 18/100\n",
      "122419/122419 [==============================] - 11s 88us/step - loss: 0.0326 - val_loss: 0.0326\n",
      "Epoch 19/100\n",
      "122419/122419 [==============================] - 11s 89us/step - loss: 0.0326 - val_loss: 0.0323\n",
      "Epoch 20/100\n",
      "122419/122419 [==============================] - 11s 92us/step - loss: 0.0322 - val_loss: 0.0323\n",
      "Epoch 21/100\n",
      "122419/122419 [==============================] - 12s 95us/step - loss: 0.0322 - val_loss: 0.0320\n",
      "Epoch 22/100\n",
      "122419/122419 [==============================] - 11s 94us/step - loss: 0.0319 - val_loss: 0.0318\n",
      "Epoch 23/100\n",
      "122419/122419 [==============================] - 11s 92us/step - loss: 0.0318 - val_loss: 0.0319\n",
      "Epoch 24/100\n",
      "122419/122419 [==============================] - 11s 92us/step - loss: 0.0316 - val_loss: 0.0313\n",
      "Epoch 25/100\n",
      "122419/122419 [==============================] - 11s 91us/step - loss: 0.0315 - val_loss: 0.0319\n",
      "Epoch 26/100\n",
      "122419/122419 [==============================] - 11s 92us/step - loss: 0.0312 - val_loss: 0.0319\n",
      "Epoch 27/100\n",
      "122419/122419 [==============================] - 12s 98us/step - loss: 0.0312 - val_loss: 0.0314\n",
      "Epoch 28/100\n",
      "122419/122419 [==============================] - 11s 88us/step - loss: 0.0310 - val_loss: 0.0320\n",
      "perc99SubjectF2andFold2\n",
      "269222\n",
      "91723\n",
      "Train on 163143 samples, validate on 56341 samples\n",
      "Epoch 1/100\n",
      "163143/163143 [==============================] - 17s 107us/step - loss: 0.0488 - val_loss: 0.0379\n",
      "Epoch 2/100\n",
      "163143/163143 [==============================] - 16s 95us/step - loss: 0.0393 - val_loss: 0.0368\n",
      "Epoch 3/100\n",
      "163143/163143 [==============================] - 16s 95us/step - loss: 0.0380 - val_loss: 0.0354\n",
      "Epoch 4/100\n",
      "163143/163143 [==============================] - 16s 97us/step - loss: 0.0371 - val_loss: 0.0352\n",
      "Epoch 5/100\n",
      "163143/163143 [==============================] - 15s 93us/step - loss: 0.0364 - val_loss: 0.0340\n",
      "Epoch 6/100\n",
      "163143/163143 [==============================] - 16s 97us/step - loss: 0.0357 - val_loss: 0.0343\n",
      "Epoch 7/100\n",
      "163143/163143 [==============================] - 15s 95us/step - loss: 0.0351 - val_loss: 0.0339\n",
      "Epoch 8/100\n",
      "163143/163143 [==============================] - 16s 97us/step - loss: 0.0343 - val_loss: 0.0337\n",
      "Epoch 9/100\n",
      "163143/163143 [==============================] - 15s 94us/step - loss: 0.0338 - val_loss: 0.0323\n",
      "Epoch 10/100\n",
      "163143/163143 [==============================] - 16s 96us/step - loss: 0.0333 - val_loss: 0.0324\n",
      "Epoch 11/100\n",
      "163143/163143 [==============================] - 16s 95us/step - loss: 0.0328 - val_loss: 0.0310\n",
      "Epoch 12/100\n",
      "163143/163143 [==============================] - 16s 99us/step - loss: 0.0323 - val_loss: 0.0309\n",
      "Epoch 13/100\n",
      "163143/163143 [==============================] - 15s 92us/step - loss: 0.0318 - val_loss: 0.0311\n",
      "Epoch 14/100\n",
      "163143/163143 [==============================] - 16s 99us/step - loss: 0.0315 - val_loss: 0.0301\n",
      "Epoch 15/100\n",
      "163143/163143 [==============================] - 17s 104us/step - loss: 0.0311 - val_loss: 0.0304\n",
      "Epoch 16/100\n",
      "163143/163143 [==============================] - 17s 105us/step - loss: 0.0308 - val_loss: 0.0300\n",
      "Epoch 17/100\n",
      "163143/163143 [==============================] - 16s 100us/step - loss: 0.0306 - val_loss: 0.0298\n",
      "Epoch 18/100\n",
      "163143/163143 [==============================] - 15s 94us/step - loss: 0.0303 - val_loss: 0.0298\n",
      "Epoch 19/100\n",
      "163143/163143 [==============================] - 15s 93us/step - loss: 0.0300 - val_loss: 0.0295\n",
      "Epoch 20/100\n",
      "163143/163143 [==============================] - 15s 91us/step - loss: 0.0299 - val_loss: 0.0299\n",
      "Epoch 21/100\n",
      "163143/163143 [==============================] - 16s 96us/step - loss: 0.0296 - val_loss: 0.0291\n",
      "Epoch 22/100\n",
      "163143/163143 [==============================] - 15s 94us/step - loss: 0.0293 - val_loss: 0.0288\n",
      "Epoch 23/100\n",
      "163143/163143 [==============================] - 20s 122us/step - loss: 0.0293 - val_loss: 0.0286\n",
      "Epoch 24/100\n",
      "163143/163143 [==============================] - 17s 105us/step - loss: 0.0291 - val_loss: 0.0290\n",
      "Epoch 25/100\n",
      "163143/163143 [==============================] - 16s 96us/step - loss: 0.0289 - val_loss: 0.0287\n",
      "Epoch 26/100\n",
      "163143/163143 [==============================] - 16s 98us/step - loss: 0.0288 - val_loss: 0.0284\n",
      "Epoch 27/100\n",
      "163143/163143 [==============================] - 15s 91us/step - loss: 0.0286 - val_loss: 0.0280\n",
      "Epoch 28/100\n",
      "163143/163143 [==============================] - 16s 95us/step - loss: 0.0285 - val_loss: 0.0291\n",
      "Epoch 29/100\n",
      "163143/163143 [==============================] - 15s 95us/step - loss: 0.0284 - val_loss: 0.0279\n",
      "Epoch 30/100\n",
      "163143/163143 [==============================] - 16s 99us/step - loss: 0.0283 - val_loss: 0.0279\n",
      "Epoch 31/100\n",
      "163143/163143 [==============================] - 16s 96us/step - loss: 0.0281 - val_loss: 0.0277\n",
      "Epoch 32/100\n",
      "163143/163143 [==============================] - 16s 97us/step - loss: 0.0279 - val_loss: 0.0283\n",
      "Epoch 33/100\n",
      "163143/163143 [==============================] - 16s 95us/step - loss: 0.0279 - val_loss: 0.0275\n",
      "Epoch 34/100\n",
      "163143/163143 [==============================] - 16s 99us/step - loss: 0.0277 - val_loss: 0.0276\n",
      "Epoch 35/100\n",
      "163143/163143 [==============================] - 16s 97us/step - loss: 0.0277 - val_loss: 0.0276\n",
      "Epoch 36/100\n",
      "163143/163143 [==============================] - 18s 111us/step - loss: 0.0275 - val_loss: 0.0278\n",
      "Epoch 37/100\n",
      "163143/163143 [==============================] - 16s 97us/step - loss: 0.0273 - val_loss: 0.0270\n",
      "Epoch 38/100\n",
      "163143/163143 [==============================] - 16s 99us/step - loss: 0.0273 - val_loss: 0.0270\n",
      "Epoch 39/100\n",
      "163143/163143 [==============================] - 16s 96us/step - loss: 0.0272 - val_loss: 0.0269\n",
      "Epoch 40/100\n",
      "163143/163143 [==============================] - 16s 97us/step - loss: 0.0272 - val_loss: 0.0281\n",
      "Epoch 41/100\n",
      "163143/163143 [==============================] - 15s 91us/step - loss: 0.0271 - val_loss: 0.0269\n",
      "Epoch 42/100\n",
      "163143/163143 [==============================] - 16s 96us/step - loss: 0.0269 - val_loss: 0.0270\n",
      "Epoch 43/100\n",
      "163143/163143 [==============================] - 16s 99us/step - loss: 0.0269 - val_loss: 0.0272\n",
      "Epoch 44/100\n",
      "163143/163143 [==============================] - 16s 98us/step - loss: 0.0269 - val_loss: 0.0270\n",
      "Epoch 45/100\n",
      "163143/163143 [==============================] - 17s 101us/step - loss: 0.0267 - val_loss: 0.0270\n",
      "perc99SubjectF2andFold3\n",
      "191822\n",
      "62116\n",
      "Train on 118780 samples, validate on 38183 samples\n",
      "Epoch 1/100\n",
      "118780/118780 [==============================] - 13s 107us/step - loss: 0.0561 - val_loss: 0.0407\n",
      "Epoch 2/100\n",
      "118780/118780 [==============================] - 11s 89us/step - loss: 0.0456 - val_loss: 0.0389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      "118780/118780 [==============================] - 11s 90us/step - loss: 0.0437 - val_loss: 0.0385\n",
      "Epoch 4/100\n",
      "118780/118780 [==============================] - 10s 88us/step - loss: 0.0427 - val_loss: 0.0411\n",
      "Epoch 5/100\n",
      "118780/118780 [==============================] - 10s 87us/step - loss: 0.0420 - val_loss: 0.0380\n",
      "Epoch 6/100\n",
      "118780/118780 [==============================] - 10s 86us/step - loss: 0.0416 - val_loss: 0.0372\n",
      "Epoch 7/100\n",
      "118780/118780 [==============================] - 10s 84us/step - loss: 0.0409 - val_loss: 0.0363\n",
      "Epoch 8/100\n",
      "118780/118780 [==============================] - 10s 87us/step - loss: 0.0405 - val_loss: 0.0360\n",
      "Epoch 9/100\n",
      "118780/118780 [==============================] - 10s 88us/step - loss: 0.0401 - val_loss: 0.0358\n",
      "Epoch 10/100\n",
      "118780/118780 [==============================] - 10s 87us/step - loss: 0.0396 - val_loss: 0.0346\n",
      "Epoch 11/100\n",
      "118780/118780 [==============================] - 10s 88us/step - loss: 0.0393 - val_loss: 0.0350\n",
      "Epoch 12/100\n",
      "118780/118780 [==============================] - 11s 90us/step - loss: 0.0390 - val_loss: 0.0347\n",
      "Epoch 13/100\n",
      "118780/118780 [==============================] - 12s 102us/step - loss: 0.0385 - val_loss: 0.0360\n",
      "Epoch 14/100\n",
      "118780/118780 [==============================] - 12s 100us/step - loss: 0.0382 - val_loss: 0.0342\n",
      "Epoch 15/100\n",
      "118780/118780 [==============================] - 12s 100us/step - loss: 0.0379 - val_loss: 0.0348\n",
      "Epoch 16/100\n",
      "118780/118780 [==============================] - 11s 96us/step - loss: 0.0376 - val_loss: 0.0333\n",
      "Epoch 17/100\n",
      "118780/118780 [==============================] - 12s 99us/step - loss: 0.0373 - val_loss: 0.0328\n",
      "Epoch 18/100\n",
      "118780/118780 [==============================] - 11s 94us/step - loss: 0.0371 - val_loss: 0.0337\n",
      "Epoch 19/100\n",
      "118780/118780 [==============================] - 11s 95us/step - loss: 0.0369 - val_loss: 0.0324\n",
      "Epoch 20/100\n",
      "118780/118780 [==============================] - 11s 96us/step - loss: 0.0366 - val_loss: 0.0326\n",
      "Epoch 21/100\n",
      "118780/118780 [==============================] - 12s 97us/step - loss: 0.0365 - val_loss: 0.0328\n",
      "Epoch 22/100\n",
      "118780/118780 [==============================] - 12s 98us/step - loss: 0.0363 - val_loss: 0.0332\n",
      "Epoch 23/100\n",
      "118780/118780 [==============================] - 12s 98us/step - loss: 0.0362 - val_loss: 0.0326\n",
      "perc99SubjectF2andFold4\n",
      "207291\n",
      "71096\n",
      "Train on 122857 samples, validate on 41356 samples\n",
      "Epoch 1/100\n",
      "122857/122857 [==============================] - 16s 128us/step - loss: 0.0519 - val_loss: 0.0410\n",
      "Epoch 2/100\n",
      "122857/122857 [==============================] - 13s 106us/step - loss: 0.0383 - val_loss: 0.0391\n",
      "Epoch 3/100\n",
      "122857/122857 [==============================] - 13s 106us/step - loss: 0.0366 - val_loss: 0.0384\n",
      "Epoch 4/100\n",
      "122857/122857 [==============================] - 14s 110us/step - loss: 0.0355 - val_loss: 0.0372\n",
      "Epoch 5/100\n",
      "122857/122857 [==============================] - 14s 112us/step - loss: 0.0349 - val_loss: 0.0367\n",
      "Epoch 6/100\n",
      "122857/122857 [==============================] - 13s 110us/step - loss: 0.0341 - val_loss: 0.0363\n",
      "Epoch 7/100\n",
      "122857/122857 [==============================] - 13s 109us/step - loss: 0.0334 - val_loss: 0.0355\n",
      "Epoch 8/100\n",
      "122857/122857 [==============================] - 13s 107us/step - loss: 0.0327 - val_loss: 0.0341\n",
      "Epoch 9/100\n",
      "122857/122857 [==============================] - 13s 107us/step - loss: 0.0321 - val_loss: 0.0352\n",
      "Epoch 10/100\n",
      "122857/122857 [==============================] - 14s 113us/step - loss: 0.0317 - val_loss: 0.0344\n",
      "Epoch 11/100\n",
      "122857/122857 [==============================] - 14s 114us/step - loss: 0.0313 - val_loss: 0.0349\n",
      "Epoch 12/100\n",
      "122857/122857 [==============================] - 14s 114us/step - loss: 0.0308 - val_loss: 0.0340\n",
      "Epoch 13/100\n",
      "122857/122857 [==============================] - 14s 112us/step - loss: 0.0304 - val_loss: 0.0333\n",
      "Epoch 14/100\n",
      "122857/122857 [==============================] - 13s 109us/step - loss: 0.0302 - val_loss: 0.0327\n",
      "Epoch 15/100\n",
      "122857/122857 [==============================] - 14s 111us/step - loss: 0.0296 - val_loss: 0.0326\n",
      "Epoch 16/100\n",
      "122857/122857 [==============================] - 14s 114us/step - loss: 0.0294 - val_loss: 0.0322\n",
      "Epoch 17/100\n",
      "122857/122857 [==============================] - 14s 110us/step - loss: 0.0294 - val_loss: 0.0320TA: 0s \n",
      "Epoch 18/100\n",
      "122857/122857 [==============================] - 13s 110us/step - loss: 0.0290 - val_loss: 0.0318\n",
      "Epoch 19/100\n",
      "122857/122857 [==============================] - 13s 109us/step - loss: 0.0288 - val_loss: 0.0319\n",
      "Epoch 20/100\n",
      "122857/122857 [==============================] - 13s 107us/step - loss: 0.0286 - val_loss: 0.0324\n",
      "Epoch 21/100\n",
      "122857/122857 [==============================] - 13s 110us/step - loss: 0.0282 - val_loss: 0.0316\n",
      "Epoch 22/100\n",
      "122857/122857 [==============================] - 13s 110us/step - loss: 0.0281 - val_loss: 0.0324\n",
      "Epoch 23/100\n",
      "122857/122857 [==============================] - 14s 111us/step - loss: 0.0279 - val_loss: 0.0307\n",
      "Epoch 24/100\n",
      "122857/122857 [==============================] - 14s 112us/step - loss: 0.0277 - val_loss: 0.0313\n",
      "Epoch 25/100\n",
      "122857/122857 [==============================] - 13s 107us/step - loss: 0.0276 - val_loss: 0.0312\n",
      "Epoch 26/100\n",
      "122857/122857 [==============================] - 14s 110us/step - loss: 0.0275 - val_loss: 0.0317\n",
      "Epoch 27/100\n",
      "122857/122857 [==============================] - 14s 111us/step - loss: 0.0272 - val_loss: 0.0300\n",
      "Epoch 28/100\n",
      "122857/122857 [==============================] - 14s 110us/step - loss: 0.0272 - val_loss: 0.0308\n",
      "Epoch 29/100\n",
      "122857/122857 [==============================] - 14s 110us/step - loss: 0.0270 - val_loss: 0.0307\n",
      "Epoch 30/100\n",
      "122857/122857 [==============================] - 14s 112us/step - loss: 0.0269 - val_loss: 0.0308\n",
      "Epoch 31/100\n",
      "122857/122857 [==============================] - 13s 109us/step - loss: 0.0268 - val_loss: 0.0311\n",
      "perc99SubjectM1andFold1\n",
      "264015\n",
      "88370\n",
      "Train on 222741 samples, validate on 75072 samples\n",
      "Epoch 1/100\n",
      "222741/222741 [==============================] - 24s 108us/step - loss: 0.0542 - val_loss: 0.0469\n",
      "Epoch 2/100\n",
      "222741/222741 [==============================] - 21s 96us/step - loss: 0.0452 - val_loss: 0.0432\n",
      "Epoch 3/100\n",
      "222741/222741 [==============================] - 22s 98us/step - loss: 0.0432 - val_loss: 0.0448\n",
      "Epoch 4/100\n",
      "222741/222741 [==============================] - 22s 99us/step - loss: 0.0418 - val_loss: 0.0401\n",
      "Epoch 5/100\n",
      "222741/222741 [==============================] - 22s 97us/step - loss: 0.0406 - val_loss: 0.0387\n",
      "Epoch 6/100\n",
      "222741/222741 [==============================] - 21s 94us/step - loss: 0.0399 - val_loss: 0.0389\n",
      "Epoch 7/100\n",
      "222741/222741 [==============================] - 22s 98us/step - loss: 0.0390 - val_loss: 0.0386\n",
      "Epoch 8/100\n",
      "222741/222741 [==============================] - 22s 99us/step - loss: 0.0384 - val_loss: 0.0366\n",
      "Epoch 9/100\n",
      "222741/222741 [==============================] - 22s 101us/step - loss: 0.0377 - val_loss: 0.0365\n",
      "Epoch 10/100\n",
      "222741/222741 [==============================] - 22s 100us/step - loss: 0.0373 - val_loss: 0.0365\n",
      "Epoch 11/100\n",
      "222741/222741 [==============================] - 21s 95us/step - loss: 0.0368 - val_loss: 0.0357\n",
      "Epoch 12/100\n",
      "222741/222741 [==============================] - 22s 97us/step - loss: 0.0362 - val_loss: 0.0353\n",
      "Epoch 13/100\n",
      "222741/222741 [==============================] - 22s 97us/step - loss: 0.0359 - val_loss: 0.0362\n",
      "Epoch 14/100\n",
      "222741/222741 [==============================] - 21s 95us/step - loss: 0.0356 - val_loss: 0.0351\n",
      "Epoch 15/100\n",
      "222741/222741 [==============================] - 22s 97us/step - loss: 0.0352 - val_loss: 0.0343\n",
      "Epoch 16/100\n",
      "222741/222741 [==============================] - 21s 94us/step - loss: 0.0349 - val_loss: 0.0341\n",
      "Epoch 17/100\n",
      "222741/222741 [==============================] - 21s 96us/step - loss: 0.0346 - val_loss: 0.0340\n",
      "Epoch 18/100\n",
      "222741/222741 [==============================] - 21s 95us/step - loss: 0.0344 - val_loss: 0.0339\n",
      "Epoch 19/100\n",
      "222741/222741 [==============================] - 22s 97us/step - loss: 0.0341 - val_loss: 0.0340\n",
      "Epoch 20/100\n",
      "222741/222741 [==============================] - 22s 99us/step - loss: 0.0338 - val_loss: 0.0335\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222741/222741 [==============================] - 23s 101us/step - loss: 0.0336 - val_loss: 0.0334\n",
      "Epoch 22/100\n",
      "222741/222741 [==============================] - 20s 91us/step - loss: 0.0334 - val_loss: 0.0327\n",
      "Epoch 23/100\n",
      "222741/222741 [==============================] - 22s 100us/step - loss: 0.0332 - val_loss: 0.0324\n",
      "Epoch 24/100\n",
      "222741/222741 [==============================] - 22s 99us/step - loss: 0.0330 - val_loss: 0.0320\n",
      "Epoch 25/100\n",
      "222741/222741 [==============================] - 22s 98us/step - loss: 0.0329 - val_loss: 0.0326\n",
      "Epoch 26/100\n",
      "222741/222741 [==============================] - 22s 101us/step - loss: 0.0327 - val_loss: 0.0325\n",
      "Epoch 27/100\n",
      "222741/222741 [==============================] - 22s 98us/step - loss: 0.0326 - val_loss: 0.0325\n",
      "Epoch 28/100\n",
      "222741/222741 [==============================] - 24s 108us/step - loss: 0.0324 - val_loss: 0.0316\n",
      "Epoch 29/100\n",
      "222741/222741 [==============================] - 23s 105us/step - loss: 0.0322 - val_loss: 0.0316\n",
      "Epoch 30/100\n",
      "222741/222741 [==============================] - 23s 105us/step - loss: 0.0320 - val_loss: 0.0323\n",
      "Epoch 31/100\n",
      "222741/222741 [==============================] - 23s 103us/step - loss: 0.0320 - val_loss: 0.0319\n",
      "Epoch 32/100\n",
      "222741/222741 [==============================] - 23s 105us/step - loss: 0.0319 - val_loss: 0.0313\n",
      "Epoch 33/100\n",
      "222741/222741 [==============================] - 23s 103us/step - loss: 0.0317 - val_loss: 0.0320\n",
      "Epoch 34/100\n",
      "222741/222741 [==============================] - 24s 106us/step - loss: 0.0317 - val_loss: 0.0313\n",
      "Epoch 35/100\n",
      "222741/222741 [==============================] - 23s 105us/step - loss: 0.0315 - val_loss: 0.0309\n",
      "Epoch 36/100\n",
      "222741/222741 [==============================] - 23s 103us/step - loss: 0.0313 - val_loss: 0.0311\n",
      "Epoch 37/100\n",
      "222741/222741 [==============================] - 23s 105us/step - loss: 0.0313 - val_loss: 0.0305\n",
      "Epoch 38/100\n",
      "222741/222741 [==============================] - 23s 104us/step - loss: 0.0311 - val_loss: 0.0304\n",
      "Epoch 39/100\n",
      "222741/222741 [==============================] - 23s 102us/step - loss: 0.0311 - val_loss: 0.0307\n",
      "Epoch 40/100\n",
      "222741/222741 [==============================] - 23s 105us/step - loss: 0.0309 - val_loss: 0.0309\n",
      "Epoch 41/100\n",
      "222741/222741 [==============================] - 23s 105us/step - loss: 0.0309 - val_loss: 0.0306\n",
      "Epoch 42/100\n",
      "222741/222741 [==============================] - 23s 104us/step - loss: 0.0307 - val_loss: 0.0305\n",
      "perc99SubjectM1andFold2\n",
      "273351\n",
      "90709\n",
      "Train on 117212 samples, validate on 37687 samples\n",
      "Epoch 1/100\n",
      "117212/117212 [==============================] - 14s 119us/step - loss: 0.0564 - val_loss: 0.0399\n",
      "Epoch 2/100\n",
      "117212/117212 [==============================] - 12s 103us/step - loss: 0.0414 - val_loss: 0.0401\n",
      "Epoch 3/100\n",
      "117212/117212 [==============================] - 13s 108us/step - loss: 0.0385 - val_loss: 0.0359\n",
      "Epoch 4/100\n",
      "117212/117212 [==============================] - 12s 103us/step - loss: 0.0365 - val_loss: 0.0363\n",
      "Epoch 5/100\n",
      "117212/117212 [==============================] - 12s 106us/step - loss: 0.0350 - val_loss: 0.0323\n",
      "Epoch 6/100\n",
      "117212/117212 [==============================] - 12s 99us/step - loss: 0.0336 - val_loss: 0.0310\n",
      "Epoch 7/100\n",
      "117212/117212 [==============================] - 12s 99us/step - loss: 0.0324 - val_loss: 0.0300\n",
      "Epoch 8/100\n",
      "117212/117212 [==============================] - 12s 99us/step - loss: 0.0315 - val_loss: 0.0305\n",
      "Epoch 9/100\n",
      "117212/117212 [==============================] - 12s 104us/step - loss: 0.0309 - val_loss: 0.0289\n",
      "Epoch 10/100\n",
      "117212/117212 [==============================] - 12s 104us/step - loss: 0.0303 - val_loss: 0.0288\n",
      "Epoch 11/100\n",
      "117212/117212 [==============================] - 12s 104us/step - loss: 0.0298 - val_loss: 0.0297\n",
      "Epoch 12/100\n",
      "117212/117212 [==============================] - 12s 103us/step - loss: 0.0291 - val_loss: 0.0275\n",
      "Epoch 13/100\n",
      "117212/117212 [==============================] - 12s 103us/step - loss: 0.0288 - val_loss: 0.0276\n",
      "Epoch 14/100\n",
      "117212/117212 [==============================] - 12s 103us/step - loss: 0.0284 - val_loss: 0.0270\n",
      "Epoch 15/100\n",
      "117212/117212 [==============================] - 12s 102us/step - loss: 0.0279 - val_loss: 0.0264\n",
      "Epoch 16/100\n",
      "117212/117212 [==============================] - 12s 106us/step - loss: 0.0275 - val_loss: 0.0261\n",
      "Epoch 17/100\n",
      "117212/117212 [==============================] - 13s 110us/step - loss: 0.0272 - val_loss: 0.0262\n",
      "Epoch 18/100\n",
      "117212/117212 [==============================] - 12s 103us/step - loss: 0.0268 - val_loss: 0.0259\n",
      "Epoch 19/100\n",
      "117212/117212 [==============================] - 12s 103us/step - loss: 0.0266 - val_loss: 0.0254\n",
      "Epoch 20/100\n",
      "117212/117212 [==============================] - 12s 102us/step - loss: 0.0264 - val_loss: 0.0254\n",
      "Epoch 21/100\n",
      "117212/117212 [==============================] - 12s 103us/step - loss: 0.0260 - val_loss: 0.0247\n",
      "Epoch 22/100\n",
      "117212/117212 [==============================] - 12s 105us/step - loss: 0.0257 - val_loss: 0.0258\n",
      "Epoch 23/100\n",
      "117212/117212 [==============================] - 12s 104us/step - loss: 0.0255 - val_loss: 0.0251\n",
      "Epoch 24/100\n",
      "117212/117212 [==============================] - 12s 106us/step - loss: 0.0253 - val_loss: 0.0243\n",
      "Epoch 25/100\n",
      "117212/117212 [==============================] - 12s 104us/step - loss: 0.0252 - val_loss: 0.0239\n",
      "Epoch 26/100\n",
      "117212/117212 [==============================] - 12s 105us/step - loss: 0.0251 - val_loss: 0.0244\n",
      "Epoch 27/100\n",
      "117212/117212 [==============================] - 12s 102us/step - loss: 0.0249 - val_loss: 0.0240\n",
      "Epoch 28/100\n",
      "117212/117212 [==============================] - 12s 102us/step - loss: 0.0247 - val_loss: 0.0244\n",
      "Epoch 29/100\n",
      "117212/117212 [==============================] - 12s 102us/step - loss: 0.0245 - val_loss: 0.0242\n",
      "perc99SubjectM1andFold3\n",
      "230512\n",
      "75922\n",
      "Train on 142924 samples, validate on 44573 samples\n",
      "Epoch 1/100\n",
      "142924/142924 [==============================] - 17s 122us/step - loss: 0.0541 - val_loss: 0.0359\n",
      "Epoch 2/100\n",
      "142924/142924 [==============================] - 15s 104us/step - loss: 0.0414 - val_loss: 0.0325\n",
      "Epoch 3/100\n",
      "142924/142924 [==============================] - 15s 102us/step - loss: 0.0392 - val_loss: 0.0315\n",
      "Epoch 4/100\n",
      "142924/142924 [==============================] - 15s 103us/step - loss: 0.0375 - val_loss: 0.0299\n",
      "Epoch 5/100\n",
      "142924/142924 [==============================] - 15s 105us/step - loss: 0.0365 - val_loss: 0.0292\n",
      "Epoch 6/100\n",
      "142924/142924 [==============================] - 15s 105us/step - loss: 0.0356 - val_loss: 0.0279\n",
      "Epoch 7/100\n",
      "142924/142924 [==============================] - 15s 105us/step - loss: 0.0348 - val_loss: 0.0279\n",
      "Epoch 8/100\n",
      "142924/142924 [==============================] - 15s 103us/step - loss: 0.0342 - val_loss: 0.0286\n",
      "Epoch 9/100\n",
      "142924/142924 [==============================] - 15s 106us/step - loss: 0.0335 - val_loss: 0.0277\n",
      "Epoch 10/100\n",
      "142924/142924 [==============================] - 15s 104us/step - loss: 0.0329 - val_loss: 0.0265\n",
      "Epoch 11/100\n",
      "142924/142924 [==============================] - 15s 105us/step - loss: 0.0325 - val_loss: 0.0271\n",
      "Epoch 12/100\n",
      "142924/142924 [==============================] - 15s 105us/step - loss: 0.0321 - val_loss: 0.0263\n",
      "Epoch 13/100\n",
      "142924/142924 [==============================] - 15s 105us/step - loss: 0.0318 - val_loss: 0.0265\n",
      "Epoch 14/100\n",
      "142924/142924 [==============================] - 15s 104us/step - loss: 0.0315 - val_loss: 0.0263\n",
      "Epoch 15/100\n",
      "142924/142924 [==============================] - 15s 106us/step - loss: 0.0312 - val_loss: 0.0259\n",
      "Epoch 16/100\n",
      "142924/142924 [==============================] - 15s 104us/step - loss: 0.0309 - val_loss: 0.0249\n",
      "Epoch 17/100\n",
      "142924/142924 [==============================] - 15s 106us/step - loss: 0.0308 - val_loss: 0.0267\n",
      "Epoch 18/100\n",
      "142924/142924 [==============================] - 15s 106us/step - loss: 0.0306 - val_loss: 0.0260\n",
      "Epoch 19/100\n",
      "142924/142924 [==============================] - 15s 105us/step - loss: 0.0303 - val_loss: 0.0256\n",
      "Epoch 20/100\n",
      "142924/142924 [==============================] - 16s 109us/step - loss: 0.0302 - val_loss: 0.0246\n",
      "Epoch 21/100\n",
      "142924/142924 [==============================] - 16s 108us/step - loss: 0.0298 - val_loss: 0.0250\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142924/142924 [==============================] - 15s 106us/step - loss: 0.0298 - val_loss: 0.0253\n",
      "Epoch 23/100\n",
      "142924/142924 [==============================] - 14s 100us/step - loss: 0.0297 - val_loss: 0.0250\n",
      "Epoch 24/100\n",
      "142924/142924 [==============================] - 15s 102us/step - loss: 0.0294 - val_loss: 0.0263\n",
      "perc99SubjectM1andFold4\n",
      "276811\n",
      "91838\n",
      "Train on 155221 samples, validate on 50299 samples\n",
      "Epoch 1/100\n",
      "155221/155221 [==============================] - 18s 118us/step - loss: 0.0466 - val_loss: 0.0348\n",
      "Epoch 2/100\n",
      "155221/155221 [==============================] - 16s 104us/step - loss: 0.0354 - val_loss: 0.0319\n",
      "Epoch 3/100\n",
      "155221/155221 [==============================] - 16s 103us/step - loss: 0.0330 - val_loss: 0.0297\n",
      "Epoch 4/100\n",
      "155221/155221 [==============================] - 17s 108us/step - loss: 0.0313 - val_loss: 0.0296\n",
      "Epoch 5/100\n",
      "155221/155221 [==============================] - 16s 105us/step - loss: 0.0303 - val_loss: 0.0290\n",
      "Epoch 6/100\n",
      "155221/155221 [==============================] - 16s 105us/step - loss: 0.0296 - val_loss: 0.0269\n",
      "Epoch 7/100\n",
      "155221/155221 [==============================] - 16s 104us/step - loss: 0.0289 - val_loss: 0.0269\n",
      "Epoch 8/100\n",
      "155221/155221 [==============================] - 16s 104us/step - loss: 0.0283 - val_loss: 0.0262\n",
      "Epoch 9/100\n",
      "155221/155221 [==============================] - 16s 103us/step - loss: 0.0277 - val_loss: 0.0269\n",
      "Epoch 10/100\n",
      "155221/155221 [==============================] - 16s 106us/step - loss: 0.0274 - val_loss: 0.0254\n",
      "Epoch 11/100\n",
      "155221/155221 [==============================] - 16s 104us/step - loss: 0.0268 - val_loss: 0.0249\n",
      "Epoch 12/100\n",
      "155221/155221 [==============================] - 16s 101us/step - loss: 0.0266 - val_loss: 0.0246\n",
      "Epoch 13/100\n",
      "155221/155221 [==============================] - 16s 106us/step - loss: 0.0262 - val_loss: 0.0245\n",
      "Epoch 14/100\n",
      "155221/155221 [==============================] - 16s 106us/step - loss: 0.0259 - val_loss: 0.0246\n",
      "Epoch 15/100\n",
      "155221/155221 [==============================] - 16s 106us/step - loss: 0.0258 - val_loss: 0.0254\n",
      "Epoch 16/100\n",
      "155221/155221 [==============================] - 17s 109us/step - loss: 0.0256 - val_loss: 0.0248\n",
      "Epoch 17/100\n",
      "155221/155221 [==============================] - 16s 104us/step - loss: 0.0253 - val_loss: 0.0248\n",
      "perc99SubjectM2andFold1\n",
      "224815\n",
      "70646\n",
      "Train on 202162 samples, validate on 64173 samples\n",
      "Epoch 1/100\n",
      "202162/202162 [==============================] - 23s 115us/step - loss: 0.0579 - val_loss: 0.0485\n",
      "Epoch 2/100\n",
      "202162/202162 [==============================] - 20s 100us/step - loss: 0.0488 - val_loss: 0.0448\n",
      "Epoch 3/100\n",
      "202162/202162 [==============================] - 21s 104us/step - loss: 0.0462 - val_loss: 0.0433\n",
      "Epoch 4/100\n",
      "202162/202162 [==============================] - 21s 105us/step - loss: 0.0444 - val_loss: 0.0424\n",
      "Epoch 5/100\n",
      "202162/202162 [==============================] - 21s 105us/step - loss: 0.0431 - val_loss: 0.0410\n",
      "Epoch 6/100\n",
      "202162/202162 [==============================] - 21s 105us/step - loss: 0.0417 - val_loss: 0.0394\n",
      "Epoch 7/100\n",
      "202162/202162 [==============================] - 20s 97us/step - loss: 0.0408 - val_loss: 0.0389\n",
      "Epoch 8/100\n",
      "202162/202162 [==============================] - 20s 99us/step - loss: 0.0399 - val_loss: 0.0383\n",
      "Epoch 9/100\n",
      "202162/202162 [==============================] - 19s 96us/step - loss: 0.0391 - val_loss: 0.0376\n",
      "Epoch 10/100\n",
      "202162/202162 [==============================] - 19s 96us/step - loss: 0.0385 - val_loss: 0.0375\n",
      "Epoch 11/100\n",
      "202162/202162 [==============================] - 20s 98us/step - loss: 0.0379 - val_loss: 0.0366\n",
      "Epoch 12/100\n",
      "202162/202162 [==============================] - 20s 97us/step - loss: 0.0374 - val_loss: 0.0369\n",
      "Epoch 13/100\n",
      "202162/202162 [==============================] - 20s 97us/step - loss: 0.0369 - val_loss: 0.0366\n",
      "Epoch 14/100\n",
      "202162/202162 [==============================] - 19s 96us/step - loss: 0.0364 - val_loss: 0.0355\n",
      "Epoch 15/100\n",
      "202162/202162 [==============================] - 19s 93us/step - loss: 0.0362 - val_loss: 0.0349\n",
      "Epoch 16/100\n",
      "202162/202162 [==============================] - 19s 96us/step - loss: 0.0358 - val_loss: 0.0353\n",
      "Epoch 17/100\n",
      "202162/202162 [==============================] - 19s 95us/step - loss: 0.0356 - val_loss: 0.0346\n",
      "Epoch 18/100\n",
      "202162/202162 [==============================] - 19s 96us/step - loss: 0.0351 - val_loss: 0.0346\n",
      "Epoch 19/100\n",
      "202162/202162 [==============================] - 20s 100us/step - loss: 0.0350 - val_loss: 0.0346\n",
      "Epoch 20/100\n",
      "202162/202162 [==============================] - 21s 102us/step - loss: 0.0346 - val_loss: 0.0343\n",
      "Epoch 21/100\n",
      "202162/202162 [==============================] - 21s 101us/step - loss: 0.0344 - val_loss: 0.0343\n",
      "Epoch 22/100\n",
      "202162/202162 [==============================] - 21s 106us/step - loss: 0.0342 - val_loss: 0.0338\n",
      "Epoch 23/100\n",
      "202162/202162 [==============================] - 21s 105us/step - loss: 0.0341 - val_loss: 0.0339\n",
      "Epoch 24/100\n",
      "202162/202162 [==============================] - 22s 106us/step - loss: 0.0338 - val_loss: 0.0336\n",
      "Epoch 25/100\n",
      "202162/202162 [==============================] - 22s 107us/step - loss: 0.0335 - val_loss: 0.0336\n",
      "Epoch 26/100\n",
      "202162/202162 [==============================] - 21s 104us/step - loss: 0.0335 - val_loss: 0.0337\n",
      "Epoch 27/100\n",
      "202162/202162 [==============================] - 24s 117us/step - loss: 0.0333 - val_loss: 0.0327\n",
      "Epoch 28/100\n",
      "202162/202162 [==============================] - 21s 104us/step - loss: 0.0332 - val_loss: 0.0334\n",
      "Epoch 29/100\n",
      "202162/202162 [==============================] - 20s 97us/step - loss: 0.0329 - val_loss: 0.0333\n",
      "Epoch 30/100\n",
      "202162/202162 [==============================] - 20s 97us/step - loss: 0.0329 - val_loss: 0.0338\n",
      "Epoch 31/100\n",
      "202162/202162 [==============================] - 20s 99us/step - loss: 0.0328 - val_loss: 0.0327\n",
      "perc99SubjectM2andFold2\n",
      "265957\n",
      "89573\n",
      "Train on 166481 samples, validate on 54568 samples\n",
      "Epoch 1/100\n",
      "166481/166481 [==============================] - 19s 116us/step - loss: 0.0512 - val_loss: 0.0432\n",
      "Epoch 2/100\n",
      "166481/166481 [==============================] - 16s 98us/step - loss: 0.0399 - val_loss: 0.0379\n",
      "Epoch 3/100\n",
      "166481/166481 [==============================] - 18s 109us/step - loss: 0.0368 - val_loss: 0.0360\n",
      "Epoch 4/100\n",
      "166481/166481 [==============================] - 18s 106us/step - loss: 0.0345 - val_loss: 0.0341\n",
      "Epoch 5/100\n",
      "166481/166481 [==============================] - 18s 109us/step - loss: 0.0328 - val_loss: 0.0331\n",
      "Epoch 6/100\n",
      "166481/166481 [==============================] - 18s 110us/step - loss: 0.0315 - val_loss: 0.0317\n",
      "Epoch 7/100\n",
      "166481/166481 [==============================] - 18s 106us/step - loss: 0.0307 - val_loss: 0.0308\n",
      "Epoch 8/100\n",
      "166481/166481 [==============================] - 18s 109us/step - loss: 0.0299 - val_loss: 0.0304\n",
      "Epoch 9/100\n",
      "166481/166481 [==============================] - 18s 109us/step - loss: 0.0291 - val_loss: 0.0296\n",
      "Epoch 10/100\n",
      "166481/166481 [==============================] - 18s 106us/step - loss: 0.0286 - val_loss: 0.0286\n",
      "Epoch 11/100\n",
      "166481/166481 [==============================] - 18s 105us/step - loss: 0.0282 - val_loss: 0.0280\n",
      "Epoch 12/100\n",
      "166481/166481 [==============================] - 18s 105us/step - loss: 0.0278 - val_loss: 0.0286\n",
      "Epoch 13/100\n",
      "166481/166481 [==============================] - 15s 90us/step - loss: 0.0271 - val_loss: 0.0279\n",
      "Epoch 14/100\n",
      "166481/166481 [==============================] - 15s 89us/step - loss: 0.0268 - val_loss: 0.0279\n",
      "Epoch 15/100\n",
      "166481/166481 [==============================] - 15s 87us/step - loss: 0.0265 - val_loss: 0.0267\n",
      "Epoch 16/100\n",
      "166481/166481 [==============================] - 15s 89us/step - loss: 0.0262 - val_loss: 0.0266\n",
      "Epoch 17/100\n",
      "166481/166481 [==============================] - 15s 88us/step - loss: 0.0259 - val_loss: 0.0271\n",
      "Epoch 18/100\n",
      "166481/166481 [==============================] - 15s 90us/step - loss: 0.0257 - val_loss: 0.0266\n",
      "Epoch 19/100\n",
      "166481/166481 [==============================] - 15s 89us/step - loss: 0.0254 - val_loss: 0.0264\n",
      "Epoch 20/100\n",
      "166481/166481 [==============================] - 15s 88us/step - loss: 0.0251 - val_loss: 0.0253\n",
      "Epoch 21/100\n",
      "166481/166481 [==============================] - 15s 90us/step - loss: 0.0248 - val_loss: 0.0254\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166481/166481 [==============================] - 15s 89us/step - loss: 0.0247 - val_loss: 0.0256\n",
      "Epoch 23/100\n",
      "166481/166481 [==============================] - 16s 93us/step - loss: 0.0245 - val_loss: 0.0252\n",
      "Epoch 24/100\n",
      "166481/166481 [==============================] - 15s 92us/step - loss: 0.0243 - val_loss: 0.0252\n",
      "Epoch 25/100\n",
      "166481/166481 [==============================] - 15s 89us/step - loss: 0.0241 - val_loss: 0.0250\n",
      "Epoch 26/100\n",
      "166481/166481 [==============================] - 15s 89us/step - loss: 0.0240 - val_loss: 0.0251\n",
      "Epoch 27/100\n",
      "166481/166481 [==============================] - 15s 88us/step - loss: 0.0238 - val_loss: 0.0247\n",
      "Epoch 28/100\n",
      "166481/166481 [==============================] - 15s 89us/step - loss: 0.0237 - val_loss: 0.0245\n",
      "Epoch 29/100\n",
      "166481/166481 [==============================] - 15s 88us/step - loss: 0.0236 - val_loss: 0.0238\n",
      "Epoch 30/100\n",
      "166481/166481 [==============================] - 14s 86us/step - loss: 0.0234 - val_loss: 0.0248\n",
      "Epoch 31/100\n",
      "166481/166481 [==============================] - 15s 88us/step - loss: 0.0232 - val_loss: 0.0242\n",
      "Epoch 32/100\n",
      "166481/166481 [==============================] - 15s 88us/step - loss: 0.0230 - val_loss: 0.0237\n",
      "Epoch 33/100\n",
      "166481/166481 [==============================] - 14s 87us/step - loss: 0.0230 - val_loss: 0.0240\n",
      "Epoch 34/100\n",
      "166481/166481 [==============================] - 14s 87us/step - loss: 0.0229 - val_loss: 0.0241\n",
      "Epoch 35/100\n",
      "166481/166481 [==============================] - 15s 88us/step - loss: 0.0227 - val_loss: 0.0235\n",
      "Epoch 36/100\n",
      "166481/166481 [==============================] - 15s 88us/step - loss: 0.0225 - val_loss: 0.0232\n",
      "Epoch 37/100\n",
      "166481/166481 [==============================] - 15s 88us/step - loss: 0.0225 - val_loss: 0.0234\n",
      "Epoch 38/100\n",
      "166481/166481 [==============================] - 15s 89us/step - loss: 0.0225 - val_loss: 0.0237\n",
      "Epoch 39/100\n",
      "166481/166481 [==============================] - 15s 88us/step - loss: 0.0222 - val_loss: 0.0232\n",
      "Epoch 40/100\n",
      "166481/166481 [==============================] - 15s 89us/step - loss: 0.0222 - val_loss: 0.0233\n",
      "perc99SubjectM2andFold3\n",
      "208141\n",
      "68898\n",
      "Train on 137479 samples, validate on 45784 samples\n",
      "Epoch 1/100\n",
      "137479/137479 [==============================] - 17s 124us/step - loss: 0.0611 - val_loss: 0.0475\n",
      "Epoch 2/100\n",
      "137479/137479 [==============================] - 13s 95us/step - loss: 0.0501 - val_loss: 0.0439\n",
      "Epoch 3/100\n",
      "137479/137479 [==============================] - 13s 94us/step - loss: 0.0470 - val_loss: 0.0416\n",
      "Epoch 4/100\n",
      "137479/137479 [==============================] - 12s 90us/step - loss: 0.0451 - val_loss: 0.0393\n",
      "Epoch 5/100\n",
      "137479/137479 [==============================] - 12s 88us/step - loss: 0.0436 - val_loss: 0.0383\n",
      "Epoch 6/100\n",
      "137479/137479 [==============================] - 12s 86us/step - loss: 0.0425 - val_loss: 0.0389\n",
      "Epoch 7/100\n",
      "137479/137479 [==============================] - 12s 89us/step - loss: 0.0415 - val_loss: 0.0369\n",
      "Epoch 8/100\n",
      "137479/137479 [==============================] - 12s 87us/step - loss: 0.0405 - val_loss: 0.0363\n",
      "Epoch 9/100\n",
      "137479/137479 [==============================] - 12s 90us/step - loss: 0.0398 - val_loss: 0.0368\n",
      "Epoch 10/100\n",
      "137479/137479 [==============================] - 14s 99us/step - loss: 0.0392 - val_loss: 0.0345\n",
      "Epoch 11/100\n",
      "137479/137479 [==============================] - 14s 99us/step - loss: 0.0385 - val_loss: 0.0353\n",
      "Epoch 12/100\n",
      "137479/137479 [==============================] - 14s 99us/step - loss: 0.0379 - val_loss: 0.0340\n",
      "Epoch 13/100\n",
      "137479/137479 [==============================] - 14s 100us/step - loss: 0.0375 - val_loss: 0.0339\n",
      "Epoch 14/100\n",
      "137479/137479 [==============================] - 13s 98us/step - loss: 0.0372 - val_loss: 0.0326\n",
      "Epoch 15/100\n",
      "137479/137479 [==============================] - 14s 100us/step - loss: 0.0368 - val_loss: 0.0331\n",
      "Epoch 16/100\n",
      "137479/137479 [==============================] - 14s 101us/step - loss: 0.0364 - val_loss: 0.0325\n",
      "Epoch 17/100\n",
      "137479/137479 [==============================] - 14s 98us/step - loss: 0.0360 - val_loss: 0.0321\n",
      "Epoch 18/100\n",
      "137479/137479 [==============================] - 14s 101us/step - loss: 0.0356 - val_loss: 0.0323\n",
      "Epoch 19/100\n",
      "137479/137479 [==============================] - 14s 99us/step - loss: 0.0353 - val_loss: 0.0310\n",
      "Epoch 20/100\n",
      "137479/137479 [==============================] - 14s 99us/step - loss: 0.0350 - val_loss: 0.0325\n",
      "Epoch 21/100\n",
      "137479/137479 [==============================] - 14s 99us/step - loss: 0.0349 - val_loss: 0.0317\n",
      "Epoch 22/100\n",
      "137479/137479 [==============================] - 14s 99us/step - loss: 0.0344 - val_loss: 0.0311\n",
      "Epoch 23/100\n",
      "137479/137479 [==============================] - 14s 99us/step - loss: 0.0342 - val_loss: 0.0310\n",
      "perc99SubjectM2andFold4\n",
      "205332\n",
      "67916\n",
      "Train on 137723 samples, validate on 44724 samples\n",
      "Epoch 1/100\n",
      "137723/137723 [==============================] - 16s 116us/step - loss: 0.0571 - val_loss: 0.0423\n",
      "Epoch 2/100\n",
      "137723/137723 [==============================] - 13s 97us/step - loss: 0.0454 - val_loss: 0.0392\n",
      "Epoch 3/100\n",
      "137723/137723 [==============================] - 14s 98us/step - loss: 0.0425 - val_loss: 0.0378\n",
      "Epoch 4/100\n",
      "137723/137723 [==============================] - 14s 101us/step - loss: 0.0403 - val_loss: 0.0363\n",
      "Epoch 5/100\n",
      "137723/137723 [==============================] - 13s 98us/step - loss: 0.0385 - val_loss: 0.0332\n",
      "Epoch 6/100\n",
      "137723/137723 [==============================] - 14s 100us/step - loss: 0.0367 - val_loss: 0.0343\n",
      "Epoch 7/100\n",
      "137723/137723 [==============================] - 14s 99us/step - loss: 0.0356 - val_loss: 0.0334\n",
      "Epoch 8/100\n",
      "137723/137723 [==============================] - 14s 98us/step - loss: 0.0347 - val_loss: 0.0315\n",
      "Epoch 9/100\n",
      "137723/137723 [==============================] - 14s 101us/step - loss: 0.0339 - val_loss: 0.0303\n",
      "Epoch 10/100\n",
      "137723/137723 [==============================] - 14s 98us/step - loss: 0.0330 - val_loss: 0.0300\n",
      "Epoch 11/100\n",
      "137723/137723 [==============================] - 14s 99us/step - loss: 0.0325 - val_loss: 0.0317\n",
      "Epoch 12/100\n",
      "137723/137723 [==============================] - 14s 99us/step - loss: 0.0320 - val_loss: 0.0305\n",
      "Epoch 13/100\n",
      "137723/137723 [==============================] - 13s 97us/step - loss: 0.0313 - val_loss: 0.0294\n",
      "Epoch 14/100\n",
      "137723/137723 [==============================] - 14s 98us/step - loss: 0.0309 - val_loss: 0.0283\n",
      "Epoch 15/100\n",
      "137723/137723 [==============================] - 14s 99us/step - loss: 0.0304 - val_loss: 0.0283\n",
      "Epoch 16/100\n",
      "137723/137723 [==============================] - 14s 99us/step - loss: 0.0301 - val_loss: 0.0285\n",
      "Epoch 17/100\n",
      "137723/137723 [==============================] - 14s 99us/step - loss: 0.0298 - val_loss: 0.0281\n",
      "Epoch 18/100\n",
      "137723/137723 [==============================] - 13s 98us/step - loss: 0.0295 - val_loss: 0.0270\n",
      "Epoch 19/100\n",
      "137723/137723 [==============================] - 13s 97us/step - loss: 0.0291 - val_loss: 0.0277\n",
      "Epoch 20/100\n",
      "137723/137723 [==============================] - 14s 99us/step - loss: 0.0289 - val_loss: 0.0269\n",
      "Epoch 21/100\n",
      "137723/137723 [==============================] - 14s 101us/step - loss: 0.0287 - val_loss: 0.0272\n",
      "Epoch 22/100\n",
      "137723/137723 [==============================] - 14s 102us/step - loss: 0.0283 - val_loss: 0.0273\n",
      "Epoch 23/100\n",
      "137723/137723 [==============================] - 14s 101us/step - loss: 0.0283 - val_loss: 0.0263\n",
      "Epoch 24/100\n",
      "137723/137723 [==============================] - 14s 98us/step - loss: 0.0279 - val_loss: 0.0265\n",
      "Epoch 25/100\n",
      "137723/137723 [==============================] - 14s 102us/step - loss: 0.0277 - val_loss: 0.0261\n",
      "Epoch 26/100\n",
      "137723/137723 [==============================] - 14s 102us/step - loss: 0.0275 - val_loss: 0.0258\n",
      "Epoch 27/100\n",
      "137723/137723 [==============================] - 13s 96us/step - loss: 0.0274 - val_loss: 0.0263\n",
      "Epoch 28/100\n",
      "137723/137723 [==============================] - 14s 99us/step - loss: 0.0273 - val_loss: 0.0272\n",
      "Epoch 29/100\n",
      "137723/137723 [==============================] - 13s 95us/step - loss: 0.0271 - val_loss: 0.0264\n",
      "Epoch 30/100\n",
      "137723/137723 [==============================] - 14s 101us/step - loss: 0.0269 - val_loss: 0.0257\n",
      "Epoch 31/100\n",
      "137723/137723 [==============================] - 13s 98us/step - loss: 0.0268 - val_loss: 0.0256\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137723/137723 [==============================] - 14s 100us/step - loss: 0.0266 - val_loss: 0.0262\n",
      "Epoch 33/100\n",
      "137723/137723 [==============================] - 14s 99us/step - loss: 0.0264 - val_loss: 0.0259\n",
      "Epoch 34/100\n",
      "137723/137723 [==============================] - 13s 96us/step - loss: 0.0263 - val_loss: 0.0259\n",
      "Epoch 35/100\n",
      "137723/137723 [==============================] - 14s 103us/step - loss: 0.0263 - val_loss: 0.0258\n",
      "perc99.25SubjectF1andFold1\n",
      "230517\n",
      "74168\n",
      "Train on 205933 samples, validate on 66874 samples\n",
      "Epoch 1/100\n",
      "205933/205933 [==============================] - 23s 109us/step - loss: 0.0528 - val_loss: 0.0459\n",
      "Epoch 2/100\n",
      "205933/205933 [==============================] - 20s 97us/step - loss: 0.0432 - val_loss: 0.0433\n",
      "Epoch 3/100\n",
      "205933/205933 [==============================] - 20s 99us/step - loss: 0.0408 - val_loss: 0.0416\n",
      "Epoch 4/100\n",
      "205933/205933 [==============================] - 21s 100us/step - loss: 0.0391 - val_loss: 0.0396\n",
      "Epoch 5/100\n",
      "205933/205933 [==============================] - 21s 101us/step - loss: 0.0377 - val_loss: 0.0385\n",
      "Epoch 6/100\n",
      "205933/205933 [==============================] - 20s 98us/step - loss: 0.0364 - val_loss: 0.0382\n",
      "Epoch 7/100\n",
      "205933/205933 [==============================] - 20s 98us/step - loss: 0.0353 - val_loss: 0.0380\n",
      "Epoch 8/100\n",
      "205933/205933 [==============================] - 18s 89us/step - loss: 0.0345 - val_loss: 0.0369\n",
      "Epoch 9/100\n",
      "205933/205933 [==============================] - 18s 87us/step - loss: 0.0338 - val_loss: 0.0350\n",
      "Epoch 10/100\n",
      "205933/205933 [==============================] - 18s 88us/step - loss: 0.0330 - val_loss: 0.0347\n",
      "Epoch 11/100\n",
      "205933/205933 [==============================] - 18s 88us/step - loss: 0.0325 - val_loss: 0.0344\n",
      "Epoch 12/100\n",
      "205933/205933 [==============================] - 19s 91us/step - loss: 0.0319 - val_loss: 0.0339\n",
      "Epoch 13/100\n",
      "205933/205933 [==============================] - 18s 89us/step - loss: 0.0313 - val_loss: 0.0335\n",
      "Epoch 14/100\n",
      "205933/205933 [==============================] - 18s 88us/step - loss: 0.0308 - val_loss: 0.0335\n",
      "Epoch 15/100\n",
      "205933/205933 [==============================] - 18s 87us/step - loss: 0.0304 - val_loss: 0.0320\n",
      "Epoch 16/100\n",
      "205933/205933 [==============================] - 19s 94us/step - loss: 0.0301 - val_loss: 0.0320\n",
      "Epoch 17/100\n",
      "205933/205933 [==============================] - 18s 88us/step - loss: 0.0297 - val_loss: 0.0321\n",
      "Epoch 18/100\n",
      "205933/205933 [==============================] - 18s 88us/step - loss: 0.0294 - val_loss: 0.0320\n",
      "Epoch 19/100\n",
      "205933/205933 [==============================] - 18s 87us/step - loss: 0.0290 - val_loss: 0.0313\n",
      "Epoch 20/100\n",
      "205933/205933 [==============================] - 18s 89us/step - loss: 0.0287 - val_loss: 0.0312\n",
      "Epoch 21/100\n",
      "205933/205933 [==============================] - 19s 91us/step - loss: 0.0285 - val_loss: 0.0309\n",
      "Epoch 22/100\n",
      "205933/205933 [==============================] - 18s 87us/step - loss: 0.0282 - val_loss: 0.0313\n",
      "Epoch 23/100\n",
      "205933/205933 [==============================] - 19s 90us/step - loss: 0.0280 - val_loss: 0.0305\n",
      "Epoch 24/100\n",
      "205933/205933 [==============================] - 18s 90us/step - loss: 0.0278 - val_loss: 0.0305\n",
      "Epoch 25/100\n",
      "205933/205933 [==============================] - 18s 90us/step - loss: 0.0275 - val_loss: 0.0301\n",
      "Epoch 26/100\n",
      "205933/205933 [==============================] - 18s 90us/step - loss: 0.0275 - val_loss: 0.0304\n",
      "Epoch 27/100\n",
      "205933/205933 [==============================] - 18s 90us/step - loss: 0.0272 - val_loss: 0.0295\n",
      "Epoch 28/100\n",
      "205933/205933 [==============================] - 18s 89us/step - loss: 0.0270 - val_loss: 0.0296\n",
      "Epoch 29/100\n",
      "205933/205933 [==============================] - 18s 87us/step - loss: 0.0268 - val_loss: 0.0297\n",
      "Epoch 30/100\n",
      "205933/205933 [==============================] - 18s 87us/step - loss: 0.0267 - val_loss: 0.0292\n",
      "Epoch 31/100\n",
      "205933/205933 [==============================] - 18s 88us/step - loss: 0.0266 - val_loss: 0.0292\n",
      "Epoch 32/100\n",
      "205933/205933 [==============================] - 18s 89us/step - loss: 0.0265 - val_loss: 0.0292\n",
      "Epoch 33/100\n",
      "205933/205933 [==============================] - 18s 89us/step - loss: 0.0262 - val_loss: 0.0294\n",
      "Epoch 34/100\n",
      "205933/205933 [==============================] - 18s 89us/step - loss: 0.0261 - val_loss: 0.0290\n",
      "Epoch 35/100\n",
      "205933/205933 [==============================] - 18s 90us/step - loss: 0.0260 - val_loss: 0.0287\n",
      "Epoch 36/100\n",
      "205933/205933 [==============================] - 18s 88us/step - loss: 0.0260 - val_loss: 0.0285\n",
      "Epoch 37/100\n",
      "205933/205933 [==============================] - 19s 91us/step - loss: 0.0257 - val_loss: 0.0284\n",
      "Epoch 38/100\n",
      "205933/205933 [==============================] - 18s 88us/step - loss: 0.0256 - val_loss: 0.0287\n",
      "Epoch 39/100\n",
      "205933/205933 [==============================] - 18s 90us/step - loss: 0.0257 - val_loss: 0.0283\n",
      "Epoch 40/100\n",
      "205933/205933 [==============================] - 19s 90us/step - loss: 0.0256 - val_loss: 0.0285\n",
      "Epoch 41/100\n",
      "205933/205933 [==============================] - 18s 89us/step - loss: 0.0253 - val_loss: 0.0277\n",
      "Epoch 42/100\n",
      "205933/205933 [==============================] - 18s 88us/step - loss: 0.0253 - val_loss: 0.0281\n",
      "Epoch 43/100\n",
      "205933/205933 [==============================] - 19s 91us/step - loss: 0.0252 - val_loss: 0.0283\n",
      "Epoch 44/100\n",
      "205933/205933 [==============================] - 19s 90us/step - loss: 0.0251 - val_loss: 0.0281\n",
      "Epoch 45/100\n",
      "205933/205933 [==============================] - 19s 90us/step - loss: 0.0250 - val_loss: 0.0283\n",
      "perc99.25SubjectF1andFold2\n",
      "284312\n",
      "94038\n",
      "Train on 103600 samples, validate on 32834 samples\n",
      "Epoch 1/100\n",
      "103600/103600 [==============================] - 12s 116us/step - loss: 0.0622 - val_loss: 0.0500\n",
      "Epoch 2/100\n",
      "103600/103600 [==============================] - 10s 93us/step - loss: 0.0476 - val_loss: 0.0445\n",
      "Epoch 3/100\n",
      "103600/103600 [==============================] - 9s 90us/step - loss: 0.0423 - val_loss: 0.0419\n",
      "Epoch 4/100\n",
      "103600/103600 [==============================] - 10s 94us/step - loss: 0.0390 - val_loss: 0.0382\n",
      "Epoch 5/100\n",
      "103600/103600 [==============================] - 10s 92us/step - loss: 0.0365 - val_loss: 0.0374\n",
      "Epoch 6/100\n",
      "103600/103600 [==============================] - 10s 94us/step - loss: 0.0347 - val_loss: 0.0350\n",
      "Epoch 7/100\n",
      "103600/103600 [==============================] - 9s 89us/step - loss: 0.0333 - val_loss: 0.0337\n",
      "Epoch 8/100\n",
      "103600/103600 [==============================] - 10s 93us/step - loss: 0.0320 - val_loss: 0.0328\n",
      "Epoch 9/100\n",
      "103600/103600 [==============================] - 10s 92us/step - loss: 0.0308 - val_loss: 0.0357\n",
      "Epoch 10/100\n",
      "103600/103600 [==============================] - 10s 93us/step - loss: 0.0301 - val_loss: 0.0327\n",
      "Epoch 11/100\n",
      "103600/103600 [==============================] - 10s 93us/step - loss: 0.0292 - val_loss: 0.0302\n",
      "Epoch 12/100\n",
      "103600/103600 [==============================] - 10s 92us/step - loss: 0.0287 - val_loss: 0.0313\n",
      "Epoch 13/100\n",
      "103600/103600 [==============================] - 10s 93us/step - loss: 0.0280 - val_loss: 0.0310\n",
      "Epoch 14/100\n",
      "103600/103600 [==============================] - 9s 91us/step - loss: 0.0274 - val_loss: 0.0304\n",
      "Epoch 15/100\n",
      "103600/103600 [==============================] - 9s 91us/step - loss: 0.0270 - val_loss: 0.0293\n",
      "Epoch 16/100\n",
      "103600/103600 [==============================] - 10s 93us/step - loss: 0.0263 - val_loss: 0.0287\n",
      "Epoch 17/100\n",
      "103600/103600 [==============================] - 10s 93us/step - loss: 0.0259 - val_loss: 0.0289\n",
      "Epoch 18/100\n",
      "103600/103600 [==============================] - 10s 93us/step - loss: 0.0256 - val_loss: 0.0278\n",
      "Epoch 19/100\n",
      "103600/103600 [==============================] - 9s 92us/step - loss: 0.0250 - val_loss: 0.0272\n",
      "Epoch 20/100\n",
      "103600/103600 [==============================] - 9s 91us/step - loss: 0.0246 - val_loss: 0.0300\n",
      "Epoch 21/100\n",
      "103600/103600 [==============================] - 9s 90us/step - loss: 0.0244 - val_loss: 0.0289\n",
      "Epoch 22/100\n",
      "103600/103600 [==============================] - 9s 90us/step - loss: 0.0240 - val_loss: 0.0270\n",
      "Epoch 23/100\n",
      "103600/103600 [==============================] - 10s 94us/step - loss: 0.0235 - val_loss: 0.0285\n",
      "Epoch 24/100\n",
      "103600/103600 [==============================] - 10s 92us/step - loss: 0.0236 - val_loss: 0.0270\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103600/103600 [==============================] - 10s 92us/step - loss: 0.0231 - val_loss: 0.0272\n",
      "Epoch 26/100\n",
      "103600/103600 [==============================] - 9s 90us/step - loss: 0.0229 - val_loss: 0.0288\n",
      "Epoch 27/100\n",
      "103600/103600 [==============================] - 9s 90us/step - loss: 0.0227 - val_loss: 0.0259\n",
      "Epoch 28/100\n",
      "103600/103600 [==============================] - 9s 90us/step - loss: 0.0224 - val_loss: 0.0268\n",
      "Epoch 29/100\n",
      "103600/103600 [==============================] - 9s 88us/step - loss: 0.0223 - val_loss: 0.0261\n",
      "Epoch 30/100\n",
      "103600/103600 [==============================] - 9s 89us/step - loss: 0.0222 - val_loss: 0.0265\n",
      "Epoch 31/100\n",
      "103600/103600 [==============================] - 9s 90us/step - loss: 0.0219 - val_loss: 0.0256\n",
      "Epoch 32/100\n",
      "103600/103600 [==============================] - 9s 88us/step - loss: 0.0216 - val_loss: 0.0269\n",
      "Epoch 33/100\n",
      "103600/103600 [==============================] - 9s 90us/step - loss: 0.0214 - val_loss: 0.0260\n",
      "Epoch 34/100\n",
      "103600/103600 [==============================] - 10s 94us/step - loss: 0.0214 - val_loss: 0.0257\n",
      "Epoch 35/100\n",
      "103600/103600 [==============================] - 10s 92us/step - loss: 0.0213 - val_loss: 0.0263\n",
      "perc99.25SubjectF1andFold3\n",
      "219502\n",
      "72190\n",
      "Train on 195662 samples, validate on 64226 samples\n",
      "Epoch 1/100\n",
      "195662/195662 [==============================] - 20s 105us/step - loss: 0.0550 - val_loss: 0.0451\n",
      "Epoch 2/100\n",
      "195662/195662 [==============================] - 18s 92us/step - loss: 0.0446 - val_loss: 0.0397\n",
      "Epoch 3/100\n",
      "195662/195662 [==============================] - 18s 93us/step - loss: 0.0422 - val_loss: 0.0409\n",
      "Epoch 4/100\n",
      "195662/195662 [==============================] - 18s 93us/step - loss: 0.0405 - val_loss: 0.0389\n",
      "Epoch 5/100\n",
      "195662/195662 [==============================] - 18s 93us/step - loss: 0.0392 - val_loss: 0.0365\n",
      "Epoch 6/100\n",
      "195662/195662 [==============================] - 18s 93us/step - loss: 0.0379 - val_loss: 0.0363\n",
      "Epoch 7/100\n",
      "195662/195662 [==============================] - 18s 94us/step - loss: 0.0370 - val_loss: 0.0353\n",
      "Epoch 8/100\n",
      "195662/195662 [==============================] - 18s 91us/step - loss: 0.0359 - val_loss: 0.0342\n",
      "Epoch 9/100\n",
      "195662/195662 [==============================] - 18s 92us/step - loss: 0.0351 - val_loss: 0.0328\n",
      "Epoch 10/100\n",
      "195662/195662 [==============================] - 18s 93us/step - loss: 0.0343 - val_loss: 0.0333\n",
      "Epoch 11/100\n",
      "195662/195662 [==============================] - 18s 94us/step - loss: 0.0337 - val_loss: 0.0329\n",
      "Epoch 12/100\n",
      "195662/195662 [==============================] - 18s 91us/step - loss: 0.0329 - val_loss: 0.0323\n",
      "Epoch 13/100\n",
      "195662/195662 [==============================] - 18s 91us/step - loss: 0.0324 - val_loss: 0.0311\n",
      "Epoch 14/100\n",
      "195662/195662 [==============================] - 18s 92us/step - loss: 0.0319 - val_loss: 0.0336\n",
      "Epoch 15/100\n",
      "195662/195662 [==============================] - 18s 93us/step - loss: 0.0315 - val_loss: 0.0304\n",
      "Epoch 16/100\n",
      "195662/195662 [==============================] - 18s 91us/step - loss: 0.0311 - val_loss: 0.0305\n",
      "Epoch 17/100\n",
      "195662/195662 [==============================] - 18s 93us/step - loss: 0.0307 - val_loss: 0.0295\n",
      "Epoch 18/100\n",
      "195662/195662 [==============================] - 18s 94us/step - loss: 0.0303 - val_loss: 0.0293\n",
      "Epoch 19/100\n",
      "195662/195662 [==============================] - 18s 93us/step - loss: 0.0300 - val_loss: 0.0297\n",
      "Epoch 20/100\n",
      "195662/195662 [==============================] - 18s 93us/step - loss: 0.0297 - val_loss: 0.0295\n",
      "Epoch 21/100\n",
      "195662/195662 [==============================] - 18s 92us/step - loss: 0.0293 - val_loss: 0.0287\n",
      "Epoch 22/100\n",
      "195662/195662 [==============================] - 18s 91us/step - loss: 0.0291 - val_loss: 0.0291\n",
      "Epoch 23/100\n",
      "195662/195662 [==============================] - 18s 92us/step - loss: 0.0289 - val_loss: 0.0276\n",
      "Epoch 24/100\n",
      "195662/195662 [==============================] - 18s 94us/step - loss: 0.0286 - val_loss: 0.0289\n",
      "Epoch 25/100\n",
      "195662/195662 [==============================] - 18s 94us/step - loss: 0.0284 - val_loss: 0.0275\n",
      "Epoch 26/100\n",
      "195662/195662 [==============================] - 17s 86us/step - loss: 0.0282 - val_loss: 0.0277\n",
      "Epoch 27/100\n",
      "195662/195662 [==============================] - 15s 77us/step - loss: 0.0280 - val_loss: 0.0279\n",
      "Epoch 28/100\n",
      "195662/195662 [==============================] - 15s 79us/step - loss: 0.0279 - val_loss: 0.0287\n",
      "Epoch 29/100\n",
      "195662/195662 [==============================] - 15s 78us/step - loss: 0.0275 - val_loss: 0.0271\n",
      "Epoch 30/100\n",
      "195662/195662 [==============================] - 15s 79us/step - loss: 0.0275 - val_loss: 0.0280\n",
      "Epoch 31/100\n",
      "195662/195662 [==============================] - 16s 81us/step - loss: 0.0275 - val_loss: 0.0276\n",
      "Epoch 32/100\n",
      "195662/195662 [==============================] - 16s 79us/step - loss: 0.0271 - val_loss: 0.0287\n",
      "Epoch 33/100\n",
      "195662/195662 [==============================] - 15s 78us/step - loss: 0.0270 - val_loss: 0.0275\n",
      "perc99.25SubjectF1andFold4\n",
      "220944\n",
      "74224\n",
      "Train on 109724 samples, validate on 36360 samples\n",
      "Epoch 1/100\n",
      "109724/109724 [==============================] - 12s 110us/step - loss: 0.0573 - val_loss: 0.0467\n",
      "Epoch 2/100\n",
      "109724/109724 [==============================] - 9s 81us/step - loss: 0.0436 - val_loss: 0.0427\n",
      "Epoch 3/100\n",
      "109724/109724 [==============================] - 9s 82us/step - loss: 0.0399 - val_loss: 0.0439\n",
      "Epoch 4/100\n",
      "109724/109724 [==============================] - 9s 78us/step - loss: 0.0374 - val_loss: 0.0379\n",
      "Epoch 5/100\n",
      "109724/109724 [==============================] - 9s 80us/step - loss: 0.0360 - val_loss: 0.0372\n",
      "Epoch 6/100\n",
      "109724/109724 [==============================] - 8s 77us/step - loss: 0.0342 - val_loss: 0.0387\n",
      "Epoch 7/100\n",
      "109724/109724 [==============================] - 9s 81us/step - loss: 0.0330 - val_loss: 0.0337\n",
      "Epoch 8/100\n",
      "109724/109724 [==============================] - 9s 81us/step - loss: 0.0319 - val_loss: 0.0338\n",
      "Epoch 9/100\n",
      "109724/109724 [==============================] - 8s 76us/step - loss: 0.0311 - val_loss: 0.0332\n",
      "Epoch 10/100\n",
      "109724/109724 [==============================] - 9s 81us/step - loss: 0.0304 - val_loss: 0.0327\n",
      "Epoch 11/100\n",
      "109724/109724 [==============================] - 9s 83us/step - loss: 0.0298 - val_loss: 0.0316\n",
      "Epoch 12/100\n",
      "109724/109724 [==============================] - 9s 82us/step - loss: 0.0294 - val_loss: 0.0326\n",
      "Epoch 13/100\n",
      "109724/109724 [==============================] - 9s 79us/step - loss: 0.0288 - val_loss: 0.0313\n",
      "Epoch 14/100\n",
      "109724/109724 [==============================] - 9s 79us/step - loss: 0.0285 - val_loss: 0.0309\n",
      "Epoch 15/100\n",
      "109724/109724 [==============================] - 9s 78us/step - loss: 0.0278 - val_loss: 0.0314\n",
      "Epoch 16/100\n",
      "109724/109724 [==============================] - 9s 79us/step - loss: 0.0273 - val_loss: 0.0302\n",
      "Epoch 17/100\n",
      "109724/109724 [==============================] - 9s 80us/step - loss: 0.0271 - val_loss: 0.0312\n",
      "Epoch 18/100\n",
      "109724/109724 [==============================] - 9s 78us/step - loss: 0.0263 - val_loss: 0.0305\n",
      "Epoch 19/100\n",
      "109724/109724 [==============================] - 9s 84us/step - loss: 0.0261 - val_loss: 0.0292\n",
      "Epoch 20/100\n",
      "109724/109724 [==============================] - 10s 89us/step - loss: 0.0259 - val_loss: 0.0287\n",
      "Epoch 21/100\n",
      "109724/109724 [==============================] - 9s 80us/step - loss: 0.0254 - val_loss: 0.0284\n",
      "Epoch 22/100\n",
      "109724/109724 [==============================] - 8s 76us/step - loss: 0.0254 - val_loss: 0.0301\n",
      "Epoch 23/100\n",
      "109724/109724 [==============================] - 9s 79us/step - loss: 0.0250 - val_loss: 0.0284\n",
      "Epoch 24/100\n",
      "109724/109724 [==============================] - 9s 79us/step - loss: 0.0245 - val_loss: 0.0290\n",
      "Epoch 25/100\n",
      "109724/109724 [==============================] - 8s 77us/step - loss: 0.0242 - val_loss: 0.0276\n",
      "Epoch 26/100\n",
      "109724/109724 [==============================] - 9s 78us/step - loss: 0.0241 - val_loss: 0.0283\n",
      "Epoch 27/100\n",
      "109724/109724 [==============================] - 9s 78us/step - loss: 0.0240 - val_loss: 0.0271\n",
      "Epoch 28/100\n",
      "109724/109724 [==============================] - 9s 78us/step - loss: 0.0236 - val_loss: 0.0287\n",
      "Epoch 29/100\n",
      "109724/109724 [==============================] - 8s 77us/step - loss: 0.0236 - val_loss: 0.0269\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109724/109724 [==============================] - 8s 76us/step - loss: 0.0234 - val_loss: 0.0270\n",
      "Epoch 31/100\n",
      "109724/109724 [==============================] - 9s 78us/step - loss: 0.0232 - val_loss: 0.0269\n",
      "Epoch 32/100\n",
      "109724/109724 [==============================] - 8s 77us/step - loss: 0.0230 - val_loss: 0.0274\n",
      "Epoch 33/100\n",
      "109724/109724 [==============================] - 8s 77us/step - loss: 0.0228 - val_loss: 0.0263\n",
      "Epoch 34/100\n",
      "109724/109724 [==============================] - 9s 78us/step - loss: 0.0226 - val_loss: 0.0262\n",
      "Epoch 35/100\n",
      "109724/109724 [==============================] - 9s 83us/step - loss: 0.0225 - val_loss: 0.0274\n",
      "Epoch 36/100\n",
      "109724/109724 [==============================] - 10s 88us/step - loss: 0.0223 - val_loss: 0.0251\n",
      "Epoch 37/100\n",
      "109724/109724 [==============================] - 10s 88us/step - loss: 0.0223 - val_loss: 0.0254\n",
      "Epoch 38/100\n",
      "109724/109724 [==============================] - 10s 87us/step - loss: 0.0220 - val_loss: 0.0260\n",
      "Epoch 39/100\n",
      "109724/109724 [==============================] - 10s 89us/step - loss: 0.0219 - val_loss: 0.0254\n",
      "Epoch 40/100\n",
      "109724/109724 [==============================] - 10s 87us/step - loss: 0.0217 - val_loss: 0.0247\n",
      "Epoch 41/100\n",
      "109724/109724 [==============================] - 10s 89us/step - loss: 0.0217 - val_loss: 0.0254\n",
      "Epoch 42/100\n",
      "109724/109724 [==============================] - 10s 88us/step - loss: 0.0215 - val_loss: 0.0265\n",
      "Epoch 43/100\n",
      "109724/109724 [==============================] - 10s 88us/step - loss: 0.0214 - val_loss: 0.0250\n",
      "Epoch 44/100\n",
      "109724/109724 [==============================] - 10s 89us/step - loss: 0.0214 - val_loss: 0.0251\n",
      "perc99.25SubjectF2andFold1\n",
      "230547\n",
      "74297\n",
      "Train on 141616 samples, validate on 45813 samples\n",
      "Epoch 1/100\n",
      "141616/141616 [==============================] - 15s 107us/step - loss: 0.0509 - val_loss: 0.0435\n",
      "Epoch 2/100\n",
      "141616/141616 [==============================] - 10s 71us/step - loss: 0.0407 - val_loss: 0.0380\n",
      "Epoch 3/100\n",
      "141616/141616 [==============================] - 11s 77us/step - loss: 0.0393 - val_loss: 0.0378\n",
      "Epoch 4/100\n",
      "141616/141616 [==============================] - 11s 76us/step - loss: 0.0384 - val_loss: 0.0370\n",
      "Epoch 5/100\n",
      "141616/141616 [==============================] - 11s 77us/step - loss: 0.0376 - val_loss: 0.0363\n",
      "Epoch 6/100\n",
      "141616/141616 [==============================] - 12s 82us/step - loss: 0.0370 - val_loss: 0.0356\n",
      "Epoch 7/100\n",
      "141616/141616 [==============================] - 14s 101us/step - loss: 0.0364 - val_loss: 0.0362\n",
      "Epoch 8/100\n",
      "141616/141616 [==============================] - 15s 105us/step - loss: 0.0358 - val_loss: 0.0351\n",
      "Epoch 9/100\n",
      "141616/141616 [==============================] - 15s 103us/step - loss: 0.0354 - val_loss: 0.0346\n",
      "Epoch 10/100\n",
      "141616/141616 [==============================] - 14s 101us/step - loss: 0.0349 - val_loss: 0.0336\n",
      "Epoch 11/100\n",
      "141616/141616 [==============================] - 14s 99us/step - loss: 0.0344 - val_loss: 0.0334\n",
      "Epoch 12/100\n",
      "141616/141616 [==============================] - 15s 106us/step - loss: 0.0341 - val_loss: 0.0349\n",
      "Epoch 13/100\n",
      "141616/141616 [==============================] - 14s 102us/step - loss: 0.0337 - val_loss: 0.0332\n",
      "Epoch 14/100\n",
      "141616/141616 [==============================] - 14s 101us/step - loss: 0.0333 - val_loss: 0.0326\n",
      "Epoch 15/100\n",
      "141616/141616 [==============================] - 14s 101us/step - loss: 0.0331 - val_loss: 0.0327\n",
      "Epoch 16/100\n",
      "141616/141616 [==============================] - 15s 107us/step - loss: 0.0327 - val_loss: 0.0328\n",
      "Epoch 17/100\n",
      "141616/141616 [==============================] - 15s 103us/step - loss: 0.0325 - val_loss: 0.0323\n",
      "Epoch 18/100\n",
      "141616/141616 [==============================] - 14s 101us/step - loss: 0.0322 - val_loss: 0.0323\n",
      "Epoch 19/100\n",
      "141616/141616 [==============================] - 14s 102us/step - loss: 0.0320 - val_loss: 0.0322\n",
      "Epoch 20/100\n",
      "141616/141616 [==============================] - 14s 99us/step - loss: 0.0318 - val_loss: 0.0323\n",
      "Epoch 21/100\n",
      "141616/141616 [==============================] - 15s 103us/step - loss: 0.0315 - val_loss: 0.0313\n",
      "Epoch 22/100\n",
      "141616/141616 [==============================] - 14s 101us/step - loss: 0.0313 - val_loss: 0.0310\n",
      "Epoch 23/100\n",
      "141616/141616 [==============================] - 15s 105us/step - loss: 0.0311 - val_loss: 0.0310\n",
      "Epoch 24/100\n",
      "141616/141616 [==============================] - 15s 106us/step - loss: 0.0308 - val_loss: 0.0307\n",
      "Epoch 25/100\n",
      "141616/141616 [==============================] - 15s 105us/step - loss: 0.0306 - val_loss: 0.0309\n",
      "Epoch 26/100\n",
      "141616/141616 [==============================] - 15s 109us/step - loss: 0.0306 - val_loss: 0.0305\n",
      "Epoch 27/100\n",
      "141616/141616 [==============================] - 14s 102us/step - loss: 0.0303 - val_loss: 0.0303\n",
      "Epoch 28/100\n",
      "141616/141616 [==============================] - 14s 102us/step - loss: 0.0302 - val_loss: 0.0307\n",
      "Epoch 29/100\n",
      "141616/141616 [==============================] - 14s 100us/step - loss: 0.0299 - val_loss: 0.0296\n",
      "Epoch 30/100\n",
      "141616/141616 [==============================] - 15s 104us/step - loss: 0.0297 - val_loss: 0.0297\n",
      "Epoch 31/100\n",
      "141616/141616 [==============================] - 14s 101us/step - loss: 0.0297 - val_loss: 0.0303\n",
      "Epoch 32/100\n",
      "141616/141616 [==============================] - 14s 101us/step - loss: 0.0295 - val_loss: 0.0294\n",
      "Epoch 33/100\n",
      "141616/141616 [==============================] - 14s 99us/step - loss: 0.0294 - val_loss: 0.0296\n",
      "Epoch 34/100\n",
      "141616/141616 [==============================] - 14s 101us/step - loss: 0.0293 - val_loss: 0.0300\n",
      "Epoch 35/100\n",
      "141616/141616 [==============================] - 14s 102us/step - loss: 0.0290 - val_loss: 0.0294\n",
      "Epoch 36/100\n",
      "141616/141616 [==============================] - 14s 100us/step - loss: 0.0290 - val_loss: 0.0291\n",
      "Epoch 37/100\n",
      "141616/141616 [==============================] - 14s 101us/step - loss: 0.0288 - val_loss: 0.0294\n",
      "Epoch 38/100\n",
      "141616/141616 [==============================] - 14s 101us/step - loss: 0.0287 - val_loss: 0.0293\n",
      "Epoch 39/100\n",
      "141616/141616 [==============================] - 14s 102us/step - loss: 0.0285 - val_loss: 0.0292\n",
      "Epoch 40/100\n",
      "141616/141616 [==============================] - 14s 102us/step - loss: 0.0285 - val_loss: 0.0290\n",
      "Epoch 41/100\n",
      "141616/141616 [==============================] - 14s 101us/step - loss: 0.0284 - val_loss: 0.0293\n",
      "Epoch 42/100\n",
      "141616/141616 [==============================] - 14s 100us/step - loss: 0.0282 - val_loss: 0.0287\n",
      "Epoch 43/100\n",
      "141616/141616 [==============================] - 14s 102us/step - loss: 0.0282 - val_loss: 0.0292\n",
      "Epoch 44/100\n",
      "141616/141616 [==============================] - 14s 102us/step - loss: 0.0280 - val_loss: 0.0294\n",
      "Epoch 45/100\n",
      "141616/141616 [==============================] - 15s 106us/step - loss: 0.0279 - val_loss: 0.0285\n",
      "Epoch 46/100\n",
      "141616/141616 [==============================] - 15s 103us/step - loss: 0.0277 - val_loss: 0.0282\n",
      "Epoch 47/100\n",
      "141616/141616 [==============================] - 14s 101us/step - loss: 0.0277 - val_loss: 0.0284\n",
      "Epoch 48/100\n",
      "141616/141616 [==============================] - 14s 100us/step - loss: 0.0277 - val_loss: 0.0283\n",
      "Epoch 49/100\n",
      "141616/141616 [==============================] - 14s 102us/step - loss: 0.0276 - val_loss: 0.0286\n",
      "Epoch 50/100\n",
      "141616/141616 [==============================] - 14s 101us/step - loss: 0.0274 - val_loss: 0.0288\n",
      "perc99.25SubjectF2andFold2\n",
      "270304\n",
      "92087\n",
      "Train on 163765 samples, validate on 56541 samples\n",
      "Epoch 1/100\n",
      "163765/163765 [==============================] - 20s 119us/step - loss: 0.0486 - val_loss: 0.0379\n",
      "Epoch 2/100\n",
      "163765/163765 [==============================] - 17s 104us/step - loss: 0.0395 - val_loss: 0.0367\n",
      "Epoch 3/100\n",
      "163765/163765 [==============================] - 17s 103us/step - loss: 0.0381 - val_loss: 0.0364\n",
      "Epoch 4/100\n",
      "163765/163765 [==============================] - 17s 104us/step - loss: 0.0372 - val_loss: 0.0346\n",
      "Epoch 5/100\n",
      "163765/163765 [==============================] - 17s 102us/step - loss: 0.0363 - val_loss: 0.0341\n",
      "Epoch 6/100\n",
      "163765/163765 [==============================] - 18s 107us/step - loss: 0.0355 - val_loss: 0.0338\n",
      "Epoch 7/100\n",
      "163765/163765 [==============================] - 17s 104us/step - loss: 0.0349 - val_loss: 0.0335\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163765/163765 [==============================] - 18s 109us/step - loss: 0.0343 - val_loss: 0.0334\n",
      "Epoch 9/100\n",
      "163765/163765 [==============================] - 18s 110us/step - loss: 0.0336 - val_loss: 0.0320\n",
      "Epoch 10/100\n",
      "163765/163765 [==============================] - 18s 108us/step - loss: 0.0330 - val_loss: 0.0315\n",
      "Epoch 11/100\n",
      "163765/163765 [==============================] - 17s 102us/step - loss: 0.0325 - val_loss: 0.0309\n",
      "Epoch 12/100\n",
      "163765/163765 [==============================] - 17s 101us/step - loss: 0.0320 - val_loss: 0.0316\n",
      "Epoch 13/100\n",
      "163765/163765 [==============================] - 17s 103us/step - loss: 0.0317 - val_loss: 0.0302\n",
      "Epoch 14/100\n",
      "163765/163765 [==============================] - 17s 102us/step - loss: 0.0312 - val_loss: 0.0307\n",
      "Epoch 15/100\n",
      "163765/163765 [==============================] - 17s 102us/step - loss: 0.0309 - val_loss: 0.0302\n",
      "Epoch 16/100\n",
      "163765/163765 [==============================] - 17s 102us/step - loss: 0.0306 - val_loss: 0.0297\n",
      "Epoch 17/100\n",
      "163765/163765 [==============================] - 17s 102us/step - loss: 0.0303 - val_loss: 0.0298\n",
      "Epoch 18/100\n",
      "163765/163765 [==============================] - 16s 101us/step - loss: 0.0300 - val_loss: 0.0295\n",
      "Epoch 19/100\n",
      "163765/163765 [==============================] - 17s 101us/step - loss: 0.0299 - val_loss: 0.0287\n",
      "Epoch 20/100\n",
      "163765/163765 [==============================] - 15s 89us/step - loss: 0.0297 - val_loss: 0.0286\n",
      "Epoch 21/100\n",
      "163765/163765 [==============================] - 16s 96us/step - loss: 0.0294 - val_loss: 0.0288\n",
      "Epoch 22/100\n",
      "163765/163765 [==============================] - 16s 97us/step - loss: 0.0292 - val_loss: 0.0284\n",
      "Epoch 23/100\n",
      "163765/163765 [==============================] - 16s 95us/step - loss: 0.0289 - val_loss: 0.0281\n",
      "Epoch 24/100\n",
      "163765/163765 [==============================] - 15s 92us/step - loss: 0.0288 - val_loss: 0.0282\n",
      "Epoch 25/100\n",
      "163765/163765 [==============================] - 15s 90us/step - loss: 0.0287 - val_loss: 0.0279\n",
      "Epoch 26/100\n",
      "163765/163765 [==============================] - 15s 93us/step - loss: 0.0284 - val_loss: 0.0278\n",
      "Epoch 27/100\n",
      "163765/163765 [==============================] - 15s 91us/step - loss: 0.0283 - val_loss: 0.0279\n",
      "Epoch 28/100\n",
      "163765/163765 [==============================] - 15s 92us/step - loss: 0.0281 - val_loss: 0.0276\n",
      "Epoch 29/100\n",
      "163765/163765 [==============================] - 15s 90us/step - loss: 0.0281 - val_loss: 0.0276\n",
      "Epoch 30/100\n",
      "163765/163765 [==============================] - 15s 91us/step - loss: 0.0279 - val_loss: 0.0274\n",
      "Epoch 31/100\n",
      "163765/163765 [==============================] - 15s 92us/step - loss: 0.0278 - val_loss: 0.0274\n",
      "Epoch 32/100\n",
      "163765/163765 [==============================] - 15s 90us/step - loss: 0.0276 - val_loss: 0.0274\n",
      "Epoch 33/100\n",
      "163765/163765 [==============================] - 15s 93us/step - loss: 0.0275 - val_loss: 0.0273\n",
      "Epoch 34/100\n",
      "163765/163765 [==============================] - 15s 91us/step - loss: 0.0273 - val_loss: 0.0271\n",
      "Epoch 35/100\n",
      "163765/163765 [==============================] - 15s 92us/step - loss: 0.0273 - val_loss: 0.0270\n",
      "Epoch 36/100\n",
      "163765/163765 [==============================] - 15s 91us/step - loss: 0.0271 - val_loss: 0.0265\n",
      "Epoch 37/100\n",
      "163765/163765 [==============================] - 16s 95us/step - loss: 0.0272 - val_loss: 0.0270\n",
      "Epoch 38/100\n",
      "163765/163765 [==============================] - 16s 97us/step - loss: 0.0270 - val_loss: 0.0268\n",
      "Epoch 39/100\n",
      "163765/163765 [==============================] - 15s 93us/step - loss: 0.0269 - val_loss: 0.0267\n",
      "Epoch 40/100\n",
      "163765/163765 [==============================] - 15s 93us/step - loss: 0.0267 - val_loss: 0.0265\n",
      "Epoch 41/100\n",
      "163765/163765 [==============================] - 15s 89us/step - loss: 0.0267 - val_loss: 0.0265\n",
      "Epoch 42/100\n",
      "163765/163765 [==============================] - 15s 89us/step - loss: 0.0265 - val_loss: 0.0263\n",
      "Epoch 43/100\n",
      "163765/163765 [==============================] - 15s 92us/step - loss: 0.0264 - val_loss: 0.0267\n",
      "Epoch 44/100\n",
      "163765/163765 [==============================] - 15s 92us/step - loss: 0.0265 - val_loss: 0.0265\n",
      "Epoch 45/100\n",
      "163765/163765 [==============================] - 15s 93us/step - loss: 0.0264 - val_loss: 0.0264\n",
      "Epoch 46/100\n",
      "163765/163765 [==============================] - 16s 96us/step - loss: 0.0263 - val_loss: 0.0259\n",
      "Epoch 47/100\n",
      "163765/163765 [==============================] - 15s 92us/step - loss: 0.0261 - val_loss: 0.0261\n",
      "Epoch 48/100\n",
      "163765/163765 [==============================] - 15s 93us/step - loss: 0.0261 - val_loss: 0.0260\n",
      "Epoch 49/100\n",
      "163765/163765 [==============================] - 15s 94us/step - loss: 0.0261 - val_loss: 0.0263\n",
      "Epoch 50/100\n",
      "163765/163765 [==============================] - 15s 94us/step - loss: 0.0260 - val_loss: 0.0261\n",
      "perc99.25SubjectF2andFold3\n",
      "221979\n",
      "71897\n",
      "Train on 137482 samples, validate on 44218 samples\n",
      "Epoch 1/100\n",
      "137482/137482 [==============================] - 14s 105us/step - loss: 0.0544 - val_loss: 0.0400\n",
      "Epoch 2/100\n",
      "137482/137482 [==============================] - 10s 72us/step - loss: 0.0438 - val_loss: 0.0367\n",
      "Epoch 3/100\n",
      "137482/137482 [==============================] - 11s 81us/step - loss: 0.0422 - val_loss: 0.0364\n",
      "Epoch 4/100\n",
      "137482/137482 [==============================] - 11s 79us/step - loss: 0.0413 - val_loss: 0.0360\n",
      "Epoch 5/100\n",
      "137482/137482 [==============================] - 11s 80us/step - loss: 0.0406 - val_loss: 0.0366\n",
      "Epoch 6/100\n",
      "137482/137482 [==============================] - 11s 82us/step - loss: 0.0400 - val_loss: 0.0356\n",
      "Epoch 7/100\n",
      "137482/137482 [==============================] - 11s 81us/step - loss: 0.0394 - val_loss: 0.0368\n",
      "Epoch 8/100\n",
      "137482/137482 [==============================] - 11s 79us/step - loss: 0.0391 - val_loss: 0.0356\n",
      "Epoch 9/100\n",
      "137482/137482 [==============================] - 11s 82us/step - loss: 0.0385 - val_loss: 0.0346\n",
      "Epoch 10/100\n",
      "137482/137482 [==============================] - 11s 78us/step - loss: 0.0382 - val_loss: 0.0338\n",
      "Epoch 11/100\n",
      "137482/137482 [==============================] - 10s 74us/step - loss: 0.0378 - val_loss: 0.0342\n",
      "Epoch 12/100\n",
      "137482/137482 [==============================] - 11s 79us/step - loss: 0.0376 - val_loss: 0.0336\n",
      "Epoch 13/100\n",
      "137482/137482 [==============================] - 11s 77us/step - loss: 0.0372 - val_loss: 0.0338\n",
      "Epoch 14/100\n",
      "137482/137482 [==============================] - 11s 82us/step - loss: 0.0368 - val_loss: 0.0344\n",
      "Epoch 15/100\n",
      "137482/137482 [==============================] - 12s 84us/step - loss: 0.0365 - val_loss: 0.0332\n",
      "Epoch 16/100\n",
      "137482/137482 [==============================] - 11s 78us/step - loss: 0.0363 - val_loss: 0.0332\n",
      "Epoch 17/100\n",
      "137482/137482 [==============================] - 12s 89us/step - loss: 0.0361 - val_loss: 0.0328\n",
      "Epoch 18/100\n",
      "137482/137482 [==============================] - 12s 87us/step - loss: 0.0358 - val_loss: 0.0324\n",
      "Epoch 19/100\n",
      "137482/137482 [==============================] - 11s 81us/step - loss: 0.0356 - val_loss: 0.0316\n",
      "Epoch 20/100\n",
      "137482/137482 [==============================] - 11s 82us/step - loss: 0.0353 - val_loss: 0.0318\n",
      "Epoch 21/100\n",
      "137482/137482 [==============================] - 11s 80us/step - loss: 0.0351 - val_loss: 0.0323\n",
      "Epoch 22/100\n",
      "137482/137482 [==============================] - 11s 81us/step - loss: 0.0350 - val_loss: 0.0331\n",
      "Epoch 23/100\n",
      "137482/137482 [==============================] - 11s 81us/step - loss: 0.0347 - val_loss: 0.0317\n",
      "perc99.25SubjectF2andFold4\n",
      "207844\n",
      "71256\n",
      "Train on 123122 samples, validate on 41439 samples\n",
      "Epoch 1/100\n",
      "123122/123122 [==============================] - 13s 107us/step - loss: 0.0505 - val_loss: 0.0408\n",
      "Epoch 2/100\n",
      "123122/123122 [==============================] - 10s 81us/step - loss: 0.0380 - val_loss: 0.0399\n",
      "Epoch 3/100\n",
      "123122/123122 [==============================] - 10s 83us/step - loss: 0.0362 - val_loss: 0.0392\n",
      "Epoch 4/100\n",
      "123122/123122 [==============================] - 10s 81us/step - loss: 0.0352 - val_loss: 0.0366\n",
      "Epoch 5/100\n",
      "123122/123122 [==============================] - 10s 81us/step - loss: 0.0344 - val_loss: 0.0362\n",
      "Epoch 6/100\n",
      "123122/123122 [==============================] - 10s 84us/step - loss: 0.0338 - val_loss: 0.0355\n",
      "Epoch 7/100\n",
      "123122/123122 [==============================] - 9s 76us/step - loss: 0.0333 - val_loss: 0.0350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      "123122/123122 [==============================] - 9s 71us/step - loss: 0.0327 - val_loss: 0.0342\n",
      "Epoch 9/100\n",
      "123122/123122 [==============================] - 9s 72us/step - loss: 0.0322 - val_loss: 0.0333\n",
      "Epoch 10/100\n",
      "123122/123122 [==============================] - 9s 74us/step - loss: 0.0316 - val_loss: 0.0337\n",
      "Epoch 11/100\n",
      "123122/123122 [==============================] - 10s 79us/step - loss: 0.0314 - val_loss: 0.0331\n",
      "Epoch 12/100\n",
      "123122/123122 [==============================] - 10s 79us/step - loss: 0.0308 - val_loss: 0.0326\n",
      "Epoch 13/100\n",
      "123122/123122 [==============================] - 9s 76us/step - loss: 0.0305 - val_loss: 0.0333\n",
      "Epoch 14/100\n",
      "123122/123122 [==============================] - 10s 81us/step - loss: 0.0301 - val_loss: 0.0334\n",
      "Epoch 15/100\n",
      "123122/123122 [==============================] - 10s 81us/step - loss: 0.0298 - val_loss: 0.0320\n",
      "Epoch 16/100\n",
      "123122/123122 [==============================] - 10s 80us/step - loss: 0.0294 - val_loss: 0.0323\n",
      "Epoch 17/100\n",
      "123122/123122 [==============================] - 10s 79us/step - loss: 0.0292 - val_loss: 0.0320\n",
      "Epoch 18/100\n",
      "123122/123122 [==============================] - 10s 82us/step - loss: 0.0289 - val_loss: 0.0312\n",
      "Epoch 19/100\n",
      "123122/123122 [==============================] - 10s 80us/step - loss: 0.0286 - val_loss: 0.0304\n",
      "Epoch 20/100\n",
      "123122/123122 [==============================] - 10s 80us/step - loss: 0.0284 - val_loss: 0.0318\n",
      "Epoch 21/100\n",
      "123122/123122 [==============================] - 10s 82us/step - loss: 0.0283 - val_loss: 0.0308\n",
      "Epoch 22/100\n",
      "123122/123122 [==============================] - 10s 79us/step - loss: 0.0281 - val_loss: 0.0306\n",
      "Epoch 23/100\n",
      "123122/123122 [==============================] - 10s 80us/step - loss: 0.0278 - val_loss: 0.0313\n",
      "perc99.25SubjectM1andFold1\n",
      "265640\n",
      "88894\n",
      "Train on 224094 samples, validate on 75523 samples\n",
      "Epoch 1/100\n",
      "224094/224094 [==============================] - 21s 94us/step - loss: 0.0538 - val_loss: 0.0467\n",
      "Epoch 2/100\n",
      "224094/224094 [==============================] - 18s 79us/step - loss: 0.0445 - val_loss: 0.0426\n",
      "Epoch 3/100\n",
      "224094/224094 [==============================] - 19s 84us/step - loss: 0.0424 - val_loss: 0.0414\n",
      "Epoch 4/100\n",
      "224094/224094 [==============================] - 18s 81us/step - loss: 0.0411 - val_loss: 0.0401\n",
      "Epoch 5/100\n",
      "224094/224094 [==============================] - 18s 80us/step - loss: 0.0401 - val_loss: 0.0389\n",
      "Epoch 6/100\n",
      "224094/224094 [==============================] - 19s 83us/step - loss: 0.0393 - val_loss: 0.0384\n",
      "Epoch 7/100\n",
      "224094/224094 [==============================] - 19s 83us/step - loss: 0.0386 - val_loss: 0.0370\n",
      "Epoch 8/100\n",
      "224094/224094 [==============================] - 19s 85us/step - loss: 0.0380 - val_loss: 0.0368\n",
      "Epoch 9/100\n",
      "224094/224094 [==============================] - 19s 83us/step - loss: 0.0375 - val_loss: 0.0361\n",
      "Epoch 10/100\n",
      "224094/224094 [==============================] - 19s 83us/step - loss: 0.0369 - val_loss: 0.0364\n",
      "Epoch 11/100\n",
      "224094/224094 [==============================] - 19s 84us/step - loss: 0.0366 - val_loss: 0.0354\n",
      "Epoch 12/100\n",
      "224094/224094 [==============================] - 19s 85us/step - loss: 0.0361 - val_loss: 0.0357\n",
      "Epoch 13/100\n",
      "224094/224094 [==============================] - 19s 87us/step - loss: 0.0358 - val_loss: 0.0344\n",
      "Epoch 14/100\n",
      "224094/224094 [==============================] - 19s 86us/step - loss: 0.0354 - val_loss: 0.0346\n",
      "Epoch 15/100\n",
      "224094/224094 [==============================] - 19s 86us/step - loss: 0.0350 - val_loss: 0.0337\n",
      "Epoch 16/100\n",
      "224094/224094 [==============================] - 19s 86us/step - loss: 0.0347 - val_loss: 0.0337\n",
      "Epoch 17/100\n",
      "224094/224094 [==============================] - 19s 85us/step - loss: 0.0345 - val_loss: 0.0342\n",
      "Epoch 18/100\n",
      "224094/224094 [==============================] - 19s 87us/step - loss: 0.0342 - val_loss: 0.0331\n",
      "Epoch 19/100\n",
      "224094/224094 [==============================] - 19s 86us/step - loss: 0.0339 - val_loss: 0.0326\n",
      "Epoch 20/100\n",
      "224094/224094 [==============================] - 19s 86us/step - loss: 0.0338 - val_loss: 0.0327\n",
      "Epoch 21/100\n",
      "224094/224094 [==============================] - 19s 86us/step - loss: 0.0335 - val_loss: 0.0322\n",
      "Epoch 22/100\n",
      "224094/224094 [==============================] - 20s 87us/step - loss: 0.0333 - val_loss: 0.0330\n",
      "Epoch 23/100\n",
      "224094/224094 [==============================] - 19s 87us/step - loss: 0.0332 - val_loss: 0.0326\n",
      "Epoch 24/100\n",
      "224094/224094 [==============================] - 19s 87us/step - loss: 0.0329 - val_loss: 0.0328\n",
      "Epoch 25/100\n",
      "224094/224094 [==============================] - 19s 86us/step - loss: 0.0329 - val_loss: 0.0322\n",
      "Epoch 26/100\n",
      "224094/224094 [==============================] - 20s 88us/step - loss: 0.0326 - val_loss: 0.0319\n",
      "Epoch 27/100\n",
      "224094/224094 [==============================] - 19s 87us/step - loss: 0.0325 - val_loss: 0.0319\n",
      "Epoch 28/100\n",
      "224094/224094 [==============================] - 20s 88us/step - loss: 0.0324 - val_loss: 0.0314\n",
      "Epoch 29/100\n",
      "224094/224094 [==============================] - 20s 87us/step - loss: 0.0323 - val_loss: 0.0314\n",
      "Epoch 30/100\n",
      "224094/224094 [==============================] - 19s 87us/step - loss: 0.0320 - val_loss: 0.0314\n",
      "Epoch 31/100\n",
      "224094/224094 [==============================] - 20s 87us/step - loss: 0.0318 - val_loss: 0.0312\n",
      "Epoch 32/100\n",
      "224094/224094 [==============================] - 19s 86us/step - loss: 0.0317 - val_loss: 0.0309\n",
      "Epoch 33/100\n",
      "224094/224094 [==============================] - 20s 88us/step - loss: 0.0317 - val_loss: 0.0316\n",
      "Epoch 34/100\n",
      "224094/224094 [==============================] - 20s 87us/step - loss: 0.0315 - val_loss: 0.0311\n",
      "Epoch 35/100\n",
      "224094/224094 [==============================] - 20s 88us/step - loss: 0.0314 - val_loss: 0.0312\n",
      "Epoch 36/100\n",
      "224094/224094 [==============================] - 19s 87us/step - loss: 0.0313 - val_loss: 0.0309\n",
      "perc99.25SubjectM1andFold2\n",
      "316623\n",
      "105131\n",
      "Train on 135707 samples, validate on 43680 samples\n",
      "Epoch 1/100\n",
      "135707/135707 [==============================] - 15s 108us/step - loss: 0.0517 - val_loss: 0.0371\n",
      "Epoch 2/100\n",
      "135707/135707 [==============================] - 12s 89us/step - loss: 0.0388 - val_loss: 0.0356\n",
      "Epoch 3/100\n",
      "135707/135707 [==============================] - 11s 79us/step - loss: 0.0359 - val_loss: 0.0334\n",
      "Epoch 4/100\n",
      "135707/135707 [==============================] - 11s 83us/step - loss: 0.0341 - val_loss: 0.0313\n",
      "Epoch 5/100\n",
      "135707/135707 [==============================] - 12s 86us/step - loss: 0.0327 - val_loss: 0.0308\n",
      "Epoch 6/100\n",
      "135707/135707 [==============================] - 11s 84us/step - loss: 0.0314 - val_loss: 0.0290\n",
      "Epoch 7/100\n",
      "135707/135707 [==============================] - 11s 83us/step - loss: 0.0302 - val_loss: 0.0276\n",
      "Epoch 8/100\n",
      "135707/135707 [==============================] - 11s 84us/step - loss: 0.0293 - val_loss: 0.0273\n",
      "Epoch 9/100\n",
      "135707/135707 [==============================] - 11s 79us/step - loss: 0.0287 - val_loss: 0.0265\n",
      "Epoch 10/100\n",
      "135707/135707 [==============================] - 12s 88us/step - loss: 0.0277 - val_loss: 0.0267\n",
      "Epoch 11/100\n",
      "135707/135707 [==============================] - 12s 91us/step - loss: 0.0272 - val_loss: 0.0252\n",
      "Epoch 12/100\n",
      "135707/135707 [==============================] - 14s 100us/step - loss: 0.0266 - val_loss: 0.0261\n",
      "Epoch 13/100\n",
      "135707/135707 [==============================] - 14s 100us/step - loss: 0.0262 - val_loss: 0.0241\n",
      "Epoch 14/100\n",
      "135707/135707 [==============================] - 12s 90us/step - loss: 0.0257 - val_loss: 0.0258\n",
      "Epoch 15/100\n",
      "135707/135707 [==============================] - 12s 90us/step - loss: 0.0254 - val_loss: 0.0242\n",
      "Epoch 16/100\n",
      "135707/135707 [==============================] - 12s 89us/step - loss: 0.0249 - val_loss: 0.0244\n",
      "Epoch 17/100\n",
      "135707/135707 [==============================] - 12s 90us/step - loss: 0.0247 - val_loss: 0.0235\n",
      "Epoch 18/100\n",
      "135707/135707 [==============================] - 12s 89us/step - loss: 0.0244 - val_loss: 0.0231\n",
      "Epoch 19/100\n",
      "135707/135707 [==============================] - 12s 91us/step - loss: 0.0240 - val_loss: 0.0224\n",
      "Epoch 20/100\n",
      "135707/135707 [==============================] - 12s 89us/step - loss: 0.0237 - val_loss: 0.0234\n",
      "Epoch 21/100\n",
      "135707/135707 [==============================] - 12s 91us/step - loss: 0.0236 - val_loss: 0.0228\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135707/135707 [==============================] - 12s 91us/step - loss: 0.0234 - val_loss: 0.0219\n",
      "Epoch 23/100\n",
      "135707/135707 [==============================] - 13s 94us/step - loss: 0.0233 - val_loss: 0.0225\n",
      "Epoch 24/100\n",
      "135707/135707 [==============================] - 13s 96us/step - loss: 0.0232 - val_loss: 0.0218\n",
      "Epoch 25/100\n",
      "135707/135707 [==============================] - 13s 93us/step - loss: 0.0229 - val_loss: 0.0227\n",
      "Epoch 26/100\n",
      "135707/135707 [==============================] - 12s 92us/step - loss: 0.0227 - val_loss: 0.0222\n",
      "Epoch 27/100\n",
      "135707/135707 [==============================] - 12s 90us/step - loss: 0.0224 - val_loss: 0.0217\n",
      "Epoch 28/100\n",
      "135707/135707 [==============================] - 12s 91us/step - loss: 0.0224 - val_loss: 0.0222\n",
      "Epoch 29/100\n",
      "135707/135707 [==============================] - 13s 99us/step - loss: 0.0223 - val_loss: 0.0217\n",
      "Epoch 30/100\n",
      "135707/135707 [==============================] - 14s 100us/step - loss: 0.0221 - val_loss: 0.0211\n",
      "Epoch 31/100\n",
      "135707/135707 [==============================] - 12s 91us/step - loss: 0.0220 - val_loss: 0.0212\n",
      "Epoch 32/100\n",
      "135707/135707 [==============================] - 11s 83us/step - loss: 0.0219 - val_loss: 0.0214\n",
      "Epoch 33/100\n",
      "135707/135707 [==============================] - 11s 83us/step - loss: 0.0218 - val_loss: 0.0206\n",
      "Epoch 34/100\n",
      "135707/135707 [==============================] - 11s 78us/step - loss: 0.0216 - val_loss: 0.0214\n",
      "Epoch 35/100\n",
      "135707/135707 [==============================] - 11s 83us/step - loss: 0.0216 - val_loss: 0.0211\n",
      "Epoch 36/100\n",
      "135707/135707 [==============================] - 11s 82us/step - loss: 0.0215 - val_loss: 0.0211\n",
      "Epoch 37/100\n",
      "135707/135707 [==============================] - 12s 85us/step - loss: 0.0213 - val_loss: 0.0210\n",
      "perc99.25SubjectM1andFold3\n",
      "231827\n",
      "76292\n",
      "Train on 143700 samples, validate on 44814 samples\n",
      "Epoch 1/100\n",
      "143700/143700 [==============================] - 16s 111us/step - loss: 0.0535 - val_loss: 0.0357\n",
      "Epoch 2/100\n",
      "143700/143700 [==============================] - 12s 82us/step - loss: 0.0410 - val_loss: 0.0327\n",
      "Epoch 3/100\n",
      "143700/143700 [==============================] - 12s 80us/step - loss: 0.0386 - val_loss: 0.0318\n",
      "Epoch 4/100\n",
      "143700/143700 [==============================] - 12s 82us/step - loss: 0.0371 - val_loss: 0.0306\n",
      "Epoch 5/100\n",
      "143700/143700 [==============================] - 12s 81us/step - loss: 0.0357 - val_loss: 0.0296\n",
      "Epoch 6/100\n",
      "143700/143700 [==============================] - 14s 95us/step - loss: 0.0346 - val_loss: 0.0296\n",
      "Epoch 7/100\n",
      "143700/143700 [==============================] - 14s 95us/step - loss: 0.0340 - val_loss: 0.0272\n",
      "Epoch 8/100\n",
      "143700/143700 [==============================] - 14s 96us/step - loss: 0.0331 - val_loss: 0.0268\n",
      "Epoch 9/100\n",
      "143700/143700 [==============================] - 13s 93us/step - loss: 0.0325 - val_loss: 0.0266\n",
      "Epoch 10/100\n",
      "143700/143700 [==============================] - 14s 94us/step - loss: 0.0321 - val_loss: 0.0273\n",
      "Epoch 11/100\n",
      "143700/143700 [==============================] - 14s 95us/step - loss: 0.0317 - val_loss: 0.0268\n",
      "Epoch 12/100\n",
      "143700/143700 [==============================] - 14s 97us/step - loss: 0.0312 - val_loss: 0.0260\n",
      "Epoch 13/100\n",
      "143700/143700 [==============================] - 14s 95us/step - loss: 0.0310 - val_loss: 0.0252\n",
      "Epoch 14/100\n",
      "143700/143700 [==============================] - 14s 97us/step - loss: 0.0306 - val_loss: 0.0262\n",
      "Epoch 15/100\n",
      "143700/143700 [==============================] - 14s 96us/step - loss: 0.0304 - val_loss: 0.0260\n",
      "Epoch 16/100\n",
      "143700/143700 [==============================] - 13s 93us/step - loss: 0.0302 - val_loss: 0.0259\n",
      "Epoch 17/100\n",
      "143700/143700 [==============================] - 13s 90us/step - loss: 0.0298 - val_loss: 0.0254\n",
      "perc99.25SubjectM1andFold4\n",
      "278410\n",
      "92409\n",
      "Train on 156124 samples, validate on 50634 samples\n",
      "Epoch 1/100\n",
      "156124/156124 [==============================] - 18s 118us/step - loss: 0.0462 - val_loss: 0.0333\n",
      "Epoch 2/100\n",
      "156124/156124 [==============================] - 15s 97us/step - loss: 0.0346 - val_loss: 0.0306\n",
      "Epoch 3/100\n",
      "156124/156124 [==============================] - 15s 99us/step - loss: 0.0320 - val_loss: 0.0291\n",
      "Epoch 4/100\n",
      "156124/156124 [==============================] - 15s 95us/step - loss: 0.0307 - val_loss: 0.0278\n",
      "Epoch 5/100\n",
      "156124/156124 [==============================] - 15s 97us/step - loss: 0.0297 - val_loss: 0.0280\n",
      "Epoch 6/100\n",
      "156124/156124 [==============================] - 15s 97us/step - loss: 0.0288 - val_loss: 0.0273\n",
      "Epoch 7/100\n",
      "156124/156124 [==============================] - 15s 97us/step - loss: 0.0281 - val_loss: 0.0255\n",
      "Epoch 8/100\n",
      "156124/156124 [==============================] - 15s 98us/step - loss: 0.0277 - val_loss: 0.0259\n",
      "Epoch 9/100\n",
      "156124/156124 [==============================] - 15s 99us/step - loss: 0.0271 - val_loss: 0.0250\n",
      "Epoch 10/100\n",
      "156124/156124 [==============================] - 15s 99us/step - loss: 0.0268 - val_loss: 0.0252\n",
      "Epoch 11/100\n",
      "156124/156124 [==============================] - 15s 94us/step - loss: 0.0264 - val_loss: 0.0247\n",
      "Epoch 12/100\n",
      "156124/156124 [==============================] - 15s 94us/step - loss: 0.0261 - val_loss: 0.0247\n",
      "Epoch 13/100\n",
      "156124/156124 [==============================] - 15s 95us/step - loss: 0.0257 - val_loss: 0.0248\n",
      "Epoch 14/100\n",
      "156124/156124 [==============================] - 15s 94us/step - loss: 0.0255 - val_loss: 0.0244\n",
      "Epoch 15/100\n",
      "156124/156124 [==============================] - 15s 97us/step - loss: 0.0253 - val_loss: 0.0235\n",
      "Epoch 16/100\n",
      "156124/156124 [==============================] - 14s 92us/step - loss: 0.0251 - val_loss: 0.0241\n",
      "Epoch 17/100\n",
      "156124/156124 [==============================] - 15s 94us/step - loss: 0.0248 - val_loss: 0.0240\n",
      "Epoch 18/100\n",
      "156124/156124 [==============================] - 15s 95us/step - loss: 0.0246 - val_loss: 0.0230\n",
      "Epoch 19/100\n",
      "156124/156124 [==============================] - 17s 108us/step - loss: 0.0244 - val_loss: 0.0231\n",
      "Epoch 20/100\n",
      "156124/156124 [==============================] - 16s 105us/step - loss: 0.0242 - val_loss: 0.0233\n",
      "Epoch 21/100\n",
      "156124/156124 [==============================] - 16s 104us/step - loss: 0.0241 - val_loss: 0.0229\n",
      "Epoch 22/100\n",
      "156124/156124 [==============================] - 16s 101us/step - loss: 0.0239 - val_loss: 0.0230\n",
      "Epoch 23/100\n",
      "156124/156124 [==============================] - 16s 104us/step - loss: 0.0238 - val_loss: 0.0229\n",
      "Epoch 24/100\n",
      "156124/156124 [==============================] - 17s 106us/step - loss: 0.0236 - val_loss: 0.0234\n",
      "Epoch 25/100\n",
      "156124/156124 [==============================] - 17s 107us/step - loss: 0.0235 - val_loss: 0.0224\n",
      "Epoch 26/100\n",
      "156124/156124 [==============================] - 18s 116us/step - loss: 0.0234 - val_loss: 0.0227\n",
      "Epoch 27/100\n",
      "156124/156124 [==============================] - 17s 110us/step - loss: 0.0233 - val_loss: 0.0223\n",
      "Epoch 28/100\n",
      "156124/156124 [==============================] - 17s 110us/step - loss: 0.0232 - val_loss: 0.0226\n",
      "Epoch 29/100\n",
      "156124/156124 [==============================] - 17s 110us/step - loss: 0.0230 - val_loss: 0.0225\n",
      "Epoch 30/100\n",
      "156124/156124 [==============================] - 17s 106us/step - loss: 0.0229 - val_loss: 0.0218\n",
      "Epoch 31/100\n",
      "156124/156124 [==============================] - 16s 102us/step - loss: 0.0228 - val_loss: 0.0217\n",
      "Epoch 32/100\n",
      "156124/156124 [==============================] - 16s 102us/step - loss: 0.0227 - val_loss: 0.0220\n",
      "Epoch 33/100\n",
      "156124/156124 [==============================] - 16s 104us/step - loss: 0.0225 - val_loss: 0.0217\n",
      "Epoch 34/100\n",
      "156124/156124 [==============================] - 16s 104us/step - loss: 0.0225 - val_loss: 0.0221\n",
      "Epoch 35/100\n",
      "156124/156124 [==============================] - 16s 105us/step - loss: 0.0224 - val_loss: 0.0220\n",
      "perc99.25SubjectM2andFold1\n",
      "260078\n",
      "81823\n",
      "Train on 233875 samples, validate on 74327 samples\n",
      "Epoch 1/100\n",
      "233875/233875 [==============================] - 28s 118us/step - loss: 0.0566 - val_loss: 0.0470\n",
      "Epoch 2/100\n",
      "233875/233875 [==============================] - 24s 104us/step - loss: 0.0469 - val_loss: 0.0450\n",
      "Epoch 3/100\n",
      "233875/233875 [==============================] - 24s 105us/step - loss: 0.0442 - val_loss: 0.0419\n",
      "Epoch 4/100\n",
      "233875/233875 [==============================] - 25s 105us/step - loss: 0.0425 - val_loss: 0.0404\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233875/233875 [==============================] - 24s 104us/step - loss: 0.0412 - val_loss: 0.0396\n",
      "Epoch 6/100\n",
      "233875/233875 [==============================] - 25s 106us/step - loss: 0.0403 - val_loss: 0.0391\n",
      "Epoch 7/100\n",
      "233875/233875 [==============================] - 23s 99us/step - loss: 0.0394 - val_loss: 0.0381\n",
      "Epoch 8/100\n",
      "233875/233875 [==============================] - 22s 93us/step - loss: 0.0386 - val_loss: 0.0374\n",
      "Epoch 9/100\n",
      "233875/233875 [==============================] - 22s 93us/step - loss: 0.0379 - val_loss: 0.0368\n",
      "Epoch 10/100\n",
      "233875/233875 [==============================] - 22s 94us/step - loss: 0.0372 - val_loss: 0.0373\n",
      "Epoch 11/100\n",
      "233875/233875 [==============================] - 22s 95us/step - loss: 0.0368 - val_loss: 0.0360\n",
      "Epoch 12/100\n",
      "233875/233875 [==============================] - 22s 95us/step - loss: 0.0363 - val_loss: 0.0353\n",
      "Epoch 13/100\n",
      "233875/233875 [==============================] - 23s 98us/step - loss: 0.0357 - val_loss: 0.0354\n",
      "Epoch 14/100\n",
      "233875/233875 [==============================] - 22s 95us/step - loss: 0.0355 - val_loss: 0.0346\n",
      "Epoch 15/100\n",
      "233875/233875 [==============================] - 22s 95us/step - loss: 0.0349 - val_loss: 0.0345\n",
      "Epoch 16/100\n",
      "233875/233875 [==============================] - 23s 97us/step - loss: 0.0347 - val_loss: 0.0344\n",
      "Epoch 17/100\n",
      "233875/233875 [==============================] - 26s 110us/step - loss: 0.0343 - val_loss: 0.0335\n",
      "Epoch 18/100\n",
      "233875/233875 [==============================] - 27s 114us/step - loss: 0.0338 - val_loss: 0.0335\n",
      "Epoch 19/100\n",
      "233875/233875 [==============================] - 25s 106us/step - loss: 0.0338 - val_loss: 0.0336\n",
      "Epoch 20/100\n",
      "233875/233875 [==============================] - 24s 105us/step - loss: 0.0333 - val_loss: 0.0328\n",
      "Epoch 21/100\n",
      "233875/233875 [==============================] - 24s 105us/step - loss: 0.0331 - val_loss: 0.0329\n",
      "Epoch 22/100\n",
      "233875/233875 [==============================] - 24s 101us/step - loss: 0.0329 - val_loss: 0.0334\n",
      "Epoch 23/100\n",
      "233875/233875 [==============================] - 22s 94us/step - loss: 0.0326 - val_loss: 0.0336\n",
      "Epoch 24/100\n",
      "233875/233875 [==============================] - 22s 92us/step - loss: 0.0324 - val_loss: 0.0325\n",
      "Epoch 25/100\n",
      "233875/233875 [==============================] - 22s 94us/step - loss: 0.0324 - val_loss: 0.0329\n",
      "Epoch 26/100\n",
      "233875/233875 [==============================] - 22s 95us/step - loss: 0.0322 - val_loss: 0.0320\n",
      "Epoch 27/100\n",
      "233875/233875 [==============================] - 22s 95us/step - loss: 0.0320 - val_loss: 0.0321\n",
      "Epoch 28/100\n",
      "233875/233875 [==============================] - 22s 95us/step - loss: 0.0318 - val_loss: 0.0322\n",
      "Epoch 29/100\n",
      "233875/233875 [==============================] - 22s 95us/step - loss: 0.0318 - val_loss: 0.0317\n",
      "Epoch 30/100\n",
      "233875/233875 [==============================] - 23s 96us/step - loss: 0.0315 - val_loss: 0.0313\n",
      "Epoch 31/100\n",
      "233875/233875 [==============================] - 22s 95us/step - loss: 0.0313 - val_loss: 0.0324\n",
      "Epoch 32/100\n",
      "233875/233875 [==============================] - 22s 95us/step - loss: 0.0312 - val_loss: 0.0314\n",
      "Epoch 33/100\n",
      "233875/233875 [==============================] - 22s 94us/step - loss: 0.0312 - val_loss: 0.0312\n",
      "Epoch 34/100\n",
      "233875/233875 [==============================] - 22s 96us/step - loss: 0.0309 - val_loss: 0.0315\n",
      "Epoch 35/100\n",
      "233875/233875 [==============================] - 22s 96us/step - loss: 0.0308 - val_loss: 0.0313\n",
      "Epoch 36/100\n",
      "233875/233875 [==============================] - 22s 95us/step - loss: 0.0308 - val_loss: 0.0307\n",
      "Epoch 37/100\n",
      "233875/233875 [==============================] - 22s 96us/step - loss: 0.0307 - val_loss: 0.0308\n",
      "Epoch 38/100\n",
      "233875/233875 [==============================] - 20s 85us/step - loss: 0.0304 - val_loss: 0.0308\n",
      "Epoch 39/100\n",
      "233875/233875 [==============================] - 19s 82us/step - loss: 0.0304 - val_loss: 0.0304\n",
      "Epoch 40/100\n",
      "233875/233875 [==============================] - 19s 82us/step - loss: 0.0304 - val_loss: 0.0303\n",
      "Epoch 41/100\n",
      "233875/233875 [==============================] - 19s 82us/step - loss: 0.0303 - val_loss: 0.0311\n",
      "Epoch 42/100\n",
      "233875/233875 [==============================] - 19s 80us/step - loss: 0.0301 - val_loss: 0.0305\n",
      "Epoch 43/100\n",
      "233875/233875 [==============================] - 19s 82us/step - loss: 0.0302 - val_loss: 0.0303\n",
      "Epoch 44/100\n",
      "233875/233875 [==============================] - 19s 81us/step - loss: 0.0301 - val_loss: 0.0304\n",
      "perc99.25SubjectM2andFold2\n",
      "266826\n",
      "89847\n",
      "Train on 166957 samples, validate on 54706 samples\n",
      "Epoch 1/100\n",
      "166957/166957 [==============================] - 17s 103us/step - loss: 0.0512 - val_loss: 0.0410\n",
      "Epoch 2/100\n",
      "166957/166957 [==============================] - 14s 86us/step - loss: 0.0395 - val_loss: 0.0376\n",
      "Epoch 3/100\n",
      "166957/166957 [==============================] - 14s 84us/step - loss: 0.0363 - val_loss: 0.0355\n",
      "Epoch 4/100\n",
      "166957/166957 [==============================] - 14s 85us/step - loss: 0.0339 - val_loss: 0.0331\n",
      "Epoch 5/100\n",
      "166957/166957 [==============================] - 14s 82us/step - loss: 0.0323 - val_loss: 0.0322\n",
      "Epoch 6/100\n",
      "166957/166957 [==============================] - 14s 84us/step - loss: 0.0312 - val_loss: 0.0323\n",
      "Epoch 7/100\n",
      "166957/166957 [==============================] - 14s 82us/step - loss: 0.0302 - val_loss: 0.0328\n",
      "Epoch 8/100\n",
      "166957/166957 [==============================] - 14s 86us/step - loss: 0.0294 - val_loss: 0.0305\n",
      "Epoch 9/100\n",
      "166957/166957 [==============================] - 14s 85us/step - loss: 0.0287 - val_loss: 0.0302\n",
      "Epoch 10/100\n",
      "166957/166957 [==============================] - 14s 87us/step - loss: 0.0281 - val_loss: 0.0295\n",
      "Epoch 11/100\n",
      "166957/166957 [==============================] - 14s 85us/step - loss: 0.0277 - val_loss: 0.0286\n",
      "Epoch 12/100\n",
      "166957/166957 [==============================] - 14s 85us/step - loss: 0.0272 - val_loss: 0.0278\n",
      "Epoch 13/100\n",
      "166957/166957 [==============================] - 14s 86us/step - loss: 0.0268 - val_loss: 0.0276\n",
      "Epoch 14/100\n",
      "166957/166957 [==============================] - 14s 86us/step - loss: 0.0264 - val_loss: 0.0273\n",
      "Epoch 15/100\n",
      "166957/166957 [==============================] - 14s 84us/step - loss: 0.0261 - val_loss: 0.0268\n",
      "Epoch 16/100\n",
      "166957/166957 [==============================] - 14s 84us/step - loss: 0.0257 - val_loss: 0.0266\n",
      "Epoch 17/100\n",
      "166957/166957 [==============================] - 13s 78us/step - loss: 0.0255 - val_loss: 0.0264\n",
      "Epoch 18/100\n",
      "166957/166957 [==============================] - 14s 84us/step - loss: 0.0252 - val_loss: 0.0265\n",
      "Epoch 19/100\n",
      "166957/166957 [==============================] - 15s 92us/step - loss: 0.0249 - val_loss: 0.0263\n",
      "Epoch 20/100\n",
      "166957/166957 [==============================] - 14s 85us/step - loss: 0.0247 - val_loss: 0.0264\n",
      "Epoch 21/100\n",
      "166957/166957 [==============================] - 15s 87us/step - loss: 0.0246 - val_loss: 0.0261\n",
      "Epoch 22/100\n",
      "166957/166957 [==============================] - 14s 86us/step - loss: 0.0242 - val_loss: 0.0250\n",
      "Epoch 23/100\n",
      "166957/166957 [==============================] - 15s 87us/step - loss: 0.0240 - val_loss: 0.0248\n",
      "Epoch 24/100\n",
      "166957/166957 [==============================] - 15s 88us/step - loss: 0.0238 - val_loss: 0.0248\n",
      "Epoch 25/100\n",
      "166957/166957 [==============================] - 16s 93us/step - loss: 0.0237 - val_loss: 0.0246\n",
      "Epoch 26/100\n",
      "166957/166957 [==============================] - 15s 88us/step - loss: 0.0235 - val_loss: 0.0247\n",
      "Epoch 27/100\n",
      "166957/166957 [==============================] - 14s 86us/step - loss: 0.0233 - val_loss: 0.0246\n",
      "Epoch 28/100\n",
      "166957/166957 [==============================] - 14s 83us/step - loss: 0.0231 - val_loss: 0.0245\n",
      "Epoch 29/100\n",
      "166957/166957 [==============================] - 15s 93us/step - loss: 0.0230 - val_loss: 0.0238\n",
      "Epoch 30/100\n",
      "166957/166957 [==============================] - 14s 85us/step - loss: 0.0229 - val_loss: 0.0240\n",
      "Epoch 31/100\n",
      "166957/166957 [==============================] - 14s 84us/step - loss: 0.0227 - val_loss: 0.0242\n",
      "Epoch 32/100\n",
      "166957/166957 [==============================] - 14s 85us/step - loss: 0.0226 - val_loss: 0.0239\n",
      "Epoch 33/100\n",
      "166957/166957 [==============================] - 14s 84us/step - loss: 0.0225 - val_loss: 0.0237\n",
      "Epoch 34/100\n",
      "166957/166957 [==============================] - 14s 86us/step - loss: 0.0224 - val_loss: 0.0241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100\n",
      "166957/166957 [==============================] - 14s 83us/step - loss: 0.0222 - val_loss: 0.0234\n",
      "Epoch 36/100\n",
      "166957/166957 [==============================] - 15s 91us/step - loss: 0.0221 - val_loss: 0.0231\n",
      "Epoch 37/100\n",
      "166957/166957 [==============================] - 14s 85us/step - loss: 0.0220 - val_loss: 0.0233\n",
      "Epoch 38/100\n",
      "166957/166957 [==============================] - 14s 85us/step - loss: 0.0218 - val_loss: 0.0228\n",
      "Epoch 39/100\n",
      "166957/166957 [==============================] - 14s 87us/step - loss: 0.0218 - val_loss: 0.0232\n",
      "Epoch 40/100\n",
      "166957/166957 [==============================] - 16s 94us/step - loss: 0.0217 - val_loss: 0.0234\n",
      "Epoch 41/100\n",
      "166957/166957 [==============================] - 14s 86us/step - loss: 0.0215 - val_loss: 0.0231\n",
      "Epoch 42/100\n",
      "166957/166957 [==============================] - 14s 86us/step - loss: 0.0216 - val_loss: 0.0225\n",
      "Epoch 43/100\n",
      "166957/166957 [==============================] - 14s 86us/step - loss: 0.0215 - val_loss: 0.0223\n",
      "Epoch 44/100\n",
      "166957/166957 [==============================] - 14s 83us/step - loss: 0.0214 - val_loss: 0.0230\n",
      "Epoch 45/100\n",
      "166957/166957 [==============================] - 14s 83us/step - loss: 0.0212 - val_loss: 0.0227\n",
      "Epoch 46/100\n",
      "166957/166957 [==============================] - 13s 80us/step - loss: 0.0212 - val_loss: 0.0220\n",
      "Epoch 47/100\n",
      "166957/166957 [==============================] - 14s 83us/step - loss: 0.0210 - val_loss: 0.0222\n",
      "Epoch 48/100\n",
      "166957/166957 [==============================] - 13s 79us/step - loss: 0.0210 - val_loss: 0.0226\n",
      "Epoch 49/100\n",
      "166957/166957 [==============================] - 13s 81us/step - loss: 0.0209 - val_loss: 0.0223\n",
      "Epoch 50/100\n",
      "166957/166957 [==============================] - 15s 88us/step - loss: 0.0208 - val_loss: 0.0223\n",
      "perc99.25SubjectM2andFold3\n",
      "240580\n",
      "79674\n",
      "Train on 158872 samples, validate on 52920 samples\n",
      "Epoch 1/100\n",
      "158872/158872 [==============================] - 17s 107us/step - loss: 0.0582 - val_loss: 0.0466\n",
      "Epoch 2/100\n",
      "158872/158872 [==============================] - 14s 88us/step - loss: 0.0480 - val_loss: 0.0428\n",
      "Epoch 3/100\n",
      "158872/158872 [==============================] - 14s 86us/step - loss: 0.0453 - val_loss: 0.0399\n",
      "Epoch 4/100\n",
      "158872/158872 [==============================] - 14s 88us/step - loss: 0.0433 - val_loss: 0.0380\n",
      "Epoch 5/100\n",
      "158872/158872 [==============================] - 14s 86us/step - loss: 0.0420 - val_loss: 0.0387\n",
      "Epoch 6/100\n",
      "158872/158872 [==============================] - 14s 87us/step - loss: 0.0408 - val_loss: 0.0367\n",
      "Epoch 7/100\n",
      "158872/158872 [==============================] - 14s 87us/step - loss: 0.0398 - val_loss: 0.0357\n",
      "Epoch 8/100\n",
      "158872/158872 [==============================] - 14s 88us/step - loss: 0.0391 - val_loss: 0.0343\n",
      "Epoch 9/100\n",
      "158872/158872 [==============================] - 14s 87us/step - loss: 0.0384 - val_loss: 0.0348\n",
      "Epoch 10/100\n",
      "158872/158872 [==============================] - 14s 87us/step - loss: 0.0376 - val_loss: 0.0336\n",
      "Epoch 11/100\n",
      "158872/158872 [==============================] - 14s 86us/step - loss: 0.0370 - val_loss: 0.0327\n",
      "Epoch 12/100\n",
      "158872/158872 [==============================] - 14s 89us/step - loss: 0.0364 - val_loss: 0.0327\n",
      "Epoch 13/100\n",
      "158872/158872 [==============================] - 14s 88us/step - loss: 0.0360 - val_loss: 0.0319\n",
      "Epoch 14/100\n",
      "158872/158872 [==============================] - 14s 86us/step - loss: 0.0356 - val_loss: 0.0322\n",
      "Epoch 15/100\n",
      "158872/158872 [==============================] - 14s 86us/step - loss: 0.0354 - val_loss: 0.0325\n",
      "Epoch 16/100\n",
      "158872/158872 [==============================] - 14s 88us/step - loss: 0.0350 - val_loss: 0.0314\n",
      "Epoch 17/100\n",
      "158872/158872 [==============================] - 14s 86us/step - loss: 0.0347 - val_loss: 0.0309\n",
      "Epoch 18/100\n",
      "158872/158872 [==============================] - 14s 87us/step - loss: 0.0343 - val_loss: 0.0306\n",
      "Epoch 19/100\n",
      "158872/158872 [==============================] - 14s 86us/step - loss: 0.0340 - val_loss: 0.0307\n",
      "Epoch 20/100\n",
      "158872/158872 [==============================] - 14s 86us/step - loss: 0.0338 - val_loss: 0.0316\n",
      "Epoch 21/100\n",
      "158872/158872 [==============================] - 14s 88us/step - loss: 0.0336 - val_loss: 0.0304\n",
      "Epoch 22/100\n",
      "158872/158872 [==============================] - 14s 86us/step - loss: 0.0333 - val_loss: 0.0303\n",
      "Epoch 23/100\n",
      "158872/158872 [==============================] - 14s 86us/step - loss: 0.0331 - val_loss: 0.0299\n",
      "Epoch 24/100\n",
      "158872/158872 [==============================] - 13s 83us/step - loss: 0.0329 - val_loss: 0.0299\n",
      "Epoch 25/100\n",
      "158872/158872 [==============================] - 14s 85us/step - loss: 0.0327 - val_loss: 0.0302\n",
      "Epoch 26/100\n",
      "158872/158872 [==============================] - 13s 85us/step - loss: 0.0325 - val_loss: 0.0296\n",
      "Epoch 27/100\n",
      "158872/158872 [==============================] - 14s 87us/step - loss: 0.0324 - val_loss: 0.0303\n",
      "Epoch 28/100\n",
      "158872/158872 [==============================] - 13s 84us/step - loss: 0.0322 - val_loss: 0.0292\n",
      "Epoch 29/100\n",
      "158872/158872 [==============================] - 14s 87us/step - loss: 0.0318 - val_loss: 0.0294\n",
      "Epoch 30/100\n",
      "158872/158872 [==============================] - 12s 77us/step - loss: 0.0318 - val_loss: 0.0288\n",
      "Epoch 31/100\n",
      "158872/158872 [==============================] - 13s 84us/step - loss: 0.0317 - val_loss: 0.0289\n",
      "Epoch 32/100\n",
      "158872/158872 [==============================] - 13s 81us/step - loss: 0.0314 - val_loss: 0.0290\n",
      "Epoch 33/100\n",
      "158872/158872 [==============================] - 13s 81us/step - loss: 0.0313 - val_loss: 0.0296\n",
      "Epoch 34/100\n",
      "158872/158872 [==============================] - 13s 84us/step - loss: 0.0312 - val_loss: 0.0289\n",
      "perc99.25SubjectM2andFold4\n",
      "237309\n",
      "78463\n",
      "Train on 159084 samples, validate on 51647 samples\n",
      "Epoch 1/100\n",
      "159084/159084 [==============================] - 17s 110us/step - loss: 0.0543 - val_loss: 0.0407\n",
      "Epoch 2/100\n",
      "159084/159084 [==============================] - 14s 86us/step - loss: 0.0438 - val_loss: 0.0372\n",
      "Epoch 3/100\n",
      "159084/159084 [==============================] - 14s 87us/step - loss: 0.0409 - val_loss: 0.0363\n",
      "Epoch 4/100\n",
      "159084/159084 [==============================] - 14s 86us/step - loss: 0.0387 - val_loss: 0.0339\n",
      "Epoch 5/100\n",
      "159084/159084 [==============================] - 14s 91us/step - loss: 0.0369 - val_loss: 0.0328\n",
      "Epoch 6/100\n",
      "159084/159084 [==============================] - 13s 85us/step - loss: 0.0357 - val_loss: 0.0308\n",
      "Epoch 7/100\n",
      "159084/159084 [==============================] - 12s 78us/step - loss: 0.0347 - val_loss: 0.0315\n",
      "Epoch 8/100\n",
      "159084/159084 [==============================] - 13s 80us/step - loss: 0.0338 - val_loss: 0.0309\n",
      "Epoch 9/100\n",
      "159084/159084 [==============================] - 12s 79us/step - loss: 0.0330 - val_loss: 0.0295\n",
      "Epoch 10/100\n",
      "159084/159084 [==============================] - 12s 76us/step - loss: 0.0325 - val_loss: 0.0283\n",
      "Epoch 11/100\n",
      "159084/159084 [==============================] - 13s 79us/step - loss: 0.0318 - val_loss: 0.0288\n",
      "Epoch 12/100\n",
      "159084/159084 [==============================] - 13s 80us/step - loss: 0.0312 - val_loss: 0.0289\n",
      "Epoch 13/100\n",
      "159084/159084 [==============================] - 12s 77us/step - loss: 0.0309 - val_loss: 0.0282\n",
      "Epoch 14/100\n",
      "159084/159084 [==============================] - 13s 80us/step - loss: 0.0305 - val_loss: 0.0275\n",
      "Epoch 15/100\n",
      "159084/159084 [==============================] - 13s 84us/step - loss: 0.0301 - val_loss: 0.0285\n",
      "Epoch 16/100\n",
      "159084/159084 [==============================] - 14s 87us/step - loss: 0.0297 - val_loss: 0.0271\n",
      "Epoch 17/100\n",
      "159084/159084 [==============================] - 13s 84us/step - loss: 0.0294 - val_loss: 0.0275\n",
      "Epoch 18/100\n",
      "159084/159084 [==============================] - 14s 86us/step - loss: 0.0291 - val_loss: 0.0277\n",
      "Epoch 19/100\n",
      "159084/159084 [==============================] - 14s 88us/step - loss: 0.0287 - val_loss: 0.0270\n",
      "Epoch 20/100\n",
      "159084/159084 [==============================] - 14s 87us/step - loss: 0.0286 - val_loss: 0.0266\n",
      "Epoch 21/100\n",
      "159084/159084 [==============================] - 14s 89us/step - loss: 0.0283 - val_loss: 0.0263\n",
      "Epoch 22/100\n",
      "159084/159084 [==============================] - 14s 89us/step - loss: 0.0281 - val_loss: 0.0262\n",
      "Epoch 23/100\n",
      "159084/159084 [==============================] - 13s 85us/step - loss: 0.0279 - val_loss: 0.0263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "159084/159084 [==============================] - 13s 82us/step - loss: 0.0276 - val_loss: 0.0259\n",
      "Epoch 25/100\n",
      "159084/159084 [==============================] - 13s 83us/step - loss: 0.0276 - val_loss: 0.0254\n",
      "Epoch 26/100\n",
      "159084/159084 [==============================] - 13s 84us/step - loss: 0.0274 - val_loss: 0.0263\n",
      "Epoch 27/100\n",
      "159084/159084 [==============================] - 14s 85us/step - loss: 0.0272 - val_loss: 0.0253\n",
      "Epoch 28/100\n",
      "159084/159084 [==============================] - 13s 85us/step - loss: 0.0271 - val_loss: 0.0251\n",
      "Epoch 29/100\n",
      "159084/159084 [==============================] - 13s 81us/step - loss: 0.0268 - val_loss: 0.0254\n",
      "Epoch 30/100\n",
      "159084/159084 [==============================] - 13s 84us/step - loss: 0.0268 - val_loss: 0.0256\n",
      "Epoch 31/100\n",
      "159084/159084 [==============================] - 14s 87us/step - loss: 0.0267 - val_loss: 0.0254\n",
      "Epoch 32/100\n",
      "159084/159084 [==============================] - 14s 89us/step - loss: 0.0264 - val_loss: 0.0259\n",
      "perc99.5SubjectF1andFold1\n",
      "268071\n",
      "86291\n",
      "Train on 239378 samples, validate on 77778 samples\n",
      "Epoch 1/100\n",
      "239378/239378 [==============================] - 23s 98us/step - loss: 0.0512 - val_loss: 0.0452\n",
      "Epoch 2/100\n",
      "239378/239378 [==============================] - 20s 85us/step - loss: 0.0416 - val_loss: 0.0417\n",
      "Epoch 3/100\n",
      "239378/239378 [==============================] - 21s 86us/step - loss: 0.0395 - val_loss: 0.0413\n",
      "Epoch 4/100\n",
      "239378/239378 [==============================] - 21s 86us/step - loss: 0.0379 - val_loss: 0.0385\n",
      "Epoch 5/100\n",
      "239378/239378 [==============================] - 20s 84us/step - loss: 0.0366 - val_loss: 0.0381\n",
      "Epoch 6/100\n",
      "239378/239378 [==============================] - 20s 85us/step - loss: 0.0356 - val_loss: 0.0361\n",
      "Epoch 7/100\n",
      "239378/239378 [==============================] - 21s 87us/step - loss: 0.0344 - val_loss: 0.0357\n",
      "Epoch 8/100\n",
      "239378/239378 [==============================] - 20s 85us/step - loss: 0.0334 - val_loss: 0.0346\n",
      "Epoch 9/100\n",
      "239378/239378 [==============================] - 20s 84us/step - loss: 0.0326 - val_loss: 0.0341\n",
      "Epoch 10/100\n",
      "239378/239378 [==============================] - 22s 91us/step - loss: 0.0319 - val_loss: 0.0323\n",
      "Epoch 11/100\n",
      "239378/239378 [==============================] - 21s 87us/step - loss: 0.0311 - val_loss: 0.0333\n",
      "Epoch 12/100\n",
      "239378/239378 [==============================] - 20s 84us/step - loss: 0.0306 - val_loss: 0.0316\n",
      "Epoch 13/100\n",
      "239378/239378 [==============================] - 20s 84us/step - loss: 0.0300 - val_loss: 0.0318\n",
      "Epoch 14/100\n",
      "239378/239378 [==============================] - 20s 85us/step - loss: 0.0296 - val_loss: 0.0307\n",
      "Epoch 15/100\n",
      "239378/239378 [==============================] - 21s 88us/step - loss: 0.0291 - val_loss: 0.0304\n",
      "Epoch 16/100\n",
      "239378/239378 [==============================] - 21s 89us/step - loss: 0.0288 - val_loss: 0.0308\n",
      "Epoch 17/100\n",
      "239378/239378 [==============================] - 21s 89us/step - loss: 0.0284 - val_loss: 0.0296\n",
      "Epoch 18/100\n",
      "239378/239378 [==============================] - 24s 100us/step - loss: 0.0280 - val_loss: 0.0295\n",
      "Epoch 19/100\n",
      "239378/239378 [==============================] - 25s 104us/step - loss: 0.0278 - val_loss: 0.0297\n",
      "Epoch 20/100\n",
      "239378/239378 [==============================] - 21s 90us/step - loss: 0.0274 - val_loss: 0.0289\n",
      "Epoch 21/100\n",
      "239378/239378 [==============================] - 20s 82us/step - loss: 0.0271 - val_loss: 0.0294\n",
      "Epoch 22/100\n",
      "239378/239378 [==============================] - 20s 82us/step - loss: 0.0268 - val_loss: 0.0284\n",
      "Epoch 23/100\n",
      "239378/239378 [==============================] - 23s 95us/step - loss: 0.0267 - val_loss: 0.0280\n",
      "Epoch 24/100\n",
      "239378/239378 [==============================] - 23s 97us/step - loss: 0.0265 - val_loss: 0.0288\n",
      "Epoch 25/100\n",
      "239378/239378 [==============================] - 23s 95us/step - loss: 0.0263 - val_loss: 0.0280\n",
      "Epoch 26/100\n",
      "239378/239378 [==============================] - 24s 101us/step - loss: 0.0261 - val_loss: 0.0278\n",
      "Epoch 27/100\n",
      "239378/239378 [==============================] - 23s 96us/step - loss: 0.0260 - val_loss: 0.0279\n",
      "Epoch 28/100\n",
      "239378/239378 [==============================] - 24s 100us/step - loss: 0.0258 - val_loss: 0.0278\n",
      "Epoch 29/100\n",
      "239378/239378 [==============================] - 23s 97us/step - loss: 0.0256 - val_loss: 0.0278\n",
      "Epoch 30/100\n",
      "239378/239378 [==============================] - 22s 91us/step - loss: 0.0255 - val_loss: 0.0269\n",
      "Epoch 31/100\n",
      "239378/239378 [==============================] - 22s 90us/step - loss: 0.0253 - val_loss: 0.0272\n",
      "Epoch 32/100\n",
      "239378/239378 [==============================] - 22s 91us/step - loss: 0.0252 - val_loss: 0.0271\n",
      "Epoch 33/100\n",
      "239378/239378 [==============================] - 22s 94us/step - loss: 0.0251 - val_loss: 0.0269\n",
      "Epoch 34/100\n",
      "239378/239378 [==============================] - 22s 92us/step - loss: 0.0248 - val_loss: 0.0269\n",
      "perc99.5SubjectF1andFold2\n",
      "285925\n",
      "94513\n",
      "Train on 104135 samples, validate on 33001 samples\n",
      "Epoch 1/100\n",
      "104135/104135 [==============================] - 13s 127us/step - loss: 0.0619 - val_loss: 0.0494\n",
      "Epoch 2/100\n",
      "104135/104135 [==============================] - 10s 92us/step - loss: 0.0453 - val_loss: 0.0465\n",
      "Epoch 3/100\n",
      "104135/104135 [==============================] - 9s 90us/step - loss: 0.0411 - val_loss: 0.0403\n",
      "Epoch 4/100\n",
      "104135/104135 [==============================] - 10s 93us/step - loss: 0.0381 - val_loss: 0.0401\n",
      "Epoch 5/100\n",
      "104135/104135 [==============================] - 10s 92us/step - loss: 0.0360 - val_loss: 0.0379\n",
      "Epoch 6/100\n",
      "104135/104135 [==============================] - 9s 90us/step - loss: 0.0344 - val_loss: 0.0366\n",
      "Epoch 7/100\n",
      "104135/104135 [==============================] - 10s 97us/step - loss: 0.0330 - val_loss: 0.0347\n",
      "Epoch 8/100\n",
      "104135/104135 [==============================] - 9s 89us/step - loss: 0.0320 - val_loss: 0.0364\n",
      "Epoch 9/100\n",
      "104135/104135 [==============================] - 10s 92us/step - loss: 0.0307 - val_loss: 0.0327\n",
      "Epoch 10/100\n",
      "104135/104135 [==============================] - 9s 91us/step - loss: 0.0299 - val_loss: 0.0324\n",
      "Epoch 11/100\n",
      "104135/104135 [==============================] - 10s 96us/step - loss: 0.0291 - val_loss: 0.0325\n",
      "Epoch 12/100\n",
      "104135/104135 [==============================] - 10s 97us/step - loss: 0.0282 - val_loss: 0.0326\n",
      "Epoch 13/100\n",
      "104135/104135 [==============================] - 10s 97us/step - loss: 0.0273 - val_loss: 0.0312\n",
      "Epoch 14/100\n",
      "104135/104135 [==============================] - 10s 98us/step - loss: 0.0267 - val_loss: 0.0302\n",
      "Epoch 15/100\n",
      "104135/104135 [==============================] - 10s 97us/step - loss: 0.0263 - val_loss: 0.0311\n",
      "Epoch 16/100\n",
      "104135/104135 [==============================] - 10s 100us/step - loss: 0.0258 - val_loss: 0.0290\n",
      "Epoch 17/100\n",
      "104135/104135 [==============================] - 10s 96us/step - loss: 0.0253 - val_loss: 0.0306\n",
      "Epoch 18/100\n",
      "104135/104135 [==============================] - 10s 100us/step - loss: 0.0247 - val_loss: 0.0291\n",
      "Epoch 19/100\n",
      "104135/104135 [==============================] - 10s 99us/step - loss: 0.0244 - val_loss: 0.0285\n",
      "Epoch 20/100\n",
      "104135/104135 [==============================] - 10s 99us/step - loss: 0.0242 - val_loss: 0.0281\n",
      "Epoch 21/100\n",
      "104135/104135 [==============================] - 10s 92us/step - loss: 0.0237 - val_loss: 0.0307\n",
      "Epoch 22/100\n",
      "104135/104135 [==============================] - 9s 90us/step - loss: 0.0234 - val_loss: 0.0292\n",
      "Epoch 23/100\n",
      "104135/104135 [==============================] - 10s 93us/step - loss: 0.0232 - val_loss: 0.0286\n",
      "Epoch 24/100\n",
      "104135/104135 [==============================] - 10s 92us/step - loss: 0.0228 - val_loss: 0.0281\n",
      "perc99.5SubjectF1andFold3\n",
      "220751\n",
      "72690\n",
      "Train on 196746 samples, validate on 64669 samples\n",
      "Epoch 1/100\n",
      "196746/196746 [==============================] - 23s 117us/step - loss: 0.0541 - val_loss: 0.0463\n",
      "Epoch 2/100\n",
      "196746/196746 [==============================] - 19s 98us/step - loss: 0.0441 - val_loss: 0.0401\n",
      "Epoch 3/100\n",
      "196746/196746 [==============================] - 19s 98us/step - loss: 0.0416 - val_loss: 0.0385\n",
      "Epoch 4/100\n",
      "196746/196746 [==============================] - 20s 100us/step - loss: 0.0398 - val_loss: 0.0382\n",
      "Epoch 5/100\n",
      "196746/196746 [==============================] - 19s 95us/step - loss: 0.0385 - val_loss: 0.0361\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196746/196746 [==============================] - 20s 100us/step - loss: 0.0374 - val_loss: 0.0390\n",
      "Epoch 7/100\n",
      "196746/196746 [==============================] - 18s 94us/step - loss: 0.0363 - val_loss: 0.0351\n",
      "Epoch 8/100\n",
      "196746/196746 [==============================] - 17s 87us/step - loss: 0.0356 - val_loss: 0.0355\n",
      "Epoch 9/100\n",
      "196746/196746 [==============================] - 17s 88us/step - loss: 0.0347 - val_loss: 0.0332\n",
      "Epoch 10/100\n",
      "196746/196746 [==============================] - 17s 87us/step - loss: 0.0340 - val_loss: 0.0332\n",
      "Epoch 11/100\n",
      "196746/196746 [==============================] - 18s 89us/step - loss: 0.0334 - val_loss: 0.0332\n",
      "Epoch 12/100\n",
      "196746/196746 [==============================] - 17s 87us/step - loss: 0.0329 - val_loss: 0.0317\n",
      "Epoch 13/100\n",
      "196746/196746 [==============================] - 18s 89us/step - loss: 0.0323 - val_loss: 0.0313\n",
      "Epoch 14/100\n",
      "196746/196746 [==============================] - 17s 88us/step - loss: 0.0320 - val_loss: 0.0323\n",
      "Epoch 15/100\n",
      "196746/196746 [==============================] - 17s 88us/step - loss: 0.0315 - val_loss: 0.0303\n",
      "Epoch 16/100\n",
      "196746/196746 [==============================] - 17s 88us/step - loss: 0.0312 - val_loss: 0.0305\n",
      "Epoch 17/100\n",
      "196746/196746 [==============================] - 17s 87us/step - loss: 0.0308 - val_loss: 0.0297\n",
      "Epoch 18/100\n",
      "196746/196746 [==============================] - 18s 89us/step - loss: 0.0304 - val_loss: 0.0299\n",
      "Epoch 19/100\n",
      "196746/196746 [==============================] - 17s 86us/step - loss: 0.0302 - val_loss: 0.0302\n",
      "Epoch 20/100\n",
      "196746/196746 [==============================] - 18s 91us/step - loss: 0.0299 - val_loss: 0.0298\n",
      "Epoch 21/100\n",
      "196746/196746 [==============================] - 16s 83us/step - loss: 0.0298 - val_loss: 0.0298\n",
      "perc99.5SubjectF1andFold4\n",
      "222438\n",
      "74698\n",
      "Train on 110379 samples, validate on 36574 samples\n",
      "Epoch 1/100\n",
      "110379/110379 [==============================] - 15s 132us/step - loss: 0.0553 - val_loss: 0.0446\n",
      "Epoch 2/100\n",
      "110379/110379 [==============================] - 9s 84us/step - loss: 0.0420 - val_loss: 0.0406\n",
      "Epoch 3/100\n",
      "110379/110379 [==============================] - 9s 84us/step - loss: 0.0384 - val_loss: 0.0405\n",
      "Epoch 4/100\n",
      "110379/110379 [==============================] - 10s 87us/step - loss: 0.0359 - val_loss: 0.0361\n",
      "Epoch 5/100\n",
      "110379/110379 [==============================] - 9s 81us/step - loss: 0.0343 - val_loss: 0.0364\n",
      "Epoch 6/100\n",
      "110379/110379 [==============================] - 10s 88us/step - loss: 0.0328 - val_loss: 0.0332\n",
      "Epoch 7/100\n",
      "110379/110379 [==============================] - 10s 87us/step - loss: 0.0317 - val_loss: 0.0327\n",
      "Epoch 8/100\n",
      "110379/110379 [==============================] - 9s 84us/step - loss: 0.0308 - val_loss: 0.0326\n",
      "Epoch 9/100\n",
      "110379/110379 [==============================] - 10s 90us/step - loss: 0.0299 - val_loss: 0.0319\n",
      "Epoch 10/100\n",
      "110379/110379 [==============================] - 10s 88us/step - loss: 0.0294 - val_loss: 0.0308\n",
      "Epoch 11/100\n",
      "110379/110379 [==============================] - 10s 94us/step - loss: 0.0286 - val_loss: 0.0305\n",
      "Epoch 12/100\n",
      "110379/110379 [==============================] - 10s 89us/step - loss: 0.0282 - val_loss: 0.0292\n",
      "Epoch 13/100\n",
      "110379/110379 [==============================] - 10s 88us/step - loss: 0.0276 - val_loss: 0.0289\n",
      "Epoch 14/100\n",
      "110379/110379 [==============================] - 9s 86us/step - loss: 0.0270 - val_loss: 0.0306\n",
      "Epoch 15/100\n",
      "110379/110379 [==============================] - 9s 85us/step - loss: 0.0267 - val_loss: 0.0286\n",
      "Epoch 16/100\n",
      "110379/110379 [==============================] - 9s 86us/step - loss: 0.0261 - val_loss: 0.0277\n",
      "Epoch 17/100\n",
      "110379/110379 [==============================] - 10s 86us/step - loss: 0.0258 - val_loss: 0.0275\n",
      "Epoch 18/100\n",
      "110379/110379 [==============================] - 9s 86us/step - loss: 0.0254 - val_loss: 0.0275\n",
      "Epoch 19/100\n",
      "110379/110379 [==============================] - 9s 85us/step - loss: 0.0252 - val_loss: 0.0275\n",
      "Epoch 20/100\n",
      "110379/110379 [==============================] - 10s 88us/step - loss: 0.0250 - val_loss: 0.0273\n",
      "Epoch 21/100\n",
      "110379/110379 [==============================] - 9s 85us/step - loss: 0.0246 - val_loss: 0.0266\n",
      "Epoch 22/100\n",
      "110379/110379 [==============================] - 9s 84us/step - loss: 0.0243 - val_loss: 0.0262\n",
      "Epoch 23/100\n",
      "110379/110379 [==============================] - 9s 86us/step - loss: 0.0239 - val_loss: 0.0258\n",
      "Epoch 24/100\n",
      "110379/110379 [==============================] - 10s 87us/step - loss: 0.0237 - val_loss: 0.0259\n",
      "Epoch 25/100\n",
      "110379/110379 [==============================] - 10s 88us/step - loss: 0.0235 - val_loss: 0.0261\n",
      "Epoch 26/100\n",
      "110379/110379 [==============================] - 9s 85us/step - loss: 0.0233 - val_loss: 0.0261\n",
      "Epoch 27/100\n",
      "110379/110379 [==============================] - 10s 88us/step - loss: 0.0232 - val_loss: 0.0271\n",
      "perc99.5SubjectF2andFold1\n",
      "231804\n",
      "74737\n",
      "Train on 142345 samples, validate on 46056 samples\n",
      "Epoch 1/100\n",
      "142345/142345 [==============================] - 20s 144us/step - loss: 0.0507 - val_loss: 0.0412\n",
      "Epoch 2/100\n",
      "142345/142345 [==============================] - 15s 102us/step - loss: 0.0409 - val_loss: 0.0396\n",
      "Epoch 3/100\n",
      "142345/142345 [==============================] - 13s 92us/step - loss: 0.0396 - val_loss: 0.0408\n",
      "Epoch 4/100\n",
      "142345/142345 [==============================] - 13s 92us/step - loss: 0.0387 - val_loss: 0.0368\n",
      "Epoch 5/100\n",
      "142345/142345 [==============================] - 12s 87us/step - loss: 0.0378 - val_loss: 0.0372\n",
      "Epoch 6/100\n",
      "142345/142345 [==============================] - 13s 90us/step - loss: 0.0372 - val_loss: 0.0355\n",
      "Epoch 7/100\n",
      "142345/142345 [==============================] - 13s 91us/step - loss: 0.0365 - val_loss: 0.0345\n",
      "Epoch 8/100\n",
      "142345/142345 [==============================] - 13s 88us/step - loss: 0.0358 - val_loss: 0.0349\n",
      "Epoch 9/100\n",
      "142345/142345 [==============================] - 13s 90us/step - loss: 0.0353 - val_loss: 0.0343\n",
      "Epoch 10/100\n",
      "142345/142345 [==============================] - 13s 88us/step - loss: 0.0346 - val_loss: 0.0337\n",
      "Epoch 11/100\n",
      "142345/142345 [==============================] - 15s 102us/step - loss: 0.0340 - val_loss: 0.0330\n",
      "Epoch 12/100\n",
      "142345/142345 [==============================] - 15s 103us/step - loss: 0.0336 - val_loss: 0.0343\n",
      "Epoch 13/100\n",
      "142345/142345 [==============================] - 15s 103us/step - loss: 0.0332 - val_loss: 0.0322\n",
      "Epoch 14/100\n",
      "142345/142345 [==============================] - 14s 100us/step - loss: 0.0328 - val_loss: 0.0330\n",
      "Epoch 15/100\n",
      "142345/142345 [==============================] - 13s 91us/step - loss: 0.0325 - val_loss: 0.0323\n",
      "Epoch 16/100\n",
      "142345/142345 [==============================] - 14s 101us/step - loss: 0.0323 - val_loss: 0.0320\n",
      "Epoch 17/100\n",
      "142345/142345 [==============================] - 14s 100us/step - loss: 0.0319 - val_loss: 0.0316\n",
      "Epoch 18/100\n",
      "142345/142345 [==============================] - 14s 98us/step - loss: 0.0316 - val_loss: 0.0322\n",
      "Epoch 19/100\n",
      "142345/142345 [==============================] - 14s 100us/step - loss: 0.0314 - val_loss: 0.0313\n",
      "Epoch 20/100\n",
      "142345/142345 [==============================] - 15s 102us/step - loss: 0.0312 - val_loss: 0.0313\n",
      "Epoch 21/100\n",
      "142345/142345 [==============================] - 14s 98us/step - loss: 0.0310 - val_loss: 0.0310\n",
      "Epoch 22/100\n",
      "142345/142345 [==============================] - 14s 100us/step - loss: 0.0308 - val_loss: 0.0309\n",
      "Epoch 23/100\n",
      "142345/142345 [==============================] - 14s 100us/step - loss: 0.0306 - val_loss: 0.0310\n",
      "Epoch 24/100\n",
      "142345/142345 [==============================] - 14s 100us/step - loss: 0.0303 - val_loss: 0.0302\n",
      "Epoch 25/100\n",
      "142345/142345 [==============================] - 14s 99us/step - loss: 0.0302 - val_loss: 0.0301\n",
      "Epoch 26/100\n",
      "142345/142345 [==============================] - 14s 98us/step - loss: 0.0299 - val_loss: 0.0306\n",
      "Epoch 27/100\n",
      "142345/142345 [==============================] - 14s 98us/step - loss: 0.0299 - val_loss: 0.0299\n",
      "Epoch 28/100\n",
      "142345/142345 [==============================] - 14s 99us/step - loss: 0.0297 - val_loss: 0.0301\n",
      "Epoch 29/100\n",
      "142345/142345 [==============================] - 14s 100us/step - loss: 0.0296 - val_loss: 0.0303\n",
      "Epoch 30/100\n",
      "142345/142345 [==============================] - 14s 100us/step - loss: 0.0295 - val_loss: 0.0296\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142345/142345 [==============================] - 14s 99us/step - loss: 0.0292 - val_loss: 0.0296\n",
      "Epoch 32/100\n",
      "142345/142345 [==============================] - 14s 99us/step - loss: 0.0291 - val_loss: 0.0295\n",
      "Epoch 33/100\n",
      "142345/142345 [==============================] - 14s 99us/step - loss: 0.0289 - val_loss: 0.0294\n",
      "Epoch 34/100\n",
      "142345/142345 [==============================] - 14s 101us/step - loss: 0.0289 - val_loss: 0.0296\n",
      "Epoch 35/100\n",
      "142345/142345 [==============================] - 14s 98us/step - loss: 0.0288 - val_loss: 0.0291\n",
      "Epoch 36/100\n",
      "142345/142345 [==============================] - 14s 101us/step - loss: 0.0288 - val_loss: 0.0293\n",
      "Epoch 37/100\n",
      "142345/142345 [==============================] - 15s 108us/step - loss: 0.0285 - val_loss: 0.0292\n",
      "Epoch 38/100\n",
      "142345/142345 [==============================] - 16s 113us/step - loss: 0.0282 - val_loss: 0.0290\n",
      "Epoch 39/100\n",
      "142345/142345 [==============================] - 15s 107us/step - loss: 0.0283 - val_loss: 0.0295\n",
      "Epoch 40/100\n",
      "142345/142345 [==============================] - 14s 98us/step - loss: 0.0281 - val_loss: 0.0288\n",
      "Epoch 41/100\n",
      "142345/142345 [==============================] - 14s 100us/step - loss: 0.0280 - val_loss: 0.0288\n",
      "Epoch 42/100\n",
      "142345/142345 [==============================] - 14s 96us/step - loss: 0.0279 - val_loss: 0.0287\n",
      "Epoch 43/100\n",
      "142345/142345 [==============================] - 14s 100us/step - loss: 0.0278 - val_loss: 0.0289\n",
      "Epoch 44/100\n",
      "142345/142345 [==============================] - 14s 99us/step - loss: 0.0278 - val_loss: 0.0284\n",
      "Epoch 45/100\n",
      "142345/142345 [==============================] - 14s 99us/step - loss: 0.0277 - val_loss: 0.0290\n",
      "Epoch 46/100\n",
      "142345/142345 [==============================] - 14s 100us/step - loss: 0.0276 - val_loss: 0.0286\n",
      "Epoch 47/100\n",
      "142345/142345 [==============================] - 14s 98us/step - loss: 0.0275 - val_loss: 0.0284\n",
      "Epoch 48/100\n",
      "142345/142345 [==============================] - 14s 100us/step - loss: 0.0274 - val_loss: 0.0283\n",
      "Epoch 49/100\n",
      "142345/142345 [==============================] - 14s 101us/step - loss: 0.0271 - val_loss: 0.0281\n",
      "Epoch 50/100\n",
      "142345/142345 [==============================] - 14s 102us/step - loss: 0.0273 - val_loss: 0.0280\n",
      "Epoch 51/100\n",
      "142345/142345 [==============================] - 14s 101us/step - loss: 0.0270 - val_loss: 0.0282\n",
      "Epoch 52/100\n",
      "142345/142345 [==============================] - 14s 99us/step - loss: 0.0271 - val_loss: 0.0280\n",
      "Epoch 53/100\n",
      "142345/142345 [==============================] - 14s 98us/step - loss: 0.0270 - val_loss: 0.0283\n",
      "Epoch 54/100\n",
      "142345/142345 [==============================] - 14s 101us/step - loss: 0.0269 - val_loss: 0.0278\n",
      "Epoch 55/100\n",
      "142345/142345 [==============================] - 14s 100us/step - loss: 0.0268 - val_loss: 0.0284\n",
      "Epoch 56/100\n",
      "142345/142345 [==============================] - 14s 101us/step - loss: 0.0268 - val_loss: 0.0280\n",
      "Epoch 57/100\n",
      "142345/142345 [==============================] - 14s 100us/step - loss: 0.0267 - val_loss: 0.0279\n",
      "Epoch 58/100\n",
      "142345/142345 [==============================] - 14s 99us/step - loss: 0.0266 - val_loss: 0.0285\n",
      "perc99.5SubjectF2andFold2\n",
      "271692\n",
      "92569\n",
      "Train on 164529 samples, validate on 56820 samples\n",
      "Epoch 1/100\n",
      "164529/164529 [==============================] - 19s 117us/step - loss: 0.0485 - val_loss: 0.0377\n",
      "Epoch 2/100\n",
      "164529/164529 [==============================] - 15s 90us/step - loss: 0.0395 - val_loss: 0.0364\n",
      "Epoch 3/100\n",
      "164529/164529 [==============================] - 15s 94us/step - loss: 0.0381 - val_loss: 0.0359\n",
      "Epoch 4/100\n",
      "164529/164529 [==============================] - 15s 94us/step - loss: 0.0370 - val_loss: 0.0346\n",
      "Epoch 5/100\n",
      "164529/164529 [==============================] - 15s 90us/step - loss: 0.0361 - val_loss: 0.0333\n",
      "Epoch 6/100\n",
      "164529/164529 [==============================] - 17s 102us/step - loss: 0.0353 - val_loss: 0.0337\n",
      "Epoch 7/100\n",
      "164529/164529 [==============================] - 17s 104us/step - loss: 0.0345 - val_loss: 0.0326\n",
      "Epoch 8/100\n",
      "164529/164529 [==============================] - 18s 111us/step - loss: 0.0338 - val_loss: 0.0316\n",
      "Epoch 9/100\n",
      "164529/164529 [==============================] - 18s 109us/step - loss: 0.0332 - val_loss: 0.0315\n",
      "Epoch 10/100\n",
      "164529/164529 [==============================] - 17s 105us/step - loss: 0.0325 - val_loss: 0.0312\n",
      "Epoch 11/100\n",
      "164529/164529 [==============================] - 16s 95us/step - loss: 0.0321 - val_loss: 0.0305\n",
      "Epoch 12/100\n",
      "164529/164529 [==============================] - 15s 91us/step - loss: 0.0316 - val_loss: 0.0301\n",
      "Epoch 13/100\n",
      "164529/164529 [==============================] - 17s 105us/step - loss: 0.0312 - val_loss: 0.0304\n",
      "Epoch 14/100\n",
      "164529/164529 [==============================] - 17s 102us/step - loss: 0.0309 - val_loss: 0.0291\n",
      "Epoch 15/100\n",
      "164529/164529 [==============================] - 15s 92us/step - loss: 0.0305 - val_loss: 0.0291\n",
      "Epoch 16/100\n",
      "164529/164529 [==============================] - 15s 90us/step - loss: 0.0301 - val_loss: 0.0289\n",
      "Epoch 17/100\n",
      "164529/164529 [==============================] - 15s 91us/step - loss: 0.0298 - val_loss: 0.0288\n",
      "Epoch 18/100\n",
      "164529/164529 [==============================] - 13s 80us/step - loss: 0.0294 - val_loss: 0.0282\n",
      "Epoch 19/100\n",
      "164529/164529 [==============================] - 14s 88us/step - loss: 0.0293 - val_loss: 0.0286\n",
      "Epoch 20/100\n",
      "164529/164529 [==============================] - 14s 87us/step - loss: 0.0291 - val_loss: 0.0280\n",
      "Epoch 21/100\n",
      "164529/164529 [==============================] - 14s 88us/step - loss: 0.0288 - val_loss: 0.0279\n",
      "Epoch 22/100\n",
      "164529/164529 [==============================] - 14s 87us/step - loss: 0.0285 - val_loss: 0.0276\n",
      "Epoch 23/100\n",
      "164529/164529 [==============================] - 15s 88us/step - loss: 0.0283 - val_loss: 0.0276\n",
      "Epoch 24/100\n",
      "164529/164529 [==============================] - 14s 87us/step - loss: 0.0282 - val_loss: 0.0276\n",
      "Epoch 25/100\n",
      "164529/164529 [==============================] - 14s 87us/step - loss: 0.0278 - val_loss: 0.0270\n",
      "Epoch 26/100\n",
      "164529/164529 [==============================] - 14s 87us/step - loss: 0.0278 - val_loss: 0.0272\n",
      "Epoch 27/100\n",
      "164529/164529 [==============================] - 15s 89us/step - loss: 0.0276 - val_loss: 0.0272\n",
      "Epoch 28/100\n",
      "164529/164529 [==============================] - 14s 87us/step - loss: 0.0274 - val_loss: 0.0268\n",
      "Epoch 29/100\n",
      "164529/164529 [==============================] - 14s 88us/step - loss: 0.0273 - val_loss: 0.0270\n",
      "Epoch 30/100\n",
      "164529/164529 [==============================] - 15s 89us/step - loss: 0.0270 - val_loss: 0.0268\n",
      "Epoch 31/100\n",
      "164529/164529 [==============================] - 14s 87us/step - loss: 0.0270 - val_loss: 0.0266\n",
      "Epoch 32/100\n",
      "164529/164529 [==============================] - 15s 90us/step - loss: 0.0268 - val_loss: 0.0263\n",
      "Epoch 33/100\n",
      "164529/164529 [==============================] - 14s 88us/step - loss: 0.0267 - val_loss: 0.0263\n",
      "Epoch 34/100\n",
      "164529/164529 [==============================] - 14s 83us/step - loss: 0.0266 - val_loss: 0.0262\n",
      "Epoch 35/100\n",
      "164529/164529 [==============================] - 14s 87us/step - loss: 0.0264 - val_loss: 0.0260\n",
      "Epoch 36/100\n",
      "164529/164529 [==============================] - 16s 98us/step - loss: 0.0264 - val_loss: 0.0260\n",
      "Epoch 37/100\n",
      "164529/164529 [==============================] - 18s 107us/step - loss: 0.0262 - val_loss: 0.0261\n",
      "Epoch 38/100\n",
      "164529/164529 [==============================] - 17s 105us/step - loss: 0.0261 - val_loss: 0.0260\n",
      "Epoch 39/100\n",
      "164529/164529 [==============================] - 17s 105us/step - loss: 0.0260 - val_loss: 0.0257\n",
      "Epoch 40/100\n",
      "164529/164529 [==============================] - 18s 107us/step - loss: 0.0260 - val_loss: 0.0255\n",
      "Epoch 41/100\n",
      "164529/164529 [==============================] - 18s 108us/step - loss: 0.0257 - val_loss: 0.0257\n",
      "Epoch 42/100\n",
      "164529/164529 [==============================] - 18s 106us/step - loss: 0.0258 - val_loss: 0.0255\n",
      "Epoch 43/100\n",
      "164529/164529 [==============================] - 16s 95us/step - loss: 0.0255 - val_loss: 0.0256\n",
      "Epoch 44/100\n",
      "164529/164529 [==============================] - 15s 92us/step - loss: 0.0256 - val_loss: 0.0258\n",
      "Epoch 45/100\n",
      "164529/164529 [==============================] - 15s 92us/step - loss: 0.0255 - val_loss: 0.0254\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164529/164529 [==============================] - 15s 90us/step - loss: 0.0254 - val_loss: 0.0251\n",
      "Epoch 47/100\n",
      "164529/164529 [==============================] - 15s 92us/step - loss: 0.0253 - val_loss: 0.0253\n",
      "Epoch 48/100\n",
      "164529/164529 [==============================] - 15s 91us/step - loss: 0.0253 - val_loss: 0.0250\n",
      "Epoch 49/100\n",
      "164529/164529 [==============================] - 15s 91us/step - loss: 0.0252 - val_loss: 0.0253\n",
      "Epoch 50/100\n",
      "164529/164529 [==============================] - 15s 90us/step - loss: 0.0251 - val_loss: 0.0252\n",
      "Epoch 51/100\n",
      "164529/164529 [==============================] - 14s 87us/step - loss: 0.0251 - val_loss: 0.0253\n",
      "Epoch 52/100\n",
      "164529/164529 [==============================] - 15s 88us/step - loss: 0.0250 - val_loss: 0.0247\n",
      "Epoch 53/100\n",
      "164529/164529 [==============================] - 15s 89us/step - loss: 0.0249 - val_loss: 0.0249\n",
      "Epoch 54/100\n",
      "164529/164529 [==============================] - 14s 88us/step - loss: 0.0248 - val_loss: 0.0250\n",
      "Epoch 55/100\n",
      "164529/164529 [==============================] - 15s 89us/step - loss: 0.0247 - val_loss: 0.0249\n",
      "Epoch 56/100\n",
      "164529/164529 [==============================] - 15s 89us/step - loss: 0.0248 - val_loss: 0.0246\n",
      "Epoch 57/100\n",
      "164529/164529 [==============================] - 14s 88us/step - loss: 0.0246 - val_loss: 0.0247\n",
      "Epoch 58/100\n",
      "164529/164529 [==============================] - 15s 88us/step - loss: 0.0245 - val_loss: 0.0245\n",
      "Epoch 59/100\n",
      "164529/164529 [==============================] - 14s 88us/step - loss: 0.0245 - val_loss: 0.0247\n",
      "Epoch 60/100\n",
      "164529/164529 [==============================] - 15s 89us/step - loss: 0.0244 - val_loss: 0.0247\n",
      "Epoch 61/100\n",
      "164529/164529 [==============================] - 16s 95us/step - loss: 0.0243 - val_loss: 0.0245\n",
      "Epoch 62/100\n",
      "164529/164529 [==============================] - 15s 92us/step - loss: 0.0244 - val_loss: 0.0243\n",
      "Epoch 63/100\n",
      "164529/164529 [==============================] - 15s 90us/step - loss: 0.0242 - val_loss: 0.0246\n",
      "Epoch 64/100\n",
      "164529/164529 [==============================] - 15s 93us/step - loss: 0.0242 - val_loss: 0.0242\n",
      "Epoch 65/100\n",
      "164529/164529 [==============================] - 16s 94us/step - loss: 0.0242 - val_loss: 0.0247\n",
      "Epoch 66/100\n",
      "164529/164529 [==============================] - 15s 89us/step - loss: 0.0241 - val_loss: 0.0244\n",
      "Epoch 67/100\n",
      "164529/164529 [==============================] - 16s 97us/step - loss: 0.0242 - val_loss: 0.0244\n",
      "Epoch 68/100\n",
      "164529/164529 [==============================] - 14s 83us/step - loss: 0.0239 - val_loss: 0.0242\n",
      "perc99.5SubjectF2andFold3\n",
      "223063\n",
      "72232\n",
      "Train on 138142 samples, validate on 44405 samples\n",
      "Epoch 1/100\n",
      "138142/138142 [==============================] - 19s 139us/step - loss: 0.0541 - val_loss: 0.0388\n",
      "Epoch 2/100\n",
      "138142/138142 [==============================] - 15s 110us/step - loss: 0.0437 - val_loss: 0.0380\n",
      "Epoch 3/100\n",
      "138142/138142 [==============================] - 15s 109us/step - loss: 0.0422 - val_loss: 0.0377\n",
      "Epoch 4/100\n",
      "138142/138142 [==============================] - 15s 111us/step - loss: 0.0413 - val_loss: 0.0363\n",
      "Epoch 5/100\n",
      "138142/138142 [==============================] - 16s 113us/step - loss: 0.0406 - val_loss: 0.0356\n",
      "Epoch 6/100\n",
      "138142/138142 [==============================] - 15s 107us/step - loss: 0.0400 - val_loss: 0.0357\n",
      "Epoch 7/100\n",
      "138142/138142 [==============================] - 14s 102us/step - loss: 0.0395 - val_loss: 0.0360\n",
      "Epoch 8/100\n",
      "138142/138142 [==============================] - 15s 110us/step - loss: 0.0389 - val_loss: 0.0346\n",
      "Epoch 9/100\n",
      "138142/138142 [==============================] - 15s 108us/step - loss: 0.0385 - val_loss: 0.0347\n",
      "Epoch 10/100\n",
      "138142/138142 [==============================] - 15s 110us/step - loss: 0.0381 - val_loss: 0.0347\n",
      "Epoch 11/100\n",
      "138142/138142 [==============================] - 15s 108us/step - loss: 0.0378 - val_loss: 0.0345\n",
      "Epoch 12/100\n",
      "138142/138142 [==============================] - 15s 109us/step - loss: 0.0376 - val_loss: 0.0342\n",
      "Epoch 13/100\n",
      "138142/138142 [==============================] - 15s 110us/step - loss: 0.0373 - val_loss: 0.0334\n",
      "Epoch 14/100\n",
      "138142/138142 [==============================] - 15s 109us/step - loss: 0.0368 - val_loss: 0.0328\n",
      "Epoch 15/100\n",
      "138142/138142 [==============================] - 15s 106us/step - loss: 0.0365 - val_loss: 0.0338\n",
      "Epoch 16/100\n",
      "138142/138142 [==============================] - 15s 111us/step - loss: 0.0363 - val_loss: 0.0329\n",
      "Epoch 17/100\n",
      "138142/138142 [==============================] - 16s 117us/step - loss: 0.0358 - val_loss: 0.0326\n",
      "Epoch 18/100\n",
      "138142/138142 [==============================] - 18s 132us/step - loss: 0.0355 - val_loss: 0.0320\n",
      "Epoch 19/100\n",
      "138142/138142 [==============================] - 17s 125us/step - loss: 0.0352 - val_loss: 0.0328\n",
      "Epoch 20/100\n",
      "138142/138142 [==============================] - 17s 119us/step - loss: 0.0349 - val_loss: 0.0321\n",
      "Epoch 21/100\n",
      "138142/138142 [==============================] - 16s 119us/step - loss: 0.0348 - val_loss: 0.0311\n",
      "Epoch 22/100\n",
      "138142/138142 [==============================] - 16s 117us/step - loss: 0.0345 - val_loss: 0.0327\n",
      "Epoch 23/100\n",
      "138142/138142 [==============================] - 15s 108us/step - loss: 0.0341 - val_loss: 0.0318\n",
      "Epoch 24/100\n",
      "138142/138142 [==============================] - 16s 116us/step - loss: 0.0340 - val_loss: 0.0317\n",
      "Epoch 25/100\n",
      "138142/138142 [==============================] - 17s 121us/step - loss: 0.0337 - val_loss: 0.0312\n",
      "perc99.5SubjectF2andFold4\n",
      "208553\n",
      "71434\n",
      "Train on 123511 samples, validate on 41548 samples\n",
      "Epoch 1/100\n",
      "123511/123511 [==============================] - 17s 141us/step - loss: 0.0497 - val_loss: 0.0416\n",
      "Epoch 2/100\n",
      "123511/123511 [==============================] - 13s 109us/step - loss: 0.0376 - val_loss: 0.0370\n",
      "Epoch 3/100\n",
      "123511/123511 [==============================] - 13s 108us/step - loss: 0.0358 - val_loss: 0.0371\n",
      "Epoch 4/100\n",
      "123511/123511 [==============================] - 13s 108us/step - loss: 0.0348 - val_loss: 0.0366\n",
      "Epoch 5/100\n",
      "123511/123511 [==============================] - 14s 110us/step - loss: 0.0341 - val_loss: 0.0347\n",
      "Epoch 6/100\n",
      "123511/123511 [==============================] - 13s 109us/step - loss: 0.0334 - val_loss: 0.0351\n",
      "Epoch 7/100\n",
      "123511/123511 [==============================] - 13s 104us/step - loss: 0.0326 - val_loss: 0.0351\n",
      "Epoch 8/100\n",
      "123511/123511 [==============================] - 13s 106us/step - loss: 0.0320 - val_loss: 0.0335\n",
      "Epoch 9/100\n",
      "123511/123511 [==============================] - 14s 110us/step - loss: 0.0316 - val_loss: 0.0342\n",
      "Epoch 10/100\n",
      "123511/123511 [==============================] - 13s 108us/step - loss: 0.0311 - val_loss: 0.0321\n",
      "Epoch 11/100\n",
      "123511/123511 [==============================] - 14s 109us/step - loss: 0.0306 - val_loss: 0.0325\n",
      "Epoch 12/100\n",
      "123511/123511 [==============================] - 14s 110us/step - loss: 0.0300 - val_loss: 0.0315\n",
      "Epoch 13/100\n",
      "123511/123511 [==============================] - 14s 113us/step - loss: 0.0298 - val_loss: 0.0321\n",
      "Epoch 14/100\n",
      "123511/123511 [==============================] - 13s 107us/step - loss: 0.0294 - val_loss: 0.0316\n",
      "Epoch 15/100\n",
      "123511/123511 [==============================] - 13s 108us/step - loss: 0.0290 - val_loss: 0.0311\n",
      "Epoch 16/100\n",
      "123511/123511 [==============================] - 14s 113us/step - loss: 0.0287 - val_loss: 0.0312\n",
      "Epoch 17/100\n",
      "123511/123511 [==============================] - 14s 111us/step - loss: 0.0285 - val_loss: 0.0309\n",
      "Epoch 18/100\n",
      "123511/123511 [==============================] - 15s 119us/step - loss: 0.0282 - val_loss: 0.0303\n",
      "Epoch 19/100\n",
      "123511/123511 [==============================] - 15s 119us/step - loss: 0.0279 - val_loss: 0.0304\n",
      "Epoch 20/100\n",
      "123511/123511 [==============================] - 15s 118us/step - loss: 0.0277 - val_loss: 0.0309\n",
      "Epoch 21/100\n",
      "123511/123511 [==============================] - 15s 120us/step - loss: 0.0275 - val_loss: 0.0294\n",
      "Epoch 22/100\n",
      "123511/123511 [==============================] - 15s 120us/step - loss: 0.0273 - val_loss: 0.0298\n",
      "Epoch 23/100\n",
      "123511/123511 [==============================] - 14s 114us/step - loss: 0.0272 - val_loss: 0.0293\n",
      "Epoch 24/100\n",
      "123511/123511 [==============================] - 14s 110us/step - loss: 0.0269 - val_loss: 0.0305\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123511/123511 [==============================] - 12s 101us/step - loss: 0.0269 - val_loss: 0.0300\n",
      "Epoch 26/100\n",
      "123511/123511 [==============================] - 14s 112us/step - loss: 0.0267 - val_loss: 0.0299\n",
      "Epoch 27/100\n",
      "123511/123511 [==============================] - 13s 109us/step - loss: 0.0264 - val_loss: 0.0295\n",
      "perc99.5SubjectM1andFold1\n",
      "307910\n",
      "103029\n",
      "Train on 259688 samples, validate on 87489 samples\n",
      "Epoch 1/100\n",
      "259688/259688 [==============================] - 36s 137us/step - loss: 0.0510 - val_loss: 0.0444\n",
      "Epoch 2/100\n",
      "259688/259688 [==============================] - 30s 115us/step - loss: 0.0427 - val_loss: 0.0420\n",
      "Epoch 3/100\n",
      "259688/259688 [==============================] - 35s 136us/step - loss: 0.0407 - val_loss: 0.0388\n",
      "Epoch 4/100\n",
      "259688/259688 [==============================] - 34s 129us/step - loss: 0.0393 - val_loss: 0.0393\n",
      "Epoch 5/100\n",
      "259688/259688 [==============================] - 33s 125us/step - loss: 0.0384 - val_loss: 0.0375\n",
      "Epoch 6/100\n",
      "259688/259688 [==============================] - 32s 125us/step - loss: 0.0374 - val_loss: 0.0363\n",
      "Epoch 7/100\n",
      "259688/259688 [==============================] - 34s 130us/step - loss: 0.0365 - val_loss: 0.0360\n",
      "Epoch 8/100\n",
      "259688/259688 [==============================] - 34s 131us/step - loss: 0.0359 - val_loss: 0.0350\n",
      "Epoch 9/100\n",
      "259688/259688 [==============================] - 30s 116us/step - loss: 0.0353 - val_loss: 0.0357\n",
      "Epoch 10/100\n",
      "259688/259688 [==============================] - 31s 119us/step - loss: 0.0348 - val_loss: 0.0341\n",
      "Epoch 11/100\n",
      "259688/259688 [==============================] - 31s 119us/step - loss: 0.0343 - val_loss: 0.0336\n",
      "Epoch 12/100\n",
      "259688/259688 [==============================] - 31s 121us/step - loss: 0.0338 - val_loss: 0.0331\n",
      "Epoch 13/100\n",
      "259688/259688 [==============================] - 30s 116us/step - loss: 0.0333 - val_loss: 0.0323\n",
      "Epoch 14/100\n",
      "259688/259688 [==============================] - 31s 118us/step - loss: 0.0329 - val_loss: 0.0323\n",
      "Epoch 15/100\n",
      "259688/259688 [==============================] - 31s 120us/step - loss: 0.0326 - val_loss: 0.0315\n",
      "Epoch 16/100\n",
      "259688/259688 [==============================] - 32s 121us/step - loss: 0.0322 - val_loss: 0.0316\n",
      "Epoch 17/100\n",
      "259688/259688 [==============================] - 30s 115us/step - loss: 0.0319 - val_loss: 0.0313\n",
      "Epoch 18/100\n",
      "259688/259688 [==============================] - 31s 118us/step - loss: 0.0316 - val_loss: 0.0309\n",
      "Epoch 19/100\n",
      "259688/259688 [==============================] - 31s 120us/step - loss: 0.0313 - val_loss: 0.0308\n",
      "Epoch 20/100\n",
      "259688/259688 [==============================] - 31s 119us/step - loss: 0.0312 - val_loss: 0.0306\n",
      "Epoch 21/100\n",
      "259688/259688 [==============================] - 31s 118us/step - loss: 0.0310 - val_loss: 0.0305\n",
      "Epoch 22/100\n",
      "259688/259688 [==============================] - 32s 124us/step - loss: 0.0307 - val_loss: 0.0302\n",
      "Epoch 23/100\n",
      "259688/259688 [==============================] - 30s 116us/step - loss: 0.0305 - val_loss: 0.0301\n",
      "Epoch 24/100\n",
      "259688/259688 [==============================] - 30s 117us/step - loss: 0.0304 - val_loss: 0.0312\n",
      "Epoch 25/100\n",
      "259688/259688 [==============================] - 30s 114us/step - loss: 0.0301 - val_loss: 0.0298\n",
      "Epoch 26/100\n",
      "259688/259688 [==============================] - 33s 126us/step - loss: 0.0300 - val_loss: 0.0289\n",
      "Epoch 27/100\n",
      "259688/259688 [==============================] - 32s 124us/step - loss: 0.0299 - val_loss: 0.0294\n",
      "Epoch 28/100\n",
      "259688/259688 [==============================] - 33s 126us/step - loss: 0.0297 - val_loss: 0.0287\n",
      "Epoch 29/100\n",
      "259688/259688 [==============================] - 32s 123us/step - loss: 0.0297 - val_loss: 0.0291\n",
      "Epoch 30/100\n",
      "259688/259688 [==============================] - 32s 125us/step - loss: 0.0294 - val_loss: 0.0289\n",
      "Epoch 31/100\n",
      "259688/259688 [==============================] - 32s 122us/step - loss: 0.0292 - val_loss: 0.0284\n",
      "Epoch 32/100\n",
      "259688/259688 [==============================] - 32s 125us/step - loss: 0.0291 - val_loss: 0.0287\n",
      "Epoch 33/100\n",
      "259688/259688 [==============================] - 32s 123us/step - loss: 0.0290 - val_loss: 0.0285\n",
      "Epoch 34/100\n",
      "259688/259688 [==============================] - 32s 121us/step - loss: 0.0289 - val_loss: 0.0285\n",
      "Epoch 35/100\n",
      "259688/259688 [==============================] - 33s 126us/step - loss: 0.0287 - val_loss: 0.0284\n",
      "perc99.5SubjectM1andFold2\n",
      "317716\n",
      "105491\n",
      "Train on 136199 samples, validate on 43828 samples\n",
      "Epoch 1/100\n",
      "136199/136199 [==============================] - 21s 154us/step - loss: 0.0542 - val_loss: 0.0401\n",
      "Epoch 2/100\n",
      "136199/136199 [==============================] - 16s 117us/step - loss: 0.0386 - val_loss: 0.0341\n",
      "Epoch 3/100\n",
      "136199/136199 [==============================] - 17s 124us/step - loss: 0.0355 - val_loss: 0.0317\n",
      "Epoch 4/100\n",
      "136199/136199 [==============================] - 17s 121us/step - loss: 0.0335 - val_loss: 0.0306\n",
      "Epoch 5/100\n",
      "136199/136199 [==============================] - 17s 122us/step - loss: 0.0318 - val_loss: 0.0294\n",
      "Epoch 6/100\n",
      "136199/136199 [==============================] - 17s 122us/step - loss: 0.0307 - val_loss: 0.0290\n",
      "Epoch 7/100\n",
      "136199/136199 [==============================] - 16s 121us/step - loss: 0.0299 - val_loss: 0.0280\n",
      "Epoch 8/100\n",
      "136199/136199 [==============================] - 17s 121us/step - loss: 0.0288 - val_loss: 0.0273\n",
      "Epoch 9/100\n",
      "136199/136199 [==============================] - 16s 120us/step - loss: 0.0281 - val_loss: 0.0276\n",
      "Epoch 10/100\n",
      "136199/136199 [==============================] - 17s 123us/step - loss: 0.0274 - val_loss: 0.0259\n",
      "Epoch 11/100\n",
      "136199/136199 [==============================] - 16s 117us/step - loss: 0.0269 - val_loss: 0.0260\n",
      "Epoch 12/100\n",
      "136199/136199 [==============================] - 17s 122us/step - loss: 0.0265 - val_loss: 0.0250\n",
      "Epoch 13/100\n",
      "136199/136199 [==============================] - 17s 122us/step - loss: 0.0260 - val_loss: 0.0245\n",
      "Epoch 14/100\n",
      "136199/136199 [==============================] - 18s 129us/step - loss: 0.0256 - val_loss: 0.0237\n",
      "Epoch 15/100\n",
      "136199/136199 [==============================] - 17s 122us/step - loss: 0.0252 - val_loss: 0.0241\n",
      "Epoch 16/100\n",
      "136199/136199 [==============================] - 17s 122us/step - loss: 0.0249 - val_loss: 0.0238\n",
      "Epoch 17/100\n",
      "136199/136199 [==============================] - 17s 124us/step - loss: 0.0245 - val_loss: 0.0237\n",
      "Epoch 18/100\n",
      "136199/136199 [==============================] - 17s 122us/step - loss: 0.0243 - val_loss: 0.0230\n",
      "Epoch 19/100\n",
      "136199/136199 [==============================] - 16s 120us/step - loss: 0.0241 - val_loss: 0.0231\n",
      "Epoch 20/100\n",
      "136199/136199 [==============================] - 16s 120us/step - loss: 0.0238 - val_loss: 0.0230\n",
      "Epoch 21/100\n",
      "136199/136199 [==============================] - 17s 125us/step - loss: 0.0236 - val_loss: 0.0228\n",
      "Epoch 22/100\n",
      "136199/136199 [==============================] - 18s 130us/step - loss: 0.0232 - val_loss: 0.0226\n",
      "Epoch 23/100\n",
      "136199/136199 [==============================] - 18s 130us/step - loss: 0.0230 - val_loss: 0.0220\n",
      "Epoch 24/100\n",
      "136199/136199 [==============================] - 18s 131us/step - loss: 0.0230 - val_loss: 0.0219\n",
      "Epoch 25/100\n",
      "136199/136199 [==============================] - 18s 132us/step - loss: 0.0226 - val_loss: 0.0217\n",
      "Epoch 26/100\n",
      "136199/136199 [==============================] - 18s 129us/step - loss: 0.0225 - val_loss: 0.0221\n",
      "Epoch 27/100\n",
      "136199/136199 [==============================] - 16s 119us/step - loss: 0.0224 - val_loss: 0.0213\n",
      "Epoch 28/100\n",
      "136199/136199 [==============================] - 16s 116us/step - loss: 0.0223 - val_loss: 0.0222\n",
      "Epoch 29/100\n",
      "136199/136199 [==============================] - 17s 122us/step - loss: 0.0221 - val_loss: 0.0218\n",
      "Epoch 30/100\n",
      "136199/136199 [==============================] - 18s 129us/step - loss: 0.0220 - val_loss: 0.0218\n",
      "Epoch 31/100\n",
      "136199/136199 [==============================] - 17s 123us/step - loss: 0.0218 - val_loss: 0.0210\n",
      "Epoch 32/100\n",
      "136199/136199 [==============================] - 16s 121us/step - loss: 0.0216 - val_loss: 0.0219\n",
      "Epoch 33/100\n",
      "136199/136199 [==============================] - 17s 124us/step - loss: 0.0215 - val_loss: 0.0207\n",
      "Epoch 34/100\n",
      "136199/136199 [==============================] - 17s 128us/step - loss: 0.0214 - val_loss: 0.0218\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136199/136199 [==============================] - 17s 123us/step - loss: 0.0213 - val_loss: 0.0214\n",
      "Epoch 36/100\n",
      "136199/136199 [==============================] - 16s 117us/step - loss: 0.0211 - val_loss: 0.0212\n",
      "Epoch 37/100\n",
      "136199/136199 [==============================] - 16s 120us/step - loss: 0.0211 - val_loss: 0.0206\n",
      "Epoch 38/100\n",
      "136199/136199 [==============================] - 17s 123us/step - loss: 0.0212 - val_loss: 0.0209\n",
      "Epoch 39/100\n",
      "136199/136199 [==============================] - 17s 123us/step - loss: 0.0210 - val_loss: 0.0207\n",
      "Epoch 40/100\n",
      "136199/136199 [==============================] - 17s 124us/step - loss: 0.0208 - val_loss: 0.0209\n",
      "Epoch 41/100\n",
      "136199/136199 [==============================] - 17s 121us/step - loss: 0.0208 - val_loss: 0.0205\n",
      "Epoch 42/100\n",
      "136199/136199 [==============================] - 17s 122us/step - loss: 0.0207 - val_loss: 0.0207\n",
      "Epoch 43/100\n",
      "136199/136199 [==============================] - 17s 122us/step - loss: 0.0205 - val_loss: 0.0205\n",
      "Epoch 44/100\n",
      "136199/136199 [==============================] - 16s 120us/step - loss: 0.0205 - val_loss: 0.0203\n",
      "Epoch 45/100\n",
      "136199/136199 [==============================] - 16s 118us/step - loss: 0.0204 - val_loss: 0.0206\n",
      "Epoch 46/100\n",
      "136199/136199 [==============================] - 17s 127us/step - loss: 0.0203 - val_loss: 0.0202\n",
      "Epoch 47/100\n",
      "136199/136199 [==============================] - 17s 125us/step - loss: 0.0201 - val_loss: 0.0202\n",
      "Epoch 48/100\n",
      "136199/136199 [==============================] - 17s 124us/step - loss: 0.0202 - val_loss: 0.0204\n",
      "Epoch 49/100\n",
      "136199/136199 [==============================] - 17s 123us/step - loss: 0.0202 - val_loss: 0.0206\n",
      "Epoch 50/100\n",
      "136199/136199 [==============================] - 17s 122us/step - loss: 0.0200 - val_loss: 0.0204\n",
      "Epoch 51/100\n",
      "136199/136199 [==============================] - 17s 122us/step - loss: 0.0200 - val_loss: 0.0201\n",
      "Epoch 52/100\n",
      "136199/136199 [==============================] - 17s 122us/step - loss: 0.0199 - val_loss: 0.0201\n",
      "Epoch 53/100\n",
      "136199/136199 [==============================] - 17s 122us/step - loss: 0.0198 - val_loss: 0.0199\n",
      "Epoch 54/100\n",
      "136199/136199 [==============================] - 16s 117us/step - loss: 0.0199 - val_loss: 0.0202\n",
      "Epoch 55/100\n",
      "136199/136199 [==============================] - 17s 123us/step - loss: 0.0197 - val_loss: 0.0202\n",
      "Epoch 56/100\n",
      "136199/136199 [==============================] - 17s 124us/step - loss: 0.0197 - val_loss: 0.0196\n",
      "Epoch 57/100\n",
      "136199/136199 [==============================] - 17s 123us/step - loss: 0.0196 - val_loss: 0.0200\n",
      "Epoch 58/100\n",
      "136199/136199 [==============================] - 17s 123us/step - loss: 0.0195 - val_loss: 0.0200\n",
      "Epoch 59/100\n",
      "136199/136199 [==============================] - 17s 122us/step - loss: 0.0196 - val_loss: 0.0197\n",
      "Epoch 60/100\n",
      "136199/136199 [==============================] - 17s 122us/step - loss: 0.0194 - val_loss: 0.0198\n",
      "perc99.5SubjectM1andFold3\n",
      "268893\n",
      "88438\n",
      "Train on 166702 samples, validate on 51951 samples\n",
      "Epoch 1/100\n",
      "166702/166702 [==============================] - 24s 142us/step - loss: 0.0505 - val_loss: 0.0327\n",
      "Epoch 2/100\n",
      "166702/166702 [==============================] - 20s 120us/step - loss: 0.0388 - val_loss: 0.0295\n",
      "Epoch 3/100\n",
      "166702/166702 [==============================] - 20s 123us/step - loss: 0.0365 - val_loss: 0.0292\n",
      "Epoch 4/100\n",
      "166702/166702 [==============================] - 20s 122us/step - loss: 0.0349 - val_loss: 0.0273\n",
      "Epoch 5/100\n",
      "166702/166702 [==============================] - 20s 122us/step - loss: 0.0340 - val_loss: 0.0263\n",
      "Epoch 6/100\n",
      "166702/166702 [==============================] - 20s 121us/step - loss: 0.0329 - val_loss: 0.0273\n",
      "Epoch 7/100\n",
      "166702/166702 [==============================] - 19s 116us/step - loss: 0.0321 - val_loss: 0.0253\n",
      "Epoch 8/100\n",
      "166702/166702 [==============================] - 18s 106us/step - loss: 0.0313 - val_loss: 0.0251\n",
      "Epoch 9/100\n",
      "166702/166702 [==============================] - 17s 102us/step - loss: 0.0308 - val_loss: 0.0256\n",
      "Epoch 10/100\n",
      "166702/166702 [==============================] - 17s 104us/step - loss: 0.0304 - val_loss: 0.0240\n",
      "Epoch 11/100\n",
      "166702/166702 [==============================] - 17s 103us/step - loss: 0.0300 - val_loss: 0.0241\n",
      "Epoch 12/100\n",
      "166702/166702 [==============================] - 17s 105us/step - loss: 0.0296 - val_loss: 0.0244\n",
      "Epoch 13/100\n",
      "166702/166702 [==============================] - 18s 106us/step - loss: 0.0293 - val_loss: 0.0242\n",
      "Epoch 14/100\n",
      "166702/166702 [==============================] - 18s 108us/step - loss: 0.0290 - val_loss: 0.0240\n",
      "Epoch 15/100\n",
      "166702/166702 [==============================] - 17s 102us/step - loss: 0.0287 - val_loss: 0.0241\n",
      "Epoch 16/100\n",
      "166702/166702 [==============================] - 17s 105us/step - loss: 0.0285 - val_loss: 0.0243\n",
      "Epoch 17/100\n",
      "166702/166702 [==============================] - 18s 106us/step - loss: 0.0283 - val_loss: 0.0235\n",
      "Epoch 18/100\n",
      "166702/166702 [==============================] - 18s 105us/step - loss: 0.0281 - val_loss: 0.0237\n",
      "Epoch 19/100\n",
      "166702/166702 [==============================] - 17s 102us/step - loss: 0.0279 - val_loss: 0.0234\n",
      "Epoch 20/100\n",
      "166702/166702 [==============================] - 18s 106us/step - loss: 0.0277 - val_loss: 0.0228\n",
      "Epoch 21/100\n",
      "166702/166702 [==============================] - 18s 106us/step - loss: 0.0275 - val_loss: 0.0232\n",
      "Epoch 22/100\n",
      "166702/166702 [==============================] - 18s 105us/step - loss: 0.0274 - val_loss: 0.0232\n",
      "Epoch 23/100\n",
      "166702/166702 [==============================] - 16s 96us/step - loss: 0.0272 - val_loss: 0.0237\n",
      "Epoch 24/100\n",
      "166702/166702 [==============================] - 15s 89us/step - loss: 0.0271 - val_loss: 0.0220\n",
      "Epoch 25/100\n",
      "166702/166702 [==============================] - 15s 92us/step - loss: 0.0269 - val_loss: 0.0222\n",
      "Epoch 26/100\n",
      "166702/166702 [==============================] - 15s 92us/step - loss: 0.0268 - val_loss: 0.0220\n",
      "Epoch 27/100\n",
      "166702/166702 [==============================] - 16s 95us/step - loss: 0.0267 - val_loss: 0.0225\n",
      "Epoch 28/100\n",
      "166702/166702 [==============================] - 16s 93us/step - loss: 0.0265 - val_loss: 0.0225\n",
      "Epoch 29/100\n",
      "166702/166702 [==============================] - 16s 94us/step - loss: 0.0264 - val_loss: 0.0229\n",
      "Epoch 30/100\n",
      "166702/166702 [==============================] - 16s 94us/step - loss: 0.0264 - val_loss: 0.0221\n",
      "perc99.5SubjectM1andFold4\n",
      "280326\n",
      "93005\n",
      "Train on 157152 samples, validate on 50998 samples\n",
      "Epoch 1/100\n",
      "157152/157152 [==============================] - 22s 139us/step - loss: 0.0481 - val_loss: 0.0333\n",
      "Epoch 2/100\n",
      "157152/157152 [==============================] - 15s 97us/step - loss: 0.0347 - val_loss: 0.0308\n",
      "Epoch 3/100\n",
      "157152/157152 [==============================] - 15s 96us/step - loss: 0.0321 - val_loss: 0.0297\n",
      "Epoch 4/100\n",
      "157152/157152 [==============================] - 14s 90us/step - loss: 0.0302 - val_loss: 0.0283\n",
      "Epoch 5/100\n",
      "157152/157152 [==============================] - 15s 94us/step - loss: 0.0292 - val_loss: 0.0275\n",
      "Epoch 6/100\n",
      "157152/157152 [==============================] - 15s 94us/step - loss: 0.0283 - val_loss: 0.0264\n",
      "Epoch 7/100\n",
      "157152/157152 [==============================] - 15s 95us/step - loss: 0.0276 - val_loss: 0.0255\n",
      "Epoch 8/100\n",
      "157152/157152 [==============================] - 14s 91us/step - loss: 0.0269 - val_loss: 0.0248\n",
      "Epoch 9/100\n",
      "157152/157152 [==============================] - 17s 107us/step - loss: 0.0266 - val_loss: 0.0249\n",
      "Epoch 10/100\n",
      "157152/157152 [==============================] - 17s 107us/step - loss: 0.0259 - val_loss: 0.0256\n",
      "Epoch 11/100\n",
      "157152/157152 [==============================] - 17s 107us/step - loss: 0.0257 - val_loss: 0.0244\n",
      "Epoch 12/100\n",
      "157152/157152 [==============================] - 16s 102us/step - loss: 0.0253 - val_loss: 0.0241\n",
      "Epoch 13/100\n",
      "157152/157152 [==============================] - 17s 107us/step - loss: 0.0250 - val_loss: 0.0233\n",
      "Epoch 14/100\n",
      "157152/157152 [==============================] - 19s 120us/step - loss: 0.0246 - val_loss: 0.0235\n",
      "Epoch 15/100\n",
      "157152/157152 [==============================] - 18s 113us/step - loss: 0.0245 - val_loss: 0.0230\n",
      "Epoch 16/100\n",
      "157152/157152 [==============================] - 17s 109us/step - loss: 0.0241 - val_loss: 0.0228\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157152/157152 [==============================] - 17s 107us/step - loss: 0.0240 - val_loss: 0.0225\n",
      "Epoch 18/100\n",
      "157152/157152 [==============================] - 17s 108us/step - loss: 0.0237 - val_loss: 0.0224\n",
      "Epoch 19/100\n",
      "157152/157152 [==============================] - 18s 113us/step - loss: 0.0235 - val_loss: 0.0217\n",
      "Epoch 20/100\n",
      "157152/157152 [==============================] - 17s 107us/step - loss: 0.0232 - val_loss: 0.0218\n",
      "Epoch 21/100\n",
      "157152/157152 [==============================] - 17s 107us/step - loss: 0.0232 - val_loss: 0.0213\n",
      "Epoch 22/100\n",
      "157152/157152 [==============================] - 17s 105us/step - loss: 0.0230 - val_loss: 0.0218\n",
      "Epoch 23/100\n",
      "157152/157152 [==============================] - 17s 107us/step - loss: 0.0228 - val_loss: 0.0218\n",
      "Epoch 24/100\n",
      "157152/157152 [==============================] - 17s 106us/step - loss: 0.0226 - val_loss: 0.0215\n",
      "Epoch 25/100\n",
      "157152/157152 [==============================] - 17s 106us/step - loss: 0.0225 - val_loss: 0.0212\n",
      "Epoch 26/100\n",
      "157152/157152 [==============================] - 17s 107us/step - loss: 0.0225 - val_loss: 0.0211\n",
      "Epoch 27/100\n",
      "157152/157152 [==============================] - 17s 106us/step - loss: 0.0223 - val_loss: 0.0207\n",
      "Epoch 28/100\n",
      "157152/157152 [==============================] - 17s 108us/step - loss: 0.0222 - val_loss: 0.0212\n",
      "Epoch 29/100\n",
      "157152/157152 [==============================] - 17s 108us/step - loss: 0.0220 - val_loss: 0.0212\n",
      "Epoch 30/100\n",
      "157152/157152 [==============================] - 18s 115us/step - loss: 0.0219 - val_loss: 0.0209\n",
      "Epoch 31/100\n",
      "157152/157152 [==============================] - 17s 107us/step - loss: 0.0218 - val_loss: 0.0208\n",
      "perc99.5SubjectM2andFold1\n",
      "261334\n",
      "82291\n",
      "Train on 235037 samples, validate on 74761 samples\n",
      "Epoch 1/100\n",
      "235037/235037 [==============================] - 30s 129us/step - loss: 0.0565 - val_loss: 0.0478\n",
      "Epoch 2/100\n",
      "235037/235037 [==============================] - 25s 106us/step - loss: 0.0471 - val_loss: 0.0438\n",
      "Epoch 3/100\n",
      "235037/235037 [==============================] - 24s 103us/step - loss: 0.0447 - val_loss: 0.0420\n",
      "Epoch 4/100\n",
      "235037/235037 [==============================] - 25s 105us/step - loss: 0.0427 - val_loss: 0.0408\n",
      "Epoch 5/100\n",
      "235037/235037 [==============================] - 26s 109us/step - loss: 0.0413 - val_loss: 0.0394\n",
      "Epoch 6/100\n",
      "235037/235037 [==============================] - 27s 114us/step - loss: 0.0402 - val_loss: 0.0392\n",
      "Epoch 7/100\n",
      "235037/235037 [==============================] - 29s 125us/step - loss: 0.0393 - val_loss: 0.0387\n",
      "Epoch 8/100\n",
      "235037/235037 [==============================] - 28s 121us/step - loss: 0.0386 - val_loss: 0.0373\n",
      "Epoch 9/100\n",
      "235037/235037 [==============================] - 29s 122us/step - loss: 0.0379 - val_loss: 0.0366\n",
      "Epoch 10/100\n",
      "235037/235037 [==============================] - 29s 125us/step - loss: 0.0374 - val_loss: 0.0373\n",
      "Epoch 11/100\n",
      "235037/235037 [==============================] - 31s 131us/step - loss: 0.0369 - val_loss: 0.0362\n",
      "Epoch 12/100\n",
      "235037/235037 [==============================] - 31s 132us/step - loss: 0.0364 - val_loss: 0.0361\n",
      "Epoch 13/100\n",
      "235037/235037 [==============================] - 29s 122us/step - loss: 0.0361 - val_loss: 0.0361\n",
      "Epoch 14/100\n",
      "235037/235037 [==============================] - 30s 126us/step - loss: 0.0357 - val_loss: 0.0355\n",
      "Epoch 15/100\n",
      "235037/235037 [==============================] - 29s 124us/step - loss: 0.0353 - val_loss: 0.0354\n",
      "Epoch 16/100\n",
      "235037/235037 [==============================] - 30s 128us/step - loss: 0.0349 - val_loss: 0.0337\n",
      "Epoch 17/100\n",
      "235037/235037 [==============================] - 29s 125us/step - loss: 0.0346 - val_loss: 0.0335\n",
      "Epoch 18/100\n",
      "235037/235037 [==============================] - 29s 123us/step - loss: 0.0344 - val_loss: 0.0340\n",
      "Epoch 19/100\n",
      "235037/235037 [==============================] - 29s 122us/step - loss: 0.0340 - val_loss: 0.0331\n",
      "Epoch 20/100\n",
      "235037/235037 [==============================] - 28s 118us/step - loss: 0.0338 - val_loss: 0.0330\n",
      "Epoch 21/100\n",
      "235037/235037 [==============================] - 28s 121us/step - loss: 0.0335 - val_loss: 0.0330\n",
      "Epoch 22/100\n",
      "235037/235037 [==============================] - 30s 126us/step - loss: 0.0333 - val_loss: 0.0326\n",
      "Epoch 23/100\n",
      "235037/235037 [==============================] - 29s 123us/step - loss: 0.0332 - val_loss: 0.0324\n",
      "Epoch 24/100\n",
      "235037/235037 [==============================] - 29s 123us/step - loss: 0.0329 - val_loss: 0.0329\n",
      "Epoch 25/100\n",
      "235037/235037 [==============================] - 28s 119us/step - loss: 0.0327 - val_loss: 0.0325\n",
      "Epoch 26/100\n",
      "235037/235037 [==============================] - 28s 121us/step - loss: 0.0325 - val_loss: 0.0320\n",
      "Epoch 27/100\n",
      "235037/235037 [==============================] - 29s 121us/step - loss: 0.0324 - val_loss: 0.0320\n",
      "Epoch 28/100\n",
      "235037/235037 [==============================] - 29s 125us/step - loss: 0.0322 - val_loss: 0.0317\n",
      "Epoch 29/100\n",
      "235037/235037 [==============================] - 31s 131us/step - loss: 0.0321 - val_loss: 0.0317\n",
      "Epoch 30/100\n",
      "235037/235037 [==============================] - 30s 129us/step - loss: 0.0319 - val_loss: 0.0316\n",
      "Epoch 31/100\n",
      "235037/235037 [==============================] - 29s 123us/step - loss: 0.0317 - val_loss: 0.0314\n",
      "Epoch 32/100\n",
      "235037/235037 [==============================] - 29s 124us/step - loss: 0.0316 - val_loss: 0.0314\n",
      "Epoch 33/100\n",
      "235037/235037 [==============================] - 29s 122us/step - loss: 0.0315 - val_loss: 0.0312\n",
      "Epoch 34/100\n",
      "235037/235037 [==============================] - 29s 122us/step - loss: 0.0314 - val_loss: 0.0314\n",
      "Epoch 35/100\n",
      "235037/235037 [==============================] - 28s 118us/step - loss: 0.0312 - val_loss: 0.0312\n",
      "Epoch 36/100\n",
      "235037/235037 [==============================] - 29s 123us/step - loss: 0.0312 - val_loss: 0.0311\n",
      "Epoch 37/100\n",
      "235037/235037 [==============================] - 29s 123us/step - loss: 0.0310 - val_loss: 0.0307\n",
      "Epoch 38/100\n",
      "235037/235037 [==============================] - 29s 124us/step - loss: 0.0308 - val_loss: 0.0309\n",
      "Epoch 39/100\n",
      "235037/235037 [==============================] - 29s 123us/step - loss: 0.0308 - val_loss: 0.0309\n",
      "Epoch 40/100\n",
      "235037/235037 [==============================] - 28s 119us/step - loss: 0.0307 - val_loss: 0.0308\n",
      "Epoch 41/100\n",
      "235037/235037 [==============================] - 29s 123us/step - loss: 0.0306 - val_loss: 0.0311\n",
      "perc99.5SubjectM2andFold2\n",
      "267998\n",
      "90196\n",
      "Train on 167614 samples, validate on 54892 samples\n",
      "Epoch 1/100\n",
      "167614/167614 [==============================] - 25s 151us/step - loss: 0.0503 - val_loss: 0.0405\n",
      "Epoch 2/100\n",
      "167614/167614 [==============================] - 21s 125us/step - loss: 0.0385 - val_loss: 0.0373\n",
      "Epoch 3/100\n",
      "167614/167614 [==============================] - 21s 124us/step - loss: 0.0352 - val_loss: 0.0354\n",
      "Epoch 4/100\n",
      "167614/167614 [==============================] - 22s 129us/step - loss: 0.0331 - val_loss: 0.0329\n",
      "Epoch 5/100\n",
      "167614/167614 [==============================] - 21s 123us/step - loss: 0.0316 - val_loss: 0.0310\n",
      "Epoch 6/100\n",
      "167614/167614 [==============================] - 20s 121us/step - loss: 0.0306 - val_loss: 0.0301\n",
      "Epoch 7/100\n",
      "167614/167614 [==============================] - 21s 123us/step - loss: 0.0296 - val_loss: 0.0296\n",
      "Epoch 8/100\n",
      "167614/167614 [==============================] - 20s 122us/step - loss: 0.0288 - val_loss: 0.0288\n",
      "Epoch 9/100\n",
      "167614/167614 [==============================] - 21s 124us/step - loss: 0.0282 - val_loss: 0.0287\n",
      "Epoch 10/100\n",
      "167614/167614 [==============================] - 21s 122us/step - loss: 0.0276 - val_loss: 0.0276\n",
      "Epoch 11/100\n",
      "167614/167614 [==============================] - 21s 125us/step - loss: 0.0271 - val_loss: 0.0269\n",
      "Epoch 12/100\n",
      "167614/167614 [==============================] - 21s 123us/step - loss: 0.0266 - val_loss: 0.0270\n",
      "Epoch 13/100\n",
      "167614/167614 [==============================] - 20s 121us/step - loss: 0.0262 - val_loss: 0.0260\n",
      "Epoch 14/100\n",
      "167614/167614 [==============================] - 21s 124us/step - loss: 0.0258 - val_loss: 0.0272\n",
      "Epoch 15/100\n",
      "167614/167614 [==============================] - 21s 127us/step - loss: 0.0255 - val_loss: 0.0264\n",
      "Epoch 16/100\n",
      "167614/167614 [==============================] - 21s 127us/step - loss: 0.0251 - val_loss: 0.0256\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167614/167614 [==============================] - 22s 129us/step - loss: 0.0248 - val_loss: 0.0263\n",
      "Epoch 18/100\n",
      "167614/167614 [==============================] - 21s 127us/step - loss: 0.0246 - val_loss: 0.0252\n",
      "Epoch 19/100\n",
      "167614/167614 [==============================] - 23s 136us/step - loss: 0.0243 - val_loss: 0.0254\n",
      "Epoch 20/100\n",
      "167614/167614 [==============================] - 21s 126us/step - loss: 0.0240 - val_loss: 0.0247\n",
      "Epoch 21/100\n",
      "167614/167614 [==============================] - 22s 134us/step - loss: 0.0240 - val_loss: 0.0247\n",
      "Epoch 22/100\n",
      "167614/167614 [==============================] - 22s 129us/step - loss: 0.0235 - val_loss: 0.0240\n",
      "Epoch 23/100\n",
      "167614/167614 [==============================] - 20s 122us/step - loss: 0.0234 - val_loss: 0.0239\n",
      "Epoch 24/100\n",
      "167614/167614 [==============================] - 21s 125us/step - loss: 0.0232 - val_loss: 0.0241\n",
      "Epoch 25/100\n",
      "167614/167614 [==============================] - 21s 125us/step - loss: 0.0229 - val_loss: 0.0234\n",
      "Epoch 26/100\n",
      "167614/167614 [==============================] - 21s 122us/step - loss: 0.0229 - val_loss: 0.0233\n",
      "Epoch 27/100\n",
      "167614/167614 [==============================] - 20s 119us/step - loss: 0.0227 - val_loss: 0.0240\n",
      "Epoch 28/100\n",
      "167614/167614 [==============================] - 21s 124us/step - loss: 0.0225 - val_loss: 0.0230\n",
      "Epoch 29/100\n",
      "167614/167614 [==============================] - 21s 123us/step - loss: 0.0224 - val_loss: 0.0232\n",
      "Epoch 30/100\n",
      "167614/167614 [==============================] - 20s 121us/step - loss: 0.0223 - val_loss: 0.0238\n",
      "Epoch 31/100\n",
      "167614/167614 [==============================] - 20s 122us/step - loss: 0.0222 - val_loss: 0.0224\n",
      "Epoch 32/100\n",
      "167614/167614 [==============================] - 21s 123us/step - loss: 0.0220 - val_loss: 0.0247\n",
      "Epoch 33/100\n",
      "167614/167614 [==============================] - 20s 122us/step - loss: 0.0219 - val_loss: 0.0230\n",
      "Epoch 34/100\n",
      "167614/167614 [==============================] - 21s 124us/step - loss: 0.0218 - val_loss: 0.0232\n",
      "Epoch 35/100\n",
      "167614/167614 [==============================] - 20s 122us/step - loss: 0.0216 - val_loss: 0.0225\n",
      "perc99.5SubjectM2andFold3\n",
      "241650\n",
      "80053\n",
      "Train on 159586 samples, validate on 53150 samples\n",
      "Epoch 1/100\n",
      "159586/159586 [==============================] - 23s 144us/step - loss: 0.0592 - val_loss: 0.0461\n",
      "Epoch 2/100\n",
      "159586/159586 [==============================] - 21s 132us/step - loss: 0.0480 - val_loss: 0.0421\n",
      "Epoch 3/100\n",
      "159586/159586 [==============================] - 20s 122us/step - loss: 0.0452 - val_loss: 0.0438\n",
      "Epoch 4/100\n",
      "159586/159586 [==============================] - 19s 121us/step - loss: 0.0432 - val_loss: 0.0384\n",
      "Epoch 5/100\n",
      "159586/159586 [==============================] - 20s 126us/step - loss: 0.0415 - val_loss: 0.0365\n",
      "Epoch 6/100\n",
      "159586/159586 [==============================] - 19s 118us/step - loss: 0.0403 - val_loss: 0.0358\n",
      "Epoch 7/100\n",
      "159586/159586 [==============================] - 19s 119us/step - loss: 0.0392 - val_loss: 0.0356\n",
      "Epoch 8/100\n",
      "159586/159586 [==============================] - 20s 123us/step - loss: 0.0382 - val_loss: 0.0349\n",
      "Epoch 9/100\n",
      "159586/159586 [==============================] - 20s 124us/step - loss: 0.0376 - val_loss: 0.0330\n",
      "Epoch 10/100\n",
      "159586/159586 [==============================] - 21s 130us/step - loss: 0.0370 - val_loss: 0.0333\n",
      "Epoch 11/100\n",
      "159586/159586 [==============================] - 20s 123us/step - loss: 0.0362 - val_loss: 0.0325\n",
      "Epoch 12/100\n",
      "159586/159586 [==============================] - 19s 118us/step - loss: 0.0359 - val_loss: 0.0329\n",
      "Epoch 13/100\n",
      "159586/159586 [==============================] - 20s 127us/step - loss: 0.0353 - val_loss: 0.0321\n",
      "Epoch 14/100\n",
      "159586/159586 [==============================] - 20s 124us/step - loss: 0.0349 - val_loss: 0.0329\n",
      "Epoch 15/100\n",
      "159586/159586 [==============================] - 20s 124us/step - loss: 0.0344 - val_loss: 0.0325\n",
      "Epoch 16/100\n",
      "159586/159586 [==============================] - 19s 122us/step - loss: 0.0340 - val_loss: 0.0314\n",
      "Epoch 17/100\n",
      "159586/159586 [==============================] - 19s 121us/step - loss: 0.0338 - val_loss: 0.0301\n",
      "Epoch 18/100\n",
      "159586/159586 [==============================] - 19s 119us/step - loss: 0.0337 - val_loss: 0.0306\n",
      "Epoch 19/100\n",
      "159586/159586 [==============================] - 19s 120us/step - loss: 0.0331 - val_loss: 0.0304\n",
      "Epoch 20/100\n",
      "159586/159586 [==============================] - 20s 124us/step - loss: 0.0331 - val_loss: 0.0304\n",
      "Epoch 21/100\n",
      "159586/159586 [==============================] - 19s 121us/step - loss: 0.0328 - val_loss: 0.0297\n",
      "Epoch 22/100\n",
      "159586/159586 [==============================] - 20s 124us/step - loss: 0.0323 - val_loss: 0.0293\n",
      "Epoch 23/100\n",
      "159586/159586 [==============================] - 20s 123us/step - loss: 0.0323 - val_loss: 0.0291\n",
      "Epoch 24/100\n",
      "159586/159586 [==============================] - 19s 118us/step - loss: 0.0320 - val_loss: 0.0289\n",
      "Epoch 25/100\n",
      "159586/159586 [==============================] - 15s 95us/step - loss: 0.0318 - val_loss: 0.0300\n",
      "Epoch 26/100\n",
      "159586/159586 [==============================] - 15s 96us/step - loss: 0.0316 - val_loss: 0.0291\n",
      "Epoch 27/100\n",
      "159586/159586 [==============================] - 15s 96us/step - loss: 0.0314 - val_loss: 0.0296\n",
      "Epoch 28/100\n",
      "159586/159586 [==============================] - 18s 110us/step - loss: 0.0312 - val_loss: 0.0295\n",
      "perc99.5SubjectM2andFold4\n",
      "238443\n",
      "78845\n",
      "Train on 159819 samples, validate on 51883 samples\n",
      "Epoch 1/100\n",
      "159819/159819 [==============================] - 24s 152us/step - loss: 0.0556 - val_loss: 0.0423\n",
      "Epoch 2/100\n",
      "159819/159819 [==============================] - 18s 111us/step - loss: 0.0436 - val_loss: 0.0367\n",
      "Epoch 3/100\n",
      "159819/159819 [==============================] - 17s 108us/step - loss: 0.0403 - val_loss: 0.0351\n",
      "Epoch 4/100\n",
      "159819/159819 [==============================] - 17s 106us/step - loss: 0.0378 - val_loss: 0.0333\n",
      "Epoch 5/100\n",
      "159819/159819 [==============================] - 18s 113us/step - loss: 0.0360 - val_loss: 0.0319\n",
      "Epoch 6/100\n",
      "159819/159819 [==============================] - 17s 109us/step - loss: 0.0346 - val_loss: 0.0309\n",
      "Epoch 7/100\n",
      "159819/159819 [==============================] - 17s 108us/step - loss: 0.0337 - val_loss: 0.0306\n",
      "Epoch 8/100\n",
      "159819/159819 [==============================] - 17s 108us/step - loss: 0.0328 - val_loss: 0.0302\n",
      "Epoch 9/100\n",
      "159819/159819 [==============================] - 18s 110us/step - loss: 0.0319 - val_loss: 0.0291\n",
      "Epoch 10/100\n",
      "159819/159819 [==============================] - 17s 107us/step - loss: 0.0311 - val_loss: 0.0284\n",
      "Epoch 11/100\n",
      "159819/159819 [==============================] - 17s 109us/step - loss: 0.0306 - val_loss: 0.0282\n",
      "Epoch 12/100\n",
      "159819/159819 [==============================] - 18s 110us/step - loss: 0.0300 - val_loss: 0.0275\n",
      "Epoch 13/100\n",
      "159819/159819 [==============================] - 18s 115us/step - loss: 0.0295 - val_loss: 0.0274\n",
      "Epoch 14/100\n",
      "159819/159819 [==============================] - 19s 118us/step - loss: 0.0293 - val_loss: 0.0279\n",
      "Epoch 15/100\n",
      "159819/159819 [==============================] - 18s 110us/step - loss: 0.0288 - val_loss: 0.0270\n",
      "Epoch 16/100\n",
      "159819/159819 [==============================] - 17s 107us/step - loss: 0.0285 - val_loss: 0.0257\n",
      "Epoch 17/100\n",
      "159819/159819 [==============================] - 19s 118us/step - loss: 0.0283 - val_loss: 0.0268\n",
      "Epoch 18/100\n",
      "159819/159819 [==============================] - 19s 118us/step - loss: 0.0278 - val_loss: 0.0259\n",
      "Epoch 19/100\n",
      "159819/159819 [==============================] - 18s 111us/step - loss: 0.0275 - val_loss: 0.0256\n",
      "Epoch 20/100\n",
      "159819/159819 [==============================] - 19s 121us/step - loss: 0.0273 - val_loss: 0.0251\n",
      "Epoch 21/100\n",
      "159819/159819 [==============================] - 20s 124us/step - loss: 0.0271 - val_loss: 0.0253\n",
      "Epoch 22/100\n",
      "159819/159819 [==============================] - 19s 118us/step - loss: 0.0269 - val_loss: 0.0256\n",
      "Epoch 23/100\n",
      "159819/159819 [==============================] - 19s 121us/step - loss: 0.0266 - val_loss: 0.0246\n",
      "Epoch 24/100\n",
      "159819/159819 [==============================] - 17s 109us/step - loss: 0.0264 - val_loss: 0.0262\n",
      "Epoch 25/100\n",
      "159819/159819 [==============================] - 16s 103us/step - loss: 0.0263 - val_loss: 0.0254\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159819/159819 [==============================] - 17s 106us/step - loss: 0.0260 - val_loss: 0.0250\n",
      "Epoch 27/100\n",
      "159819/159819 [==============================] - 17s 108us/step - loss: 0.0259 - val_loss: 0.0250\n",
      "perc99.75SubjectF1andFold1\n",
      "269633\n",
      "86916\n",
      "Train on 240700 samples, validate on 78328 samples\n",
      "Epoch 1/100\n",
      "240700/240700 [==============================] - 32s 134us/step - loss: 0.0500 - val_loss: 0.0428\n",
      "Epoch 2/100\n",
      "240700/240700 [==============================] - 28s 115us/step - loss: 0.0407 - val_loss: 0.0393\n",
      "Epoch 3/100\n",
      "240700/240700 [==============================] - 28s 117us/step - loss: 0.0382 - val_loss: 0.0375\n",
      "Epoch 4/100\n",
      "240700/240700 [==============================] - 28s 116us/step - loss: 0.0365 - val_loss: 0.0365\n",
      "Epoch 5/100\n",
      "240700/240700 [==============================] - 28s 115us/step - loss: 0.0351 - val_loss: 0.0349\n",
      "Epoch 6/100\n",
      "240700/240700 [==============================] - 28s 115us/step - loss: 0.0339 - val_loss: 0.0337\n",
      "Epoch 7/100\n",
      "240700/240700 [==============================] - 28s 114us/step - loss: 0.0330 - val_loss: 0.0327\n",
      "Epoch 8/100\n",
      "240700/240700 [==============================] - 28s 116us/step - loss: 0.0321 - val_loss: 0.0320\n",
      "Epoch 9/100\n",
      "240700/240700 [==============================] - 28s 116us/step - loss: 0.0312 - val_loss: 0.0319\n",
      "Epoch 10/100\n",
      "240700/240700 [==============================] - 29s 122us/step - loss: 0.0306 - val_loss: 0.0305\n",
      "Epoch 11/100\n",
      "240700/240700 [==============================] - 28s 116us/step - loss: 0.0299 - val_loss: 0.0297\n",
      "Epoch 12/100\n",
      "240700/240700 [==============================] - 28s 116us/step - loss: 0.0294 - val_loss: 0.0302\n",
      "Epoch 13/100\n",
      "240700/240700 [==============================] - 29s 121us/step - loss: 0.0290 - val_loss: 0.0290\n",
      "Epoch 14/100\n",
      "240700/240700 [==============================] - 30s 126us/step - loss: 0.0285 - val_loss: 0.0296\n",
      "Epoch 15/100\n",
      "240700/240700 [==============================] - 27s 114us/step - loss: 0.0282 - val_loss: 0.0301\n",
      "Epoch 16/100\n",
      "240700/240700 [==============================] - 28s 115us/step - loss: 0.0278 - val_loss: 0.0282\n",
      "Epoch 17/100\n",
      "240700/240700 [==============================] - 28s 114us/step - loss: 0.0274 - val_loss: 0.0275\n",
      "Epoch 18/100\n",
      "240700/240700 [==============================] - 28s 117us/step - loss: 0.0272 - val_loss: 0.0275\n",
      "Epoch 19/100\n",
      "240700/240700 [==============================] - 28s 116us/step - loss: 0.0269 - val_loss: 0.0271\n",
      "Epoch 20/100\n",
      "240700/240700 [==============================] - 28s 114us/step - loss: 0.0266 - val_loss: 0.0274\n",
      "Epoch 21/100\n",
      "240700/240700 [==============================] - 28s 115us/step - loss: 0.0263 - val_loss: 0.0272\n",
      "Epoch 22/100\n",
      "240700/240700 [==============================] - 28s 116us/step - loss: 0.0261 - val_loss: 0.0268\n",
      "Epoch 23/100\n",
      "240700/240700 [==============================] - 27s 113us/step - loss: 0.0259 - val_loss: 0.0278\n",
      "Epoch 24/100\n",
      "240700/240700 [==============================] - 28s 116us/step - loss: 0.0257 - val_loss: 0.0265\n",
      "Epoch 25/100\n",
      "240700/240700 [==============================] - 28s 114us/step - loss: 0.0255 - val_loss: 0.0265\n",
      "Epoch 26/100\n",
      "240700/240700 [==============================] - 28s 118us/step - loss: 0.0254 - val_loss: 0.0265\n",
      "Epoch 27/100\n",
      "240700/240700 [==============================] - 29s 121us/step - loss: 0.0251 - val_loss: 0.0262\n",
      "Epoch 28/100\n",
      "240700/240700 [==============================] - 28s 115us/step - loss: 0.0251 - val_loss: 0.0262\n",
      "Epoch 29/100\n",
      "240700/240700 [==============================] - 28s 117us/step - loss: 0.0249 - val_loss: 0.0255\n",
      "Epoch 30/100\n",
      "240700/240700 [==============================] - 27s 114us/step - loss: 0.0247 - val_loss: 0.0255\n",
      "Epoch 31/100\n",
      "240700/240700 [==============================] - 28s 118us/step - loss: 0.0246 - val_loss: 0.0254\n",
      "Epoch 32/100\n",
      "240700/240700 [==============================] - 29s 119us/step - loss: 0.0245 - val_loss: 0.0261\n",
      "Epoch 33/100\n",
      "240700/240700 [==============================] - 28s 115us/step - loss: 0.0244 - val_loss: 0.0256\n",
      "Epoch 34/100\n",
      "240700/240700 [==============================] - 28s 118us/step - loss: 0.0243 - val_loss: 0.0259\n",
      "Epoch 35/100\n",
      "240700/240700 [==============================] - 30s 123us/step - loss: 0.0242 - val_loss: 0.0256\n",
      "perc99.75SubjectF1andFold2\n",
      "287903\n",
      "95122\n",
      "Train on 104856 samples, validate on 33208 samples\n",
      "Epoch 1/100\n",
      "104856/104856 [==============================] - 18s 176us/step - loss: 0.0621 - val_loss: 0.0492\n",
      "Epoch 2/100\n",
      "104856/104856 [==============================] - 13s 120us/step - loss: 0.0467 - val_loss: 0.0431\n",
      "Epoch 3/100\n",
      "104856/104856 [==============================] - 12s 118us/step - loss: 0.0412 - val_loss: 0.0400\n",
      "Epoch 4/100\n",
      "104856/104856 [==============================] - 12s 115us/step - loss: 0.0385 - val_loss: 0.0372\n",
      "Epoch 5/100\n",
      "104856/104856 [==============================] - 12s 116us/step - loss: 0.0362 - val_loss: 0.0349\n",
      "Epoch 6/100\n",
      "104856/104856 [==============================] - 12s 116us/step - loss: 0.0340 - val_loss: 0.0351\n",
      "Epoch 7/100\n",
      "104856/104856 [==============================] - 12s 116us/step - loss: 0.0322 - val_loss: 0.0350\n",
      "Epoch 8/100\n",
      "104856/104856 [==============================] - 12s 116us/step - loss: 0.0310 - val_loss: 0.0329\n",
      "Epoch 9/100\n",
      "104856/104856 [==============================] - 12s 116us/step - loss: 0.0298 - val_loss: 0.0309\n",
      "Epoch 10/100\n",
      "104856/104856 [==============================] - 11s 101us/step - loss: 0.0286 - val_loss: 0.0316\n",
      "Epoch 11/100\n",
      "104856/104856 [==============================] - 11s 104us/step - loss: 0.0276 - val_loss: 0.0322\n",
      "Epoch 12/100\n",
      "104856/104856 [==============================] - 11s 108us/step - loss: 0.0272 - val_loss: 0.0313\n",
      "Epoch 13/100\n",
      "104856/104856 [==============================] - 10s 99us/step - loss: 0.0262 - val_loss: 0.0291\n",
      "Epoch 14/100\n",
      "104856/104856 [==============================] - 9s 87us/step - loss: 0.0255 - val_loss: 0.0296\n",
      "Epoch 15/100\n",
      "104856/104856 [==============================] - 10s 96us/step - loss: 0.0249 - val_loss: 0.0289\n",
      "Epoch 16/100\n",
      "104856/104856 [==============================] - 10s 97us/step - loss: 0.0245 - val_loss: 0.0278\n",
      "Epoch 17/100\n",
      "104856/104856 [==============================] - 10s 93us/step - loss: 0.0239 - val_loss: 0.0279\n",
      "Epoch 18/100\n",
      "104856/104856 [==============================] - 10s 97us/step - loss: 0.0234 - val_loss: 0.0287\n",
      "Epoch 19/100\n",
      "104856/104856 [==============================] - 10s 99us/step - loss: 0.0232 - val_loss: 0.0277\n",
      "Epoch 20/100\n",
      "104856/104856 [==============================] - 11s 101us/step - loss: 0.0227 - val_loss: 0.0269\n",
      "Epoch 21/100\n",
      "104856/104856 [==============================] - 10s 98us/step - loss: 0.0226 - val_loss: 0.0274\n",
      "Epoch 22/100\n",
      "104856/104856 [==============================] - 10s 100us/step - loss: 0.0223 - val_loss: 0.0271\n",
      "Epoch 23/100\n",
      "104856/104856 [==============================] - 10s 98us/step - loss: 0.0219 - val_loss: 0.0274\n",
      "Epoch 24/100\n",
      "104856/104856 [==============================] - 11s 107us/step - loss: 0.0217 - val_loss: 0.0262\n",
      "Epoch 25/100\n",
      "104856/104856 [==============================] - 12s 117us/step - loss: 0.0214 - val_loss: 0.0274\n",
      "Epoch 26/100\n",
      "104856/104856 [==============================] - 12s 112us/step - loss: 0.0211 - val_loss: 0.0255\n",
      "Epoch 27/100\n",
      "104856/104856 [==============================] - 12s 117us/step - loss: 0.0211 - val_loss: 0.0264\n",
      "Epoch 28/100\n",
      "104856/104856 [==============================] - 11s 106us/step - loss: 0.0207 - val_loss: 0.0262\n",
      "Epoch 29/100\n",
      "104856/104856 [==============================] - 11s 101us/step - loss: 0.0207 - val_loss: 0.0270\n",
      "Epoch 30/100\n",
      "104856/104856 [==============================] - 11s 101us/step - loss: 0.0205 - val_loss: 0.0264\n",
      "perc99.75SubjectF1andFold3\n",
      "221656\n",
      "73022\n",
      "Train on 197531 samples, validate on 64944 samples\n",
      "Epoch 1/100\n",
      "197531/197531 [==============================] - 30s 153us/step - loss: 0.0528 - val_loss: 0.0414\n",
      "Epoch 2/100\n",
      "197531/197531 [==============================] - 24s 120us/step - loss: 0.0427 - val_loss: 0.0385\n",
      "Epoch 3/100\n",
      "197531/197531 [==============================] - 24s 121us/step - loss: 0.0403 - val_loss: 0.0396\n",
      "Epoch 4/100\n",
      "197531/197531 [==============================] - 24s 120us/step - loss: 0.0386 - val_loss: 0.0356\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197531/197531 [==============================] - 24s 120us/step - loss: 0.0372 - val_loss: 0.0346\n",
      "Epoch 6/100\n",
      "197531/197531 [==============================] - 24s 123us/step - loss: 0.0361 - val_loss: 0.0356\n",
      "Epoch 7/100\n",
      "197531/197531 [==============================] - 23s 117us/step - loss: 0.0351 - val_loss: 0.0339\n",
      "Epoch 8/100\n",
      "197531/197531 [==============================] - 20s 102us/step - loss: 0.0344 - val_loss: 0.0324\n",
      "Epoch 9/100\n",
      "197531/197531 [==============================] - 19s 96us/step - loss: 0.0337 - val_loss: 0.0315\n",
      "Epoch 10/100\n",
      "197531/197531 [==============================] - 20s 99us/step - loss: 0.0330 - val_loss: 0.0325\n",
      "Epoch 11/100\n",
      "197531/197531 [==============================] - 19s 94us/step - loss: 0.0323 - val_loss: 0.0303\n",
      "Epoch 12/100\n",
      "197531/197531 [==============================] - 19s 95us/step - loss: 0.0318 - val_loss: 0.0310\n",
      "Epoch 13/100\n",
      "197531/197531 [==============================] - 19s 95us/step - loss: 0.0313 - val_loss: 0.0300\n",
      "Epoch 14/100\n",
      "197531/197531 [==============================] - 19s 98us/step - loss: 0.0308 - val_loss: 0.0295\n",
      "Epoch 15/100\n",
      "197531/197531 [==============================] - 19s 95us/step - loss: 0.0304 - val_loss: 0.0294\n",
      "Epoch 16/100\n",
      "197531/197531 [==============================] - 18s 93us/step - loss: 0.0299 - val_loss: 0.0288\n",
      "Epoch 17/100\n",
      "197531/197531 [==============================] - 19s 96us/step - loss: 0.0296 - val_loss: 0.0287\n",
      "Epoch 18/100\n",
      "197531/197531 [==============================] - 18s 93us/step - loss: 0.0292 - val_loss: 0.0285\n",
      "Epoch 19/100\n",
      "197531/197531 [==============================] - 19s 97us/step - loss: 0.0290 - val_loss: 0.0291\n",
      "Epoch 20/100\n",
      "197531/197531 [==============================] - 19s 95us/step - loss: 0.0287 - val_loss: 0.0277\n",
      "Epoch 21/100\n",
      "197531/197531 [==============================] - 18s 91us/step - loss: 0.0284 - val_loss: 0.0273\n",
      "Epoch 22/100\n",
      "197531/197531 [==============================] - 18s 91us/step - loss: 0.0282 - val_loss: 0.0274\n",
      "Epoch 23/100\n",
      "197531/197531 [==============================] - 18s 93us/step - loss: 0.0279 - val_loss: 0.0277\n",
      "Epoch 24/100\n",
      "197531/197531 [==============================] - 20s 99us/step - loss: 0.0276 - val_loss: 0.0267\n",
      "Epoch 25/100\n",
      "197531/197531 [==============================] - 21s 107us/step - loss: 0.0274 - val_loss: 0.0261\n",
      "Epoch 26/100\n",
      "197531/197531 [==============================] - 21s 106us/step - loss: 0.0272 - val_loss: 0.0269\n",
      "Epoch 27/100\n",
      "197531/197531 [==============================] - 21s 104us/step - loss: 0.0271 - val_loss: 0.0256\n",
      "Epoch 28/100\n",
      "197531/197531 [==============================] - 22s 110us/step - loss: 0.0269 - val_loss: 0.0263\n",
      "Epoch 29/100\n",
      "197531/197531 [==============================] - 21s 109us/step - loss: 0.0267 - val_loss: 0.0264\n",
      "Epoch 30/100\n",
      "197531/197531 [==============================] - 22s 111us/step - loss: 0.0265 - val_loss: 0.0256\n",
      "Epoch 31/100\n",
      "197531/197531 [==============================] - 21s 107us/step - loss: 0.0263 - val_loss: 0.0253\n",
      "Epoch 32/100\n",
      "197531/197531 [==============================] - 21s 105us/step - loss: 0.0263 - val_loss: 0.0257\n",
      "Epoch 33/100\n",
      "197531/197531 [==============================] - 21s 107us/step - loss: 0.0262 - val_loss: 0.0263\n",
      "Epoch 34/100\n",
      "197531/197531 [==============================] - 21s 108us/step - loss: 0.0260 - val_loss: 0.0258\n",
      "Epoch 35/100\n",
      "197531/197531 [==============================] - 21s 105us/step - loss: 0.0259 - val_loss: 0.0258\n",
      "perc99.75SubjectF1andFold4\n",
      "223694\n",
      "75093\n",
      "Train on 110934 samples, validate on 36771 samples\n",
      "Epoch 1/100\n",
      "110934/110934 [==============================] - 17s 149us/step - loss: 0.0566 - val_loss: 0.0441\n",
      "Epoch 2/100\n",
      "110934/110934 [==============================] - 12s 108us/step - loss: 0.0424 - val_loss: 0.0423\n",
      "Epoch 3/100\n",
      "110934/110934 [==============================] - 12s 107us/step - loss: 0.0393 - val_loss: 0.0376\n",
      "Epoch 4/100\n",
      "110934/110934 [==============================] - 12s 106us/step - loss: 0.0367 - val_loss: 0.0355\n",
      "Epoch 5/100\n",
      "110934/110934 [==============================] - 12s 108us/step - loss: 0.0346 - val_loss: 0.0344\n",
      "Epoch 6/100\n",
      "110934/110934 [==============================] - 12s 110us/step - loss: 0.0332 - val_loss: 0.0345\n",
      "Epoch 7/100\n",
      "110934/110934 [==============================] - 12s 109us/step - loss: 0.0319 - val_loss: 0.0317\n",
      "Epoch 8/100\n",
      "110934/110934 [==============================] - 12s 111us/step - loss: 0.0308 - val_loss: 0.0328\n",
      "Epoch 9/100\n",
      "110934/110934 [==============================] - 15s 131us/step - loss: 0.0299 - val_loss: 0.0312\n",
      "Epoch 10/100\n",
      "110934/110934 [==============================] - 13s 117us/step - loss: 0.0290 - val_loss: 0.0306\n",
      "Epoch 11/100\n",
      "110934/110934 [==============================] - 12s 107us/step - loss: 0.0285 - val_loss: 0.0290\n",
      "Epoch 12/100\n",
      "110934/110934 [==============================] - 12s 108us/step - loss: 0.0278 - val_loss: 0.0289\n",
      "Epoch 13/100\n",
      "110934/110934 [==============================] - 12s 107us/step - loss: 0.0272 - val_loss: 0.0282\n",
      "Epoch 14/100\n",
      "110934/110934 [==============================] - 12s 108us/step - loss: 0.0266 - val_loss: 0.0287\n",
      "Epoch 15/100\n",
      "110934/110934 [==============================] - 12s 105us/step - loss: 0.0262 - val_loss: 0.0286\n",
      "Epoch 16/100\n",
      "110934/110934 [==============================] - 12s 107us/step - loss: 0.0258 - val_loss: 0.0270\n",
      "Epoch 17/100\n",
      "110934/110934 [==============================] - 12s 108us/step - loss: 0.0253 - val_loss: 0.0269\n",
      "Epoch 18/100\n",
      "110934/110934 [==============================] - 12s 111us/step - loss: 0.0251 - val_loss: 0.0274\n",
      "Epoch 19/100\n",
      "110934/110934 [==============================] - 13s 114us/step - loss: 0.0246 - val_loss: 0.0272\n",
      "Epoch 20/100\n",
      "110934/110934 [==============================] - 12s 109us/step - loss: 0.0243 - val_loss: 0.0274\n",
      "Epoch 21/100\n",
      "110934/110934 [==============================] - 12s 106us/step - loss: 0.0240 - val_loss: 0.0265\n",
      "Epoch 22/100\n",
      "110934/110934 [==============================] - 12s 104us/step - loss: 0.0237 - val_loss: 0.0261\n",
      "Epoch 23/100\n",
      "110934/110934 [==============================] - 12s 105us/step - loss: 0.0234 - val_loss: 0.0264\n",
      "Epoch 24/100\n",
      "110934/110934 [==============================] - 12s 107us/step - loss: 0.0232 - val_loss: 0.0263\n",
      "Epoch 25/100\n",
      "110934/110934 [==============================] - 12s 107us/step - loss: 0.0230 - val_loss: 0.0250\n",
      "Epoch 26/100\n",
      "110934/110934 [==============================] - 12s 107us/step - loss: 0.0229 - val_loss: 0.0256\n",
      "Epoch 27/100\n",
      "110934/110934 [==============================] - 11s 103us/step - loss: 0.0226 - val_loss: 0.0252\n",
      "Epoch 28/100\n",
      "110934/110934 [==============================] - 12s 104us/step - loss: 0.0222 - val_loss: 0.0245\n",
      "Epoch 29/100\n",
      "110934/110934 [==============================] - 12s 110us/step - loss: 0.0222 - val_loss: 0.0249\n",
      "Epoch 30/100\n",
      "110934/110934 [==============================] - 12s 107us/step - loss: 0.0219 - val_loss: 0.0233\n",
      "Epoch 31/100\n",
      "110934/110934 [==============================] - 12s 106us/step - loss: 0.0218 - val_loss: 0.0242\n",
      "Epoch 32/100\n",
      "110934/110934 [==============================] - 12s 108us/step - loss: 0.0218 - val_loss: 0.0244\n",
      "Epoch 33/100\n",
      "110934/110934 [==============================] - 12s 111us/step - loss: 0.0214 - val_loss: 0.0233\n",
      "Epoch 34/100\n",
      "110934/110934 [==============================] - 12s 108us/step - loss: 0.0216 - val_loss: 0.0238\n",
      "perc99.75SubjectF2andFold1\n",
      "233071\n",
      "75200\n",
      "Train on 143058 samples, validate on 46284 samples\n",
      "Epoch 1/100\n",
      "143058/143058 [==============================] - 20s 140us/step - loss: 0.0506 - val_loss: 0.0392\n",
      "Epoch 2/100\n",
      "143058/143058 [==============================] - 16s 115us/step - loss: 0.0404 - val_loss: 0.0378\n",
      "Epoch 3/100\n",
      "143058/143058 [==============================] - 15s 108us/step - loss: 0.0388 - val_loss: 0.0369\n",
      "Epoch 4/100\n",
      "143058/143058 [==============================] - 15s 107us/step - loss: 0.0380 - val_loss: 0.0360\n",
      "Epoch 5/100\n",
      "143058/143058 [==============================] - 15s 105us/step - loss: 0.0372 - val_loss: 0.0355\n",
      "Epoch 6/100\n",
      "143058/143058 [==============================] - 15s 108us/step - loss: 0.0365 - val_loss: 0.0351\n",
      "Epoch 7/100\n",
      "143058/143058 [==============================] - 16s 108us/step - loss: 0.0359 - val_loss: 0.0346\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143058/143058 [==============================] - 15s 104us/step - loss: 0.0353 - val_loss: 0.0338\n",
      "Epoch 9/100\n",
      "143058/143058 [==============================] - 15s 103us/step - loss: 0.0346 - val_loss: 0.0333\n",
      "Epoch 10/100\n",
      "143058/143058 [==============================] - 16s 110us/step - loss: 0.0342 - val_loss: 0.0329\n",
      "Epoch 11/100\n",
      "143058/143058 [==============================] - 16s 112us/step - loss: 0.0335 - val_loss: 0.0323\n",
      "Epoch 12/100\n",
      "143058/143058 [==============================] - 16s 110us/step - loss: 0.0332 - val_loss: 0.0325\n",
      "Epoch 13/100\n",
      "143058/143058 [==============================] - 16s 112us/step - loss: 0.0329 - val_loss: 0.0320\n",
      "Epoch 14/100\n",
      "143058/143058 [==============================] - 18s 125us/step - loss: 0.0323 - val_loss: 0.0316\n",
      "Epoch 15/100\n",
      "143058/143058 [==============================] - 17s 121us/step - loss: 0.0321 - val_loss: 0.0319\n",
      "Epoch 16/100\n",
      "143058/143058 [==============================] - 18s 126us/step - loss: 0.0316 - val_loss: 0.0312\n",
      "Epoch 17/100\n",
      "143058/143058 [==============================] - 19s 134us/step - loss: 0.0316 - val_loss: 0.0312\n",
      "Epoch 18/100\n",
      "143058/143058 [==============================] - 18s 124us/step - loss: 0.0311 - val_loss: 0.0307\n",
      "Epoch 19/100\n",
      "143058/143058 [==============================] - 18s 124us/step - loss: 0.0310 - val_loss: 0.0305\n",
      "Epoch 20/100\n",
      "143058/143058 [==============================] - 18s 128us/step - loss: 0.0307 - val_loss: 0.0309\n",
      "Epoch 21/100\n",
      "143058/143058 [==============================] - 18s 123us/step - loss: 0.0305 - val_loss: 0.0303\n",
      "Epoch 22/100\n",
      "143058/143058 [==============================] - 18s 128us/step - loss: 0.0302 - val_loss: 0.0304\n",
      "Epoch 23/100\n",
      "143058/143058 [==============================] - 19s 136us/step - loss: 0.0300 - val_loss: 0.0297A: 0s - loss: 0.\n",
      "Epoch 24/100\n",
      "143058/143058 [==============================] - 17s 120us/step - loss: 0.0299 - val_loss: 0.0307\n",
      "Epoch 25/100\n",
      "143058/143058 [==============================] - 17s 116us/step - loss: 0.0297 - val_loss: 0.0301\n",
      "Epoch 26/100\n",
      "143058/143058 [==============================] - 16s 114us/step - loss: 0.0294 - val_loss: 0.0296\n",
      "Epoch 27/100\n",
      "143058/143058 [==============================] - 17s 116us/step - loss: 0.0293 - val_loss: 0.0292\n",
      "Epoch 28/100\n",
      "143058/143058 [==============================] - 16s 115us/step - loss: 0.0291 - val_loss: 0.0290\n",
      "Epoch 29/100\n",
      "143058/143058 [==============================] - 18s 126us/step - loss: 0.0290 - val_loss: 0.0290\n",
      "Epoch 30/100\n",
      "143058/143058 [==============================] - 17s 116us/step - loss: 0.0289 - val_loss: 0.0286\n",
      "Epoch 31/100\n",
      "143058/143058 [==============================] - 16s 115us/step - loss: 0.0288 - val_loss: 0.0292\n",
      "Epoch 32/100\n",
      "143058/143058 [==============================] - 16s 115us/step - loss: 0.0285 - val_loss: 0.0286\n",
      "Epoch 33/100\n",
      "143058/143058 [==============================] - 17s 117us/step - loss: 0.0285 - val_loss: 0.0290\n",
      "Epoch 34/100\n",
      "143058/143058 [==============================] - 18s 124us/step - loss: 0.0283 - val_loss: 0.0289\n",
      "perc99.75SubjectF2andFold2\n",
      "272739\n",
      "92928\n",
      "Train on 165074 samples, validate on 56993 samples\n",
      "Epoch 1/100\n",
      "165074/165074 [==============================] - 26s 158us/step - loss: 0.0484 - val_loss: 0.0364\n",
      "Epoch 2/100\n",
      "165074/165074 [==============================] - 19s 117us/step - loss: 0.0391 - val_loss: 0.0356\n",
      "Epoch 3/100\n",
      "165074/165074 [==============================] - 20s 123us/step - loss: 0.0376 - val_loss: 0.0349\n",
      "Epoch 4/100\n",
      "165074/165074 [==============================] - 20s 122us/step - loss: 0.0365 - val_loss: 0.0337\n",
      "Epoch 5/100\n",
      "165074/165074 [==============================] - 20s 121us/step - loss: 0.0357 - val_loss: 0.0339\n",
      "Epoch 6/100\n",
      "165074/165074 [==============================] - 21s 127us/step - loss: 0.0349 - val_loss: 0.0324\n",
      "Epoch 7/100\n",
      "165074/165074 [==============================] - 21s 130us/step - loss: 0.0342 - val_loss: 0.0325\n",
      "Epoch 8/100\n",
      "165074/165074 [==============================] - 22s 133us/step - loss: 0.0334 - val_loss: 0.0322\n",
      "Epoch 9/100\n",
      "165074/165074 [==============================] - 21s 128us/step - loss: 0.0329 - val_loss: 0.0308\n",
      "Epoch 10/100\n",
      "165074/165074 [==============================] - 23s 140us/step - loss: 0.0324 - val_loss: 0.0311\n",
      "Epoch 11/100\n",
      "165074/165074 [==============================] - 21s 129us/step - loss: 0.0319 - val_loss: 0.0302\n",
      "Epoch 12/100\n",
      "165074/165074 [==============================] - 21s 129us/step - loss: 0.0314 - val_loss: 0.0301\n",
      "Epoch 13/100\n",
      "165074/165074 [==============================] - 21s 129us/step - loss: 0.0311 - val_loss: 0.0294\n",
      "Epoch 14/100\n",
      "165074/165074 [==============================] - 21s 130us/step - loss: 0.0307 - val_loss: 0.0288\n",
      "Epoch 15/100\n",
      "165074/165074 [==============================] - 21s 128us/step - loss: 0.0304 - val_loss: 0.0290\n",
      "Epoch 16/100\n",
      "165074/165074 [==============================] - 21s 124us/step - loss: 0.0300 - val_loss: 0.0285\n",
      "Epoch 17/100\n",
      "165074/165074 [==============================] - 20s 120us/step - loss: 0.0298 - val_loss: 0.0281\n",
      "Epoch 18/100\n",
      "165074/165074 [==============================] - 19s 117us/step - loss: 0.0296 - val_loss: 0.0283\n",
      "Epoch 19/100\n",
      "165074/165074 [==============================] - 21s 125us/step - loss: 0.0293 - val_loss: 0.0282\n",
      "Epoch 20/100\n",
      "165074/165074 [==============================] - 21s 126us/step - loss: 0.0291 - val_loss: 0.0280\n",
      "Epoch 21/100\n",
      "165074/165074 [==============================] - 20s 124us/step - loss: 0.0288 - val_loss: 0.0274\n",
      "Epoch 22/100\n",
      "165074/165074 [==============================] - 20s 123us/step - loss: 0.0286 - val_loss: 0.0279\n",
      "Epoch 23/100\n",
      "165074/165074 [==============================] - 20s 124us/step - loss: 0.0285 - val_loss: 0.0276\n",
      "Epoch 24/100\n",
      "165074/165074 [==============================] - 20s 120us/step - loss: 0.0283 - val_loss: 0.0280\n",
      "Epoch 25/100\n",
      "165074/165074 [==============================] - 19s 118us/step - loss: 0.0280 - val_loss: 0.0271\n",
      "Epoch 26/100\n",
      "165074/165074 [==============================] - 20s 122us/step - loss: 0.0279 - val_loss: 0.0276\n",
      "Epoch 27/100\n",
      "165074/165074 [==============================] - 20s 121us/step - loss: 0.0278 - val_loss: 0.0273\n",
      "Epoch 28/100\n",
      "165074/165074 [==============================] - 19s 116us/step - loss: 0.0277 - val_loss: 0.0269\n",
      "Epoch 29/100\n",
      "165074/165074 [==============================] - 19s 117us/step - loss: 0.0275 - val_loss: 0.0274\n",
      "Epoch 30/100\n",
      "165074/165074 [==============================] - 19s 116us/step - loss: 0.0274 - val_loss: 0.0266\n",
      "Epoch 31/100\n",
      "165074/165074 [==============================] - 19s 116us/step - loss: 0.0271 - val_loss: 0.0268\n",
      "Epoch 32/100\n",
      "165074/165074 [==============================] - 19s 117us/step - loss: 0.0273 - val_loss: 0.0264\n",
      "Epoch 33/100\n",
      "165074/165074 [==============================] - 19s 115us/step - loss: 0.0270 - val_loss: 0.0262\n",
      "Epoch 34/100\n",
      "165074/165074 [==============================] - 19s 116us/step - loss: 0.0269 - val_loss: 0.0267\n",
      "Epoch 35/100\n",
      "165074/165074 [==============================] - 19s 116us/step - loss: 0.0270 - val_loss: 0.0259\n",
      "Epoch 36/100\n",
      "165074/165074 [==============================] - 19s 116us/step - loss: 0.0266 - val_loss: 0.0262\n",
      "Epoch 37/100\n",
      "165074/165074 [==============================] - 19s 117us/step - loss: 0.0266 - val_loss: 0.0263\n",
      "Epoch 38/100\n",
      "165074/165074 [==============================] - 19s 116us/step - loss: 0.0265 - val_loss: 0.0259\n",
      "Epoch 39/100\n",
      "165074/165074 [==============================] - 19s 118us/step - loss: 0.0265 - val_loss: 0.0258\n",
      "Epoch 40/100\n",
      "165074/165074 [==============================] - 21s 124us/step - loss: 0.0264 - val_loss: 0.0260\n",
      "Epoch 41/100\n",
      "165074/165074 [==============================] - 18s 112us/step - loss: 0.0262 - val_loss: 0.0258\n",
      "Epoch 42/100\n",
      "165074/165074 [==============================] - 19s 115us/step - loss: 0.0262 - val_loss: 0.0259\n",
      "Epoch 43/100\n",
      "165074/165074 [==============================] - 19s 116us/step - loss: 0.0260 - val_loss: 0.0260\n",
      "perc99.75SubjectF2andFold3\n",
      "224443\n",
      "72698\n",
      "Train on 138956 samples, validate on 44682 samples\n",
      "Epoch 1/100\n",
      "138956/138956 [==============================] - 22s 157us/step - loss: 0.0536 - val_loss: 0.0380\n",
      "Epoch 2/100\n",
      "138956/138956 [==============================] - 19s 134us/step - loss: 0.0432 - val_loss: 0.0371\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138956/138956 [==============================] - 17s 124us/step - loss: 0.0416 - val_loss: 0.0368\n",
      "Epoch 4/100\n",
      "138956/138956 [==============================] - 19s 133us/step - loss: 0.0406 - val_loss: 0.0361\n",
      "Epoch 5/100\n",
      "138956/138956 [==============================] - 19s 137us/step - loss: 0.0398 - val_loss: 0.0350\n",
      "Epoch 6/100\n",
      "138956/138956 [==============================] - 19s 133us/step - loss: 0.0391 - val_loss: 0.0342\n",
      "Epoch 7/100\n",
      "138956/138956 [==============================] - 18s 130us/step - loss: 0.0387 - val_loss: 0.0336\n",
      "Epoch 8/100\n",
      "138956/138956 [==============================] - 18s 133us/step - loss: 0.0380 - val_loss: 0.0357\n",
      "Epoch 9/100\n",
      "138956/138956 [==============================] - 18s 129us/step - loss: 0.0376 - val_loss: 0.0332\n",
      "Epoch 10/100\n",
      "138956/138956 [==============================] - 18s 131us/step - loss: 0.0371 - val_loss: 0.0324\n",
      "Epoch 11/100\n",
      "138956/138956 [==============================] - 18s 128us/step - loss: 0.0367 - val_loss: 0.0331\n",
      "Epoch 12/100\n",
      "138956/138956 [==============================] - 19s 137us/step - loss: 0.0363 - val_loss: 0.0317\n",
      "Epoch 13/100\n",
      "138956/138956 [==============================] - 17s 124us/step - loss: 0.0360 - val_loss: 0.0328\n",
      "Epoch 14/100\n",
      "138956/138956 [==============================] - 17s 125us/step - loss: 0.0357 - val_loss: 0.0321\n",
      "Epoch 15/100\n",
      "138956/138956 [==============================] - 18s 127us/step - loss: 0.0353 - val_loss: 0.0313\n",
      "Epoch 16/100\n",
      "138956/138956 [==============================] - 17s 124us/step - loss: 0.0351 - val_loss: 0.0316\n",
      "Epoch 17/100\n",
      "138956/138956 [==============================] - 17s 124us/step - loss: 0.0347 - val_loss: 0.0314\n",
      "Epoch 18/100\n",
      "138956/138956 [==============================] - 17s 121us/step - loss: 0.0346 - val_loss: 0.0318\n",
      "Epoch 19/100\n",
      "138956/138956 [==============================] - 18s 127us/step - loss: 0.0342 - val_loss: 0.0305\n",
      "Epoch 20/100\n",
      "138956/138956 [==============================] - 18s 129us/step - loss: 0.0340 - val_loss: 0.0312\n",
      "Epoch 21/100\n",
      "138956/138956 [==============================] - 17s 125us/step - loss: 0.0337 - val_loss: 0.0305\n",
      "Epoch 22/100\n",
      "138956/138956 [==============================] - 17s 120us/step - loss: 0.0335 - val_loss: 0.0316\n",
      "Epoch 23/100\n",
      "138956/138956 [==============================] - 17s 124us/step - loss: 0.0334 - val_loss: 0.0306\n",
      "perc99.75SubjectF2andFold4\n",
      "209245\n",
      "71616\n",
      "Train on 123905 samples, validate on 41660 samples\n",
      "Epoch 1/100\n",
      "123905/123905 [==============================] - 22s 177us/step - loss: 0.0500 - val_loss: 0.0400\n",
      "Epoch 2/100\n",
      "123905/123905 [==============================] - 16s 128us/step - loss: 0.0377 - val_loss: 0.0388\n",
      "Epoch 3/100\n",
      "123905/123905 [==============================] - 15s 125us/step - loss: 0.0359 - val_loss: 0.0361\n",
      "Epoch 4/100\n",
      "123905/123905 [==============================] - 15s 124us/step - loss: 0.0347 - val_loss: 0.0370\n",
      "Epoch 5/100\n",
      "123905/123905 [==============================] - 16s 129us/step - loss: 0.0340 - val_loss: 0.0370\n",
      "Epoch 6/100\n",
      "123905/123905 [==============================] - 16s 128us/step - loss: 0.0333 - val_loss: 0.0340\n",
      "Epoch 7/100\n",
      "123905/123905 [==============================] - 16s 128us/step - loss: 0.0327 - val_loss: 0.0350\n",
      "Epoch 8/100\n",
      "123905/123905 [==============================] - 16s 126us/step - loss: 0.0322 - val_loss: 0.0339\n",
      "Epoch 9/100\n",
      "123905/123905 [==============================] - 15s 124us/step - loss: 0.0315 - val_loss: 0.0327\n",
      "Epoch 10/100\n",
      "123905/123905 [==============================] - 16s 127us/step - loss: 0.0311 - val_loss: 0.0326\n",
      "Epoch 11/100\n",
      "123905/123905 [==============================] - 16s 126us/step - loss: 0.0305 - val_loss: 0.0328\n",
      "Epoch 12/100\n",
      "123905/123905 [==============================] - 16s 126us/step - loss: 0.0301 - val_loss: 0.0318\n",
      "Epoch 13/100\n",
      "123905/123905 [==============================] - 16s 128us/step - loss: 0.0297 - val_loss: 0.0318\n",
      "Epoch 14/100\n",
      "123905/123905 [==============================] - 16s 129us/step - loss: 0.0293 - val_loss: 0.0312\n",
      "Epoch 15/100\n",
      "123905/123905 [==============================] - 17s 134us/step - loss: 0.0290 - val_loss: 0.0309\n",
      "Epoch 16/100\n",
      "123905/123905 [==============================] - 17s 133us/step - loss: 0.0287 - val_loss: 0.0314\n",
      "Epoch 17/100\n",
      "123905/123905 [==============================] - 15s 122us/step - loss: 0.0284 - val_loss: 0.0306\n",
      "Epoch 18/100\n",
      "123905/123905 [==============================] - 15s 125us/step - loss: 0.0280 - val_loss: 0.0311\n",
      "Epoch 19/100\n",
      "123905/123905 [==============================] - 16s 128us/step - loss: 0.0279 - val_loss: 0.0314\n",
      "Epoch 20/100\n",
      "123905/123905 [==============================] - 17s 136us/step - loss: 0.0277 - val_loss: 0.0305\n",
      "Epoch 21/100\n",
      "123905/123905 [==============================] - 14s 117us/step - loss: 0.0274 - val_loss: 0.0295\n",
      "Epoch 22/100\n",
      "123905/123905 [==============================] - 14s 112us/step - loss: 0.0272 - val_loss: 0.0295\n",
      "Epoch 23/100\n",
      "123905/123905 [==============================] - 15s 119us/step - loss: 0.0271 - val_loss: 0.0298\n",
      "Epoch 24/100\n",
      "123905/123905 [==============================] - 15s 119us/step - loss: 0.0270 - val_loss: 0.0295\n",
      "Epoch 25/100\n",
      "123905/123905 [==============================] - 15s 118us/step - loss: 0.0267 - val_loss: 0.0292\n",
      "Epoch 26/100\n",
      "123905/123905 [==============================] - 14s 116us/step - loss: 0.0267 - val_loss: 0.0293\n",
      "Epoch 27/100\n",
      "123905/123905 [==============================] - 15s 118us/step - loss: 0.0263 - val_loss: 0.0292\n",
      "Epoch 28/100\n",
      "123905/123905 [==============================] - 15s 118us/step - loss: 0.0263 - val_loss: 0.0293\n",
      "Epoch 29/100\n",
      "123905/123905 [==============================] - 15s 117us/step - loss: 0.0262 - val_loss: 0.0288\n",
      "Epoch 30/100\n",
      "123905/123905 [==============================] - 15s 118us/step - loss: 0.0260 - val_loss: 0.0289\n",
      "Epoch 31/100\n",
      "123905/123905 [==============================] - 14s 116us/step - loss: 0.0258 - val_loss: 0.0293\n",
      "Epoch 32/100\n",
      "123905/123905 [==============================] - 15s 119us/step - loss: 0.0257 - val_loss: 0.0290\n",
      "Epoch 33/100\n",
      "123905/123905 [==============================] - 15s 119us/step - loss: 0.0257 - val_loss: 0.0286\n",
      "Epoch 34/100\n",
      "123905/123905 [==============================] - 15s 123us/step - loss: 0.0256 - val_loss: 0.0284\n",
      "Epoch 35/100\n",
      "123905/123905 [==============================] - 16s 132us/step - loss: 0.0254 - val_loss: 0.0279\n",
      "Epoch 36/100\n",
      "123905/123905 [==============================] - 16s 127us/step - loss: 0.0253 - val_loss: 0.0286\n",
      "Epoch 37/100\n",
      "123905/123905 [==============================] - 15s 122us/step - loss: 0.0251 - val_loss: 0.0286\n",
      "Epoch 38/100\n",
      "123905/123905 [==============================] - 15s 118us/step - loss: 0.0251 - val_loss: 0.0278\n",
      "Epoch 39/100\n",
      "123905/123905 [==============================] - 15s 119us/step - loss: 0.0250 - val_loss: 0.0281\n",
      "Epoch 40/100\n",
      "123905/123905 [==============================] - 15s 123us/step - loss: 0.0249 - val_loss: 0.0283\n",
      "Epoch 41/100\n",
      "123905/123905 [==============================] - 15s 119us/step - loss: 0.0249 - val_loss: 0.0273\n",
      "Epoch 42/100\n",
      "123905/123905 [==============================] - 14s 110us/step - loss: 0.0247 - val_loss: 0.0277\n",
      "Epoch 43/100\n",
      "123905/123905 [==============================] - 14s 110us/step - loss: 0.0246 - val_loss: 0.0284\n",
      "Epoch 44/100\n",
      "123905/123905 [==============================] - 14s 113us/step - loss: 0.0246 - val_loss: 0.0271\n",
      "Epoch 45/100\n",
      "123905/123905 [==============================] - 14s 116us/step - loss: 0.0244 - val_loss: 0.0274\n",
      "Epoch 46/100\n",
      "123905/123905 [==============================] - 14s 114us/step - loss: 0.0244 - val_loss: 0.0273\n",
      "Epoch 47/100\n",
      "123905/123905 [==============================] - 14s 111us/step - loss: 0.0243 - val_loss: 0.0272\n",
      "Epoch 48/100\n",
      "123905/123905 [==============================] - 14s 114us/step - loss: 0.0243 - val_loss: 0.0277\n",
      "perc99.75SubjectM1andFold1\n",
      "310556\n",
      "103925\n",
      "Train on 261956 samples, validate on 88282 samples\n",
      "Epoch 1/100\n",
      "261956/261956 [==============================] - 35s 135us/step - loss: 0.0496 - val_loss: 0.0417\n",
      "Epoch 2/100\n",
      "261956/261956 [==============================] - 28s 108us/step - loss: 0.0411 - val_loss: 0.0387\n",
      "Epoch 3/100\n",
      "261956/261956 [==============================] - 27s 102us/step - loss: 0.0391 - val_loss: 0.0377\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261956/261956 [==============================] - 27s 101us/step - loss: 0.0377 - val_loss: 0.0360\n",
      "Epoch 5/100\n",
      "261956/261956 [==============================] - 26s 100us/step - loss: 0.0368 - val_loss: 0.0354\n",
      "Epoch 6/100\n",
      "261956/261956 [==============================] - 27s 101us/step - loss: 0.0357 - val_loss: 0.0341\n",
      "Epoch 7/100\n",
      "261956/261956 [==============================] - 27s 102us/step - loss: 0.0351 - val_loss: 0.0329\n",
      "Epoch 8/100\n",
      "261956/261956 [==============================] - 29s 110us/step - loss: 0.0343 - val_loss: 0.0325\n",
      "Epoch 9/100\n",
      "261956/261956 [==============================] - 30s 114us/step - loss: 0.0337 - val_loss: 0.0323\n",
      "Epoch 10/100\n",
      "261956/261956 [==============================] - 27s 101us/step - loss: 0.0331 - val_loss: 0.0322\n",
      "Epoch 11/100\n",
      "261956/261956 [==============================] - 27s 103us/step - loss: 0.0327 - val_loss: 0.0315\n",
      "Epoch 12/100\n",
      "261956/261956 [==============================] - 28s 108us/step - loss: 0.0323 - val_loss: 0.0308\n",
      "Epoch 13/100\n",
      "261956/261956 [==============================] - 28s 106us/step - loss: 0.0318 - val_loss: 0.0303\n",
      "Epoch 14/100\n",
      "261956/261956 [==============================] - 27s 103us/step - loss: 0.0314 - val_loss: 0.0301\n",
      "Epoch 15/100\n",
      "261956/261956 [==============================] - 28s 107us/step - loss: 0.0312 - val_loss: 0.0297\n",
      "Epoch 16/100\n",
      "261956/261956 [==============================] - 28s 107us/step - loss: 0.0308 - val_loss: 0.0298\n",
      "Epoch 17/100\n",
      "261956/261956 [==============================] - 30s 115us/step - loss: 0.0305 - val_loss: 0.0290\n",
      "Epoch 18/100\n",
      "261956/261956 [==============================] - 28s 107us/step - loss: 0.0302 - val_loss: 0.0295\n",
      "Epoch 19/100\n",
      "261956/261956 [==============================] - 26s 101us/step - loss: 0.0300 - val_loss: 0.0289\n",
      "Epoch 20/100\n",
      "261956/261956 [==============================] - 29s 110us/step - loss: 0.0298 - val_loss: 0.0285\n",
      "Epoch 21/100\n",
      "261956/261956 [==============================] - 28s 108us/step - loss: 0.0296 - val_loss: 0.0291\n",
      "Epoch 22/100\n",
      "261956/261956 [==============================] - 32s 121us/step - loss: 0.0293 - val_loss: 0.0284\n",
      "Epoch 23/100\n",
      "261956/261956 [==============================] - 33s 125us/step - loss: 0.0292 - val_loss: 0.0285\n",
      "Epoch 24/100\n",
      "261956/261956 [==============================] - 32s 124us/step - loss: 0.0290 - val_loss: 0.0283\n",
      "Epoch 25/100\n",
      "261956/261956 [==============================] - 31s 119us/step - loss: 0.0289 - val_loss: 0.0273\n",
      "Epoch 26/100\n",
      "261956/261956 [==============================] - 33s 125us/step - loss: 0.0287 - val_loss: 0.0276\n",
      "Epoch 27/100\n",
      "261956/261956 [==============================] - 34s 131us/step - loss: 0.0285 - val_loss: 0.0278\n",
      "Epoch 28/100\n",
      "261956/261956 [==============================] - 31s 119us/step - loss: 0.0284 - val_loss: 0.0274\n",
      "Epoch 29/100\n",
      "261956/261956 [==============================] - 32s 121us/step - loss: 0.0282 - val_loss: 0.0278\n",
      "perc99.75SubjectM1andFold2\n",
      "318987\n",
      "105903\n",
      "Train on 136774 samples, validate on 43998 samples\n",
      "Epoch 1/100\n",
      "136774/136774 [==============================] - 21s 154us/step - loss: 0.0516 - val_loss: 0.0386\n",
      "Epoch 2/100\n",
      "136774/136774 [==============================] - 15s 111us/step - loss: 0.0379 - val_loss: 0.0347\n",
      "Epoch 3/100\n",
      "136774/136774 [==============================] - 16s 117us/step - loss: 0.0350 - val_loss: 0.0335\n",
      "Epoch 4/100\n",
      "136774/136774 [==============================] - 17s 122us/step - loss: 0.0331 - val_loss: 0.0319\n",
      "Epoch 5/100\n",
      "136774/136774 [==============================] - 16s 117us/step - loss: 0.0315 - val_loss: 0.0293\n",
      "Epoch 6/100\n",
      "136774/136774 [==============================] - 16s 113us/step - loss: 0.0303 - val_loss: 0.0279\n",
      "Epoch 7/100\n",
      "136774/136774 [==============================] - 16s 116us/step - loss: 0.0294 - val_loss: 0.0283\n",
      "Epoch 8/100\n",
      "136774/136774 [==============================] - 16s 118us/step - loss: 0.0283 - val_loss: 0.0265\n",
      "Epoch 9/100\n",
      "136774/136774 [==============================] - 16s 117us/step - loss: 0.0276 - val_loss: 0.0269\n",
      "Epoch 10/100\n",
      "136774/136774 [==============================] - 15s 112us/step - loss: 0.0270 - val_loss: 0.0258\n",
      "Epoch 11/100\n",
      "136774/136774 [==============================] - 15s 112us/step - loss: 0.0263 - val_loss: 0.0249\n",
      "Epoch 12/100\n",
      "136774/136774 [==============================] - 16s 117us/step - loss: 0.0258 - val_loss: 0.0241\n",
      "Epoch 13/100\n",
      "136774/136774 [==============================] - 16s 116us/step - loss: 0.0254 - val_loss: 0.0262\n",
      "Epoch 14/100\n",
      "136774/136774 [==============================] - 15s 112us/step - loss: 0.0251 - val_loss: 0.0235\n",
      "Epoch 15/100\n",
      "136774/136774 [==============================] - 16s 115us/step - loss: 0.0246 - val_loss: 0.0243\n",
      "Epoch 16/100\n",
      "136774/136774 [==============================] - 17s 125us/step - loss: 0.0243 - val_loss: 0.0234\n",
      "Epoch 17/100\n",
      "136774/136774 [==============================] - 16s 119us/step - loss: 0.0240 - val_loss: 0.0233\n",
      "Epoch 18/100\n",
      "136774/136774 [==============================] - 15s 113us/step - loss: 0.0236 - val_loss: 0.0227\n",
      "Epoch 19/100\n",
      "136774/136774 [==============================] - 15s 111us/step - loss: 0.0234 - val_loss: 0.0236\n",
      "Epoch 20/100\n",
      "136774/136774 [==============================] - 16s 114us/step - loss: 0.0230 - val_loss: 0.0226\n",
      "Epoch 21/100\n",
      "136774/136774 [==============================] - 15s 111us/step - loss: 0.0229 - val_loss: 0.0222\n",
      "Epoch 22/100\n",
      "136774/136774 [==============================] - 16s 115us/step - loss: 0.0227 - val_loss: 0.0221\n",
      "Epoch 23/100\n",
      "136774/136774 [==============================] - 16s 117us/step - loss: 0.0225 - val_loss: 0.0228\n",
      "Epoch 24/100\n",
      "136774/136774 [==============================] - 15s 109us/step - loss: 0.0221 - val_loss: 0.0213\n",
      "Epoch 25/100\n",
      "136774/136774 [==============================] - 16s 114us/step - loss: 0.0218 - val_loss: 0.0208\n",
      "Epoch 26/100\n",
      "136774/136774 [==============================] - 15s 112us/step - loss: 0.0218 - val_loss: 0.0216\n",
      "Epoch 27/100\n",
      "136774/136774 [==============================] - 16s 114us/step - loss: 0.0217 - val_loss: 0.0210\n",
      "Epoch 28/100\n",
      "136774/136774 [==============================] - 16s 117us/step - loss: 0.0216 - val_loss: 0.0210\n",
      "Epoch 29/100\n",
      "136774/136774 [==============================] - 16s 118us/step - loss: 0.0214 - val_loss: 0.0207\n",
      "Epoch 30/100\n",
      "136774/136774 [==============================] - 15s 113us/step - loss: 0.0212 - val_loss: 0.0205\n",
      "Epoch 31/100\n",
      "136774/136774 [==============================] - 15s 111us/step - loss: 0.0211 - val_loss: 0.0207\n",
      "Epoch 32/100\n",
      "136774/136774 [==============================] - 16s 115us/step - loss: 0.0210 - val_loss: 0.0208\n",
      "Epoch 33/100\n",
      "136774/136774 [==============================] - 15s 110us/step - loss: 0.0209 - val_loss: 0.0204\n",
      "Epoch 34/100\n",
      "136774/136774 [==============================] - 16s 119us/step - loss: 0.0208 - val_loss: 0.0204\n",
      "Epoch 35/100\n",
      "136774/136774 [==============================] - 15s 110us/step - loss: 0.0206 - val_loss: 0.0208\n",
      "Epoch 36/100\n",
      "136774/136774 [==============================] - 15s 109us/step - loss: 0.0205 - val_loss: 0.0204\n",
      "Epoch 37/100\n",
      "136774/136774 [==============================] - 15s 113us/step - loss: 0.0204 - val_loss: 0.0199\n",
      "Epoch 38/100\n",
      "136774/136774 [==============================] - 15s 112us/step - loss: 0.0205 - val_loss: 0.0202\n",
      "Epoch 39/100\n",
      "136774/136774 [==============================] - 15s 110us/step - loss: 0.0204 - val_loss: 0.0193\n",
      "Epoch 40/100\n",
      "136774/136774 [==============================] - 15s 111us/step - loss: 0.0201 - val_loss: 0.0198\n",
      "Epoch 41/100\n",
      "136774/136774 [==============================] - 15s 113us/step - loss: 0.0200 - val_loss: 0.0199\n",
      "Epoch 42/100\n",
      "136774/136774 [==============================] - 15s 112us/step - loss: 0.0199 - val_loss: 0.0201\n",
      "Epoch 43/100\n",
      "136774/136774 [==============================] - 15s 110us/step - loss: 0.0198 - val_loss: 0.0194\n",
      "perc99.75SubjectM1andFold3\n",
      "271077\n",
      "89103\n",
      "Train on 168059 samples, validate on 52330 samples\n",
      "Epoch 1/100\n",
      "168059/168059 [==============================] - 27s 158us/step - loss: 0.0500 - val_loss: 0.0331\n",
      "Epoch 2/100\n",
      "168059/168059 [==============================] - 19s 111us/step - loss: 0.0380 - val_loss: 0.0289\n",
      "Epoch 3/100\n",
      "168059/168059 [==============================] - 20s 117us/step - loss: 0.0354 - val_loss: 0.0283\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168059/168059 [==============================] - 21s 123us/step - loss: 0.0336 - val_loss: 0.0275\n",
      "Epoch 5/100\n",
      "168059/168059 [==============================] - 18s 110us/step - loss: 0.0324 - val_loss: 0.0258\n",
      "Epoch 6/100\n",
      "168059/168059 [==============================] - 19s 116us/step - loss: 0.0314 - val_loss: 0.0249\n",
      "Epoch 7/100\n",
      "168059/168059 [==============================] - 19s 115us/step - loss: 0.0306 - val_loss: 0.0243\n",
      "Epoch 8/100\n",
      "168059/168059 [==============================] - 19s 114us/step - loss: 0.0298 - val_loss: 0.0237\n",
      "Epoch 9/100\n",
      "168059/168059 [==============================] - 19s 114us/step - loss: 0.0293 - val_loss: 0.0250\n",
      "Epoch 10/100\n",
      "168059/168059 [==============================] - 19s 114us/step - loss: 0.0288 - val_loss: 0.0238\n",
      "Epoch 11/100\n",
      "168059/168059 [==============================] - 19s 112us/step - loss: 0.0285 - val_loss: 0.0238\n",
      "Epoch 12/100\n",
      "168059/168059 [==============================] - 21s 123us/step - loss: 0.0280 - val_loss: 0.0235\n",
      "Epoch 13/100\n",
      "168059/168059 [==============================] - 19s 112us/step - loss: 0.0277 - val_loss: 0.0225\n",
      "Epoch 14/100\n",
      "168059/168059 [==============================] - 21s 125us/step - loss: 0.0275 - val_loss: 0.0227\n",
      "Epoch 15/100\n",
      "168059/168059 [==============================] - 19s 115us/step - loss: 0.0271 - val_loss: 0.0223\n",
      "Epoch 16/100\n",
      "168059/168059 [==============================] - 18s 105us/step - loss: 0.0269 - val_loss: 0.0221\n",
      "Epoch 17/100\n",
      "168059/168059 [==============================] - 19s 110us/step - loss: 0.0267 - val_loss: 0.0220\n",
      "Epoch 18/100\n",
      "168059/168059 [==============================] - 19s 114us/step - loss: 0.0265 - val_loss: 0.0217\n",
      "Epoch 19/100\n",
      "168059/168059 [==============================] - 19s 111us/step - loss: 0.0265 - val_loss: 0.0218\n",
      "Epoch 20/100\n",
      "168059/168059 [==============================] - 19s 115us/step - loss: 0.0261 - val_loss: 0.0217\n",
      "Epoch 21/100\n",
      "168059/168059 [==============================] - 18s 109us/step - loss: 0.0260 - val_loss: 0.0221\n",
      "Epoch 22/100\n",
      "168059/168059 [==============================] - 18s 106us/step - loss: 0.0259 - val_loss: 0.0215\n",
      "Epoch 23/100\n",
      "168059/168059 [==============================] - 18s 104us/step - loss: 0.0257 - val_loss: 0.0214\n",
      "Epoch 24/100\n",
      "168059/168059 [==============================] - 17s 99us/step - loss: 0.0256 - val_loss: 0.0221\n",
      "Epoch 25/100\n",
      "168059/168059 [==============================] - 16s 97us/step - loss: 0.0254 - val_loss: 0.0217\n",
      "Epoch 26/100\n",
      "168059/168059 [==============================] - 17s 99us/step - loss: 0.0253 - val_loss: 0.0212\n",
      "Epoch 27/100\n",
      "168059/168059 [==============================] - 20s 118us/step - loss: 0.0251 - val_loss: 0.0213\n",
      "Epoch 28/100\n",
      "168059/168059 [==============================] - 20s 118us/step - loss: 0.0250 - val_loss: 0.0214\n",
      "Epoch 29/100\n",
      "168059/168059 [==============================] - 19s 114us/step - loss: 0.0249 - val_loss: 0.0212\n",
      "Epoch 30/100\n",
      "168059/168059 [==============================] - 19s 111us/step - loss: 0.0247 - val_loss: 0.0215\n",
      "perc99.75SubjectM1andFold4\n",
      "281792\n",
      "93493\n",
      "Train on 157976 samples, validate on 51272 samples\n",
      "Epoch 1/100\n",
      "157976/157976 [==============================] - 24s 149us/step - loss: 0.0470 - val_loss: 0.0322\n",
      "Epoch 2/100\n",
      "157976/157976 [==============================] - 18s 112us/step - loss: 0.0335 - val_loss: 0.0290\n",
      "Epoch 3/100\n",
      "157976/157976 [==============================] - 18s 113us/step - loss: 0.0310 - val_loss: 0.0267\n",
      "Epoch 4/100\n",
      "157976/157976 [==============================] - 18s 114us/step - loss: 0.0295 - val_loss: 0.0271\n",
      "Epoch 5/100\n",
      "157976/157976 [==============================] - 18s 113us/step - loss: 0.0284 - val_loss: 0.0258\n",
      "Epoch 6/100\n",
      "157976/157976 [==============================] - 18s 114us/step - loss: 0.0277 - val_loss: 0.0246\n",
      "Epoch 7/100\n",
      "157976/157976 [==============================] - 19s 119us/step - loss: 0.0270 - val_loss: 0.0252\n",
      "Epoch 8/100\n",
      "157976/157976 [==============================] - 18s 115us/step - loss: 0.0265 - val_loss: 0.0248\n",
      "Epoch 9/100\n",
      "157976/157976 [==============================] - 18s 114us/step - loss: 0.0260 - val_loss: 0.0239\n",
      "Epoch 10/100\n",
      "157976/157976 [==============================] - 18s 114us/step - loss: 0.0255 - val_loss: 0.0235\n",
      "Epoch 11/100\n",
      "157976/157976 [==============================] - 18s 113us/step - loss: 0.0251 - val_loss: 0.0236\n",
      "Epoch 12/100\n",
      "157976/157976 [==============================] - 18s 117us/step - loss: 0.0248 - val_loss: 0.0233\n",
      "Epoch 13/100\n",
      "157976/157976 [==============================] - 19s 117us/step - loss: 0.0245 - val_loss: 0.0229\n",
      "Epoch 14/100\n",
      "157976/157976 [==============================] - 18s 112us/step - loss: 0.0243 - val_loss: 0.0235\n",
      "Epoch 15/100\n",
      "157976/157976 [==============================] - 18s 113us/step - loss: 0.0239 - val_loss: 0.0222\n",
      "Epoch 16/100\n",
      "157976/157976 [==============================] - 18s 112us/step - loss: 0.0236 - val_loss: 0.0219\n",
      "Epoch 17/100\n",
      "157976/157976 [==============================] - 18s 113us/step - loss: 0.0235 - val_loss: 0.0220\n",
      "Epoch 18/100\n",
      "157976/157976 [==============================] - 18s 114us/step - loss: 0.0232 - val_loss: 0.0221\n",
      "Epoch 19/100\n",
      "157976/157976 [==============================] - 18s 114us/step - loss: 0.0230 - val_loss: 0.0218\n",
      "Epoch 20/100\n",
      "157976/157976 [==============================] - 18s 113us/step - loss: 0.0229 - val_loss: 0.0223\n",
      "Epoch 21/100\n",
      "157976/157976 [==============================] - 19s 121us/step - loss: 0.0227 - val_loss: 0.0214\n",
      "Epoch 22/100\n",
      "157976/157976 [==============================] - 19s 121us/step - loss: 0.0224 - val_loss: 0.0216\n",
      "Epoch 23/100\n",
      "157976/157976 [==============================] - 19s 123us/step - loss: 0.0223 - val_loss: 0.0211\n",
      "Epoch 24/100\n",
      "157976/157976 [==============================] - 17s 111us/step - loss: 0.0222 - val_loss: 0.0207\n",
      "Epoch 25/100\n",
      "157976/157976 [==============================] - 18s 115us/step - loss: 0.0220 - val_loss: 0.0213\n",
      "Epoch 26/100\n",
      "157976/157976 [==============================] - 18s 112us/step - loss: 0.0219 - val_loss: 0.0206\n",
      "Epoch 27/100\n",
      "157976/157976 [==============================] - 18s 113us/step - loss: 0.0217 - val_loss: 0.0208\n",
      "Epoch 28/100\n",
      "157976/157976 [==============================] - 18s 115us/step - loss: 0.0217 - val_loss: 0.0211\n",
      "Epoch 29/100\n",
      "157976/157976 [==============================] - 17s 111us/step - loss: 0.0216 - val_loss: 0.0204\n",
      "Epoch 30/100\n",
      "157976/157976 [==============================] - 18s 113us/step - loss: 0.0215 - val_loss: 0.0208\n",
      "Epoch 31/100\n",
      "157976/157976 [==============================] - 18s 116us/step - loss: 0.0213 - val_loss: 0.0206\n",
      "Epoch 32/100\n",
      "157976/157976 [==============================] - 18s 116us/step - loss: 0.0213 - val_loss: 0.0202\n",
      "Epoch 33/100\n",
      "157976/157976 [==============================] - 18s 116us/step - loss: 0.0211 - val_loss: 0.0213\n",
      "Epoch 34/100\n",
      "157976/157976 [==============================] - 19s 119us/step - loss: 0.0211 - val_loss: 0.0200\n",
      "Epoch 35/100\n",
      "157976/157976 [==============================] - 19s 118us/step - loss: 0.0211 - val_loss: 0.0203\n",
      "Epoch 36/100\n",
      "157976/157976 [==============================] - 19s 117us/step - loss: 0.0209 - val_loss: 0.0203\n",
      "Epoch 37/100\n",
      "157976/157976 [==============================] - 19s 118us/step - loss: 0.0208 - val_loss: 0.0204\n",
      "Epoch 38/100\n",
      "157976/157976 [==============================] - 19s 120us/step - loss: 0.0208 - val_loss: 0.0202\n",
      "perc99.75SubjectM2andFold1\n",
      "262885\n",
      "82857\n",
      "Train on 236443 samples, validate on 75290 samples\n",
      "Epoch 1/100\n",
      "236443/236443 [==============================] - 34s 144us/step - loss: 0.0559 - val_loss: 0.0449\n",
      "Epoch 2/100\n",
      "236443/236443 [==============================] - 28s 120us/step - loss: 0.0460 - val_loss: 0.0415\n",
      "Epoch 3/100\n",
      "236443/236443 [==============================] - 25s 108us/step - loss: 0.0432 - val_loss: 0.0390\n",
      "Epoch 4/100\n",
      "236443/236443 [==============================] - 27s 114us/step - loss: 0.0412 - val_loss: 0.0378\n",
      "Epoch 5/100\n",
      "236443/236443 [==============================] - 25s 105us/step - loss: 0.0395 - val_loss: 0.0370\n",
      "Epoch 6/100\n",
      "236443/236443 [==============================] - 26s 112us/step - loss: 0.0383 - val_loss: 0.0360\n",
      "Epoch 7/100\n",
      "236443/236443 [==============================] - 29s 123us/step - loss: 0.0372 - val_loss: 0.0353\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236443/236443 [==============================] - 27s 115us/step - loss: 0.0366 - val_loss: 0.0349\n",
      "Epoch 9/100\n",
      "236443/236443 [==============================] - 28s 119us/step - loss: 0.0358 - val_loss: 0.0336\n",
      "Epoch 10/100\n",
      "236443/236443 [==============================] - 28s 118us/step - loss: 0.0351 - val_loss: 0.0336\n",
      "Epoch 11/100\n",
      "236443/236443 [==============================] - 28s 120us/step - loss: 0.0346 - val_loss: 0.0335\n",
      "Epoch 12/100\n",
      "236443/236443 [==============================] - 29s 122us/step - loss: 0.0341 - val_loss: 0.0323\n",
      "Epoch 13/100\n",
      "236443/236443 [==============================] - 28s 118us/step - loss: 0.0336 - val_loss: 0.0325\n",
      "Epoch 14/100\n",
      "236443/236443 [==============================] - 28s 120us/step - loss: 0.0332 - val_loss: 0.0315\n",
      "Epoch 15/100\n",
      "236443/236443 [==============================] - 27s 115us/step - loss: 0.0328 - val_loss: 0.0314\n",
      "Epoch 16/100\n",
      "236443/236443 [==============================] - 27s 116us/step - loss: 0.0325 - val_loss: 0.0316\n",
      "Epoch 17/100\n",
      "236443/236443 [==============================] - 28s 118us/step - loss: 0.0322 - val_loss: 0.0312\n",
      "Epoch 18/100\n",
      "236443/236443 [==============================] - 27s 114us/step - loss: 0.0319 - val_loss: 0.0309\n",
      "Epoch 19/100\n",
      "236443/236443 [==============================] - 27s 115us/step - loss: 0.0316 - val_loss: 0.0307\n",
      "Epoch 20/100\n",
      "236443/236443 [==============================] - 24s 103us/step - loss: 0.0314 - val_loss: 0.0304\n",
      "Epoch 21/100\n",
      "236443/236443 [==============================] - 24s 101us/step - loss: 0.0311 - val_loss: 0.0303\n",
      "Epoch 22/100\n",
      "236443/236443 [==============================] - 24s 103us/step - loss: 0.0309 - val_loss: 0.0306\n",
      "Epoch 23/100\n",
      "236443/236443 [==============================] - 24s 101us/step - loss: 0.0308 - val_loss: 0.0310\n",
      "Epoch 24/100\n",
      "236443/236443 [==============================] - 24s 100us/step - loss: 0.0305 - val_loss: 0.0295\n",
      "Epoch 25/100\n",
      "236443/236443 [==============================] - 24s 102us/step - loss: 0.0305 - val_loss: 0.0296\n",
      "Epoch 26/100\n",
      "236443/236443 [==============================] - 23s 97us/step - loss: 0.0302 - val_loss: 0.0301\n",
      "Epoch 27/100\n",
      "236443/236443 [==============================] - 24s 102us/step - loss: 0.0300 - val_loss: 0.0295\n",
      "Epoch 28/100\n",
      "236443/236443 [==============================] - 24s 100us/step - loss: 0.0298 - val_loss: 0.0293\n",
      "Epoch 29/100\n",
      "236443/236443 [==============================] - 24s 102us/step - loss: 0.0298 - val_loss: 0.0295\n",
      "Epoch 30/100\n",
      "236443/236443 [==============================] - 24s 100us/step - loss: 0.0296 - val_loss: 0.0291\n",
      "Epoch 31/100\n",
      "236443/236443 [==============================] - 24s 100us/step - loss: 0.0295 - val_loss: 0.0292\n",
      "Epoch 32/100\n",
      "236443/236443 [==============================] - 23s 99us/step - loss: 0.0293 - val_loss: 0.0290\n",
      "Epoch 33/100\n",
      "236443/236443 [==============================] - 25s 104us/step - loss: 0.0292 - val_loss: 0.0290\n",
      "Epoch 34/100\n",
      "236443/236443 [==============================] - 24s 100us/step - loss: 0.0291 - val_loss: 0.0291\n",
      "Epoch 35/100\n",
      "236443/236443 [==============================] - 24s 101us/step - loss: 0.0290 - val_loss: 0.0287\n",
      "Epoch 36/100\n",
      "236443/236443 [==============================] - 23s 98us/step - loss: 0.0290 - val_loss: 0.0293\n",
      "Epoch 37/100\n",
      "236443/236443 [==============================] - 24s 100us/step - loss: 0.0288 - val_loss: 0.0287\n",
      "Epoch 38/100\n",
      "236443/236443 [==============================] - 24s 100us/step - loss: 0.0287 - val_loss: 0.0284\n",
      "Epoch 39/100\n",
      "236443/236443 [==============================] - 24s 102us/step - loss: 0.0285 - val_loss: 0.0282\n",
      "Epoch 40/100\n",
      "236443/236443 [==============================] - 24s 103us/step - loss: 0.0284 - val_loss: 0.0283\n",
      "Epoch 41/100\n",
      "236443/236443 [==============================] - 23s 98us/step - loss: 0.0284 - val_loss: 0.0284\n",
      "Epoch 42/100\n",
      "236443/236443 [==============================] - 24s 99us/step - loss: 0.0284 - val_loss: 0.0286\n",
      "Epoch 43/100\n",
      "236443/236443 [==============================] - 23s 98us/step - loss: 0.0282 - val_loss: 0.0286\n",
      "perc99.75SubjectM2andFold2\n",
      "269231\n",
      "90564\n",
      "Train on 168312 samples, validate on 55104 samples\n",
      "Epoch 1/100\n",
      "168312/168312 [==============================] - 23s 139us/step - loss: 0.0499 - val_loss: 0.0398\n",
      "Epoch 2/100\n",
      "168312/168312 [==============================] - 18s 106us/step - loss: 0.0378 - val_loss: 0.0354\n",
      "Epoch 3/100\n",
      "168312/168312 [==============================] - 18s 106us/step - loss: 0.0347 - val_loss: 0.0338\n",
      "Epoch 4/100\n",
      "168312/168312 [==============================] - 18s 108us/step - loss: 0.0326 - val_loss: 0.0313\n",
      "Epoch 5/100\n",
      "168312/168312 [==============================] - 18s 106us/step - loss: 0.0312 - val_loss: 0.0304\n",
      "Epoch 6/100\n",
      "168312/168312 [==============================] - 18s 107us/step - loss: 0.0300 - val_loss: 0.0297\n",
      "Epoch 7/100\n",
      "168312/168312 [==============================] - 18s 104us/step - loss: 0.0290 - val_loss: 0.0292\n",
      "Epoch 8/100\n",
      "168312/168312 [==============================] - 18s 106us/step - loss: 0.0282 - val_loss: 0.0285\n",
      "Epoch 9/100\n",
      "168312/168312 [==============================] - 17s 99us/step - loss: 0.0276 - val_loss: 0.0290\n",
      "Epoch 10/100\n",
      "168312/168312 [==============================] - 17s 98us/step - loss: 0.0269 - val_loss: 0.0271\n",
      "Epoch 11/100\n",
      "168312/168312 [==============================] - 17s 102us/step - loss: 0.0264 - val_loss: 0.0270\n",
      "Epoch 12/100\n",
      "168312/168312 [==============================] - 17s 103us/step - loss: 0.0259 - val_loss: 0.0263\n",
      "Epoch 13/100\n",
      "168312/168312 [==============================] - 17s 103us/step - loss: 0.0255 - val_loss: 0.0268\n",
      "Epoch 14/100\n",
      "168312/168312 [==============================] - 17s 103us/step - loss: 0.0251 - val_loss: 0.0254\n",
      "Epoch 15/100\n",
      "168312/168312 [==============================] - 18s 106us/step - loss: 0.0249 - val_loss: 0.0256\n",
      "Epoch 16/100\n",
      "168312/168312 [==============================] - 18s 104us/step - loss: 0.0246 - val_loss: 0.0252\n",
      "Epoch 17/100\n",
      "168312/168312 [==============================] - 17s 100us/step - loss: 0.0241 - val_loss: 0.0246\n",
      "Epoch 18/100\n",
      "168312/168312 [==============================] - 16s 97us/step - loss: 0.0240 - val_loss: 0.0246\n",
      "Epoch 19/100\n",
      "168312/168312 [==============================] - 18s 104us/step - loss: 0.0237 - val_loss: 0.0241\n",
      "Epoch 20/100\n",
      "168312/168312 [==============================] - 15s 88us/step - loss: 0.0235 - val_loss: 0.0250\n",
      "Epoch 21/100\n",
      "168312/168312 [==============================] - 15s 86us/step - loss: 0.0233 - val_loss: 0.0238\n",
      "Epoch 22/100\n",
      "168312/168312 [==============================] - 15s 88us/step - loss: 0.0230 - val_loss: 0.0238\n",
      "Epoch 23/100\n",
      "168312/168312 [==============================] - 15s 87us/step - loss: 0.0230 - val_loss: 0.0237\n",
      "Epoch 24/100\n",
      "168312/168312 [==============================] - 13s 79us/step - loss: 0.0228 - val_loss: 0.0235\n",
      "Epoch 25/100\n",
      "168312/168312 [==============================] - 14s 86us/step - loss: 0.0226 - val_loss: 0.0235\n",
      "Epoch 26/100\n",
      "168312/168312 [==============================] - 14s 84us/step - loss: 0.0224 - val_loss: 0.0241\n",
      "Epoch 27/100\n",
      "168312/168312 [==============================] - 14s 86us/step - loss: 0.0222 - val_loss: 0.0234\n",
      "Epoch 28/100\n",
      "168312/168312 [==============================] - 15s 87us/step - loss: 0.0221 - val_loss: 0.0234\n",
      "Epoch 29/100\n",
      "168312/168312 [==============================] - 14s 85us/step - loss: 0.0219 - val_loss: 0.0225\n",
      "Epoch 30/100\n",
      "168312/168312 [==============================] - 14s 85us/step - loss: 0.0217 - val_loss: 0.0228\n",
      "Epoch 31/100\n",
      "168312/168312 [==============================] - 15s 88us/step - loss: 0.0217 - val_loss: 0.0227\n",
      "Epoch 32/100\n",
      "168312/168312 [==============================] - 15s 87us/step - loss: 0.0216 - val_loss: 0.0226\n",
      "Epoch 33/100\n",
      "168312/168312 [==============================] - 15s 88us/step - loss: 0.0215 - val_loss: 0.0226\n",
      "perc99.75SubjectM2andFold3\n",
      "243097\n",
      "80474\n",
      "Train on 160506 samples, validate on 53427 samples\n",
      "Epoch 1/100\n",
      "160506/160506 [==============================] - 19s 121us/step - loss: 0.0577 - val_loss: 0.0436\n",
      "Epoch 2/100\n",
      "160506/160506 [==============================] - 14s 88us/step - loss: 0.0468 - val_loss: 0.0415\n",
      "Epoch 3/100\n",
      "160506/160506 [==============================] - 14s 85us/step - loss: 0.0439 - val_loss: 0.0387\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160506/160506 [==============================] - 14s 86us/step - loss: 0.0415 - val_loss: 0.0377\n",
      "Epoch 5/100\n",
      "160506/160506 [==============================] - 14s 85us/step - loss: 0.0398 - val_loss: 0.0357\n",
      "Epoch 6/100\n",
      "160506/160506 [==============================] - 14s 86us/step - loss: 0.0387 - val_loss: 0.0346\n",
      "Epoch 7/100\n",
      "160506/160506 [==============================] - 13s 81us/step - loss: 0.0377 - val_loss: 0.0348\n",
      "Epoch 8/100\n",
      "160506/160506 [==============================] - 13s 83us/step - loss: 0.0368 - val_loss: 0.0344\n",
      "Epoch 9/100\n",
      "160506/160506 [==============================] - 17s 104us/step - loss: 0.0362 - val_loss: 0.0328\n",
      "Epoch 10/100\n",
      "160506/160506 [==============================] - 16s 100us/step - loss: 0.0355 - val_loss: 0.0329\n",
      "Epoch 11/100\n",
      "160506/160506 [==============================] - 16s 102us/step - loss: 0.0349 - val_loss: 0.0320\n",
      "Epoch 12/100\n",
      "160506/160506 [==============================] - 16s 102us/step - loss: 0.0344 - val_loss: 0.0312\n",
      "Epoch 13/100\n",
      "160506/160506 [==============================] - 17s 106us/step - loss: 0.0340 - val_loss: 0.0309\n",
      "Epoch 14/100\n",
      "160506/160506 [==============================] - 17s 104us/step - loss: 0.0336 - val_loss: 0.0320\n",
      "Epoch 15/100\n",
      "160506/160506 [==============================] - 17s 104us/step - loss: 0.0333 - val_loss: 0.0303\n",
      "Epoch 16/100\n",
      "160506/160506 [==============================] - 18s 112us/step - loss: 0.0329 - val_loss: 0.0304\n",
      "Epoch 17/100\n",
      "160506/160506 [==============================] - 17s 107us/step - loss: 0.0325 - val_loss: 0.0296\n",
      "Epoch 18/100\n",
      "160506/160506 [==============================] - 17s 106us/step - loss: 0.0323 - val_loss: 0.0295\n",
      "Epoch 19/100\n",
      "160506/160506 [==============================] - 17s 108us/step - loss: 0.0320 - val_loss: 0.0297\n",
      "Epoch 20/100\n",
      "160506/160506 [==============================] - 17s 105us/step - loss: 0.0318 - val_loss: 0.0286\n",
      "Epoch 21/100\n",
      "160506/160506 [==============================] - 17s 107us/step - loss: 0.0315 - val_loss: 0.0285\n",
      "Epoch 22/100\n",
      "160506/160506 [==============================] - 16s 100us/step - loss: 0.0313 - val_loss: 0.0285\n",
      "Epoch 23/100\n",
      "160506/160506 [==============================] - 16s 98us/step - loss: 0.0311 - val_loss: 0.0300\n",
      "Epoch 24/100\n",
      "160506/160506 [==============================] - 14s 89us/step - loss: 0.0308 - val_loss: 0.0286\n",
      "Epoch 25/100\n",
      "160506/160506 [==============================] - 14s 87us/step - loss: 0.0306 - val_loss: 0.0284\n",
      "Epoch 26/100\n",
      "160506/160506 [==============================] - 15s 91us/step - loss: 0.0305 - val_loss: 0.0280\n",
      "Epoch 27/100\n",
      "160506/160506 [==============================] - 14s 90us/step - loss: 0.0301 - val_loss: 0.0284\n",
      "Epoch 28/100\n",
      "160506/160506 [==============================] - 14s 87us/step - loss: 0.0302 - val_loss: 0.0281\n",
      "Epoch 29/100\n",
      "160506/160506 [==============================] - 14s 89us/step - loss: 0.0300 - val_loss: 0.0289\n",
      "Epoch 30/100\n",
      "160506/160506 [==============================] - 14s 89us/step - loss: 0.0297 - val_loss: 0.0277\n",
      "Epoch 31/100\n",
      "160506/160506 [==============================] - 16s 100us/step - loss: 0.0296 - val_loss: 0.0280\n",
      "Epoch 32/100\n",
      "160506/160506 [==============================] - 14s 90us/step - loss: 0.0296 - val_loss: 0.0270\n",
      "Epoch 33/100\n",
      "160506/160506 [==============================] - 14s 88us/step - loss: 0.0292 - val_loss: 0.0269\n",
      "Epoch 34/100\n",
      "160506/160506 [==============================] - 15s 91us/step - loss: 0.0291 - val_loss: 0.0271\n",
      "Epoch 35/100\n",
      "160506/160506 [==============================] - 14s 87us/step - loss: 0.0290 - val_loss: 0.0273\n",
      "Epoch 36/100\n",
      "160506/160506 [==============================] - 13s 82us/step - loss: 0.0289 - val_loss: 0.0274\n",
      "Epoch 37/100\n",
      "160506/160506 [==============================] - 14s 85us/step - loss: 0.0288 - val_loss: 0.0273\n",
      "perc99.75SubjectM2andFold4\n",
      "239479\n",
      "79158\n",
      "Train on 160480 samples, validate on 52096 samples\n",
      "Epoch 1/100\n",
      "160480/160480 [==============================] - 23s 146us/step - loss: 0.0564 - val_loss: 0.0389\n",
      "Epoch 2/100\n",
      "160480/160480 [==============================] - 16s 101us/step - loss: 0.0431 - val_loss: 0.0357\n",
      "Epoch 3/100\n",
      "160480/160480 [==============================] - 16s 102us/step - loss: 0.0395 - val_loss: 0.0345\n",
      "Epoch 4/100\n",
      "160480/160480 [==============================] - 16s 101us/step - loss: 0.0375 - val_loss: 0.0314\n",
      "Epoch 5/100\n",
      "160480/160480 [==============================] - 16s 102us/step - loss: 0.0358 - val_loss: 0.0303\n",
      "Epoch 6/100\n",
      "160480/160480 [==============================] - 17s 104us/step - loss: 0.0346 - val_loss: 0.0299\n",
      "Epoch 7/100\n",
      "160480/160480 [==============================] - 16s 102us/step - loss: 0.0336 - val_loss: 0.0299\n",
      "Epoch 8/100\n",
      "160480/160480 [==============================] - 16s 100us/step - loss: 0.0326 - val_loss: 0.0291\n",
      "Epoch 9/100\n",
      "160480/160480 [==============================] - 17s 103us/step - loss: 0.0319 - val_loss: 0.0295\n",
      "Epoch 10/100\n",
      "160480/160480 [==============================] - 17s 105us/step - loss: 0.0313 - val_loss: 0.0288\n",
      "Epoch 11/100\n",
      "160480/160480 [==============================] - 16s 101us/step - loss: 0.0306 - val_loss: 0.0277\n",
      "Epoch 12/100\n",
      "160480/160480 [==============================] - 16s 103us/step - loss: 0.0302 - val_loss: 0.0279\n",
      "Epoch 13/100\n",
      "160480/160480 [==============================] - 17s 106us/step - loss: 0.0296 - val_loss: 0.0273\n",
      "Epoch 14/100\n",
      "160480/160480 [==============================] - 16s 101us/step - loss: 0.0291 - val_loss: 0.0270\n",
      "Epoch 15/100\n",
      "160480/160480 [==============================] - 17s 104us/step - loss: 0.0287 - val_loss: 0.0265\n",
      "Epoch 16/100\n",
      "160480/160480 [==============================] - 15s 93us/step - loss: 0.0283 - val_loss: 0.0259\n",
      "Epoch 17/100\n",
      "160480/160480 [==============================] - 14s 90us/step - loss: 0.0279 - val_loss: 0.0265\n",
      "Epoch 18/100\n",
      "160480/160480 [==============================] - 16s 100us/step - loss: 0.0276 - val_loss: 0.0254\n",
      "Epoch 19/100\n",
      "160480/160480 [==============================] - 16s 103us/step - loss: 0.0273 - val_loss: 0.0258\n",
      "Epoch 20/100\n",
      "160480/160480 [==============================] - 17s 104us/step - loss: 0.0271 - val_loss: 0.0252\n",
      "Epoch 21/100\n",
      "160480/160480 [==============================] - 16s 102us/step - loss: 0.0268 - val_loss: 0.0254\n",
      "Epoch 22/100\n",
      "160480/160480 [==============================] - 17s 104us/step - loss: 0.0266 - val_loss: 0.0250\n",
      "Epoch 23/100\n",
      "160480/160480 [==============================] - 17s 105us/step - loss: 0.0263 - val_loss: 0.0245\n",
      "Epoch 24/100\n",
      "160480/160480 [==============================] - 17s 106us/step - loss: 0.0261 - val_loss: 0.0243\n",
      "Epoch 25/100\n",
      "160480/160480 [==============================] - 15s 96us/step - loss: 0.0259 - val_loss: 0.0248\n",
      "Epoch 26/100\n",
      "160480/160480 [==============================] - 14s 89us/step - loss: 0.0258 - val_loss: 0.0244\n",
      "Epoch 27/100\n",
      "160480/160480 [==============================] - 14s 88us/step - loss: 0.0255 - val_loss: 0.0250\n",
      "Epoch 28/100\n",
      "160480/160480 [==============================] - 15s 91us/step - loss: 0.0254 - val_loss: 0.0241\n",
      "Epoch 29/100\n",
      "160480/160480 [==============================] - 15s 90us/step - loss: 0.0252 - val_loss: 0.0240\n",
      "Epoch 30/100\n",
      "160480/160480 [==============================] - 14s 88us/step - loss: 0.0252 - val_loss: 0.0239\n",
      "Epoch 31/100\n",
      "160480/160480 [==============================] - 14s 87us/step - loss: 0.0250 - val_loss: 0.0238\n",
      "Epoch 32/100\n",
      "160480/160480 [==============================] - 14s 87us/step - loss: 0.0250 - val_loss: 0.0252\n",
      "Epoch 33/100\n",
      "160480/160480 [==============================] - 14s 86us/step - loss: 0.0247 - val_loss: 0.0244\n",
      "Epoch 34/100\n",
      "160480/160480 [==============================] - 15s 91us/step - loss: 0.0246 - val_loss: 0.0245\n",
      "Epoch 35/100\n",
      "160480/160480 [==============================] - 14s 86us/step - loss: 0.0245 - val_loss: 0.0245\n",
      "perc100SubjectF1andFold1\n",
      "271418\n",
      "87540\n",
      "Train on 242064 samples, validate on 78836 samples\n",
      "Epoch 1/100\n",
      "242064/242064 [==============================] - 28s 117us/step - loss: 0.0499 - val_loss: 0.0424\n",
      "Epoch 2/100\n",
      "242064/242064 [==============================] - 24s 100us/step - loss: 0.0399 - val_loss: 0.0387\n",
      "Epoch 3/100\n",
      "242064/242064 [==============================] - 22s 89us/step - loss: 0.0372 - val_loss: 0.0370\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242064/242064 [==============================] - 22s 92us/step - loss: 0.0355 - val_loss: 0.0357\n",
      "Epoch 5/100\n",
      "242064/242064 [==============================] - 22s 90us/step - loss: 0.0341 - val_loss: 0.0344\n",
      "Epoch 6/100\n",
      "242064/242064 [==============================] - 20s 85us/step - loss: 0.0332 - val_loss: 0.0336\n",
      "Epoch 7/100\n",
      "242064/242064 [==============================] - 20s 85us/step - loss: 0.0321 - val_loss: 0.0336\n",
      "Epoch 8/100\n",
      "242064/242064 [==============================] - 22s 89us/step - loss: 0.0313 - val_loss: 0.0325\n",
      "Epoch 9/100\n",
      "242064/242064 [==============================] - 22s 91us/step - loss: 0.0305 - val_loss: 0.0320\n",
      "Epoch 10/100\n",
      "242064/242064 [==============================] - 22s 91us/step - loss: 0.0299 - val_loss: 0.0317\n",
      "Epoch 11/100\n",
      "242064/242064 [==============================] - 22s 91us/step - loss: 0.0293 - val_loss: 0.0309\n",
      "Epoch 12/100\n",
      "242064/242064 [==============================] - 22s 90us/step - loss: 0.0287 - val_loss: 0.0295\n",
      "Epoch 13/100\n",
      "242064/242064 [==============================] - 22s 92us/step - loss: 0.0282 - val_loss: 0.0297\n",
      "Epoch 14/100\n",
      "242064/242064 [==============================] - 22s 90us/step - loss: 0.0278 - val_loss: 0.0287\n",
      "Epoch 15/100\n",
      "242064/242064 [==============================] - 22s 91us/step - loss: 0.0273 - val_loss: 0.0290\n",
      "Epoch 16/100\n",
      "242064/242064 [==============================] - 22s 91us/step - loss: 0.0270 - val_loss: 0.0286\n",
      "Epoch 17/100\n",
      "242064/242064 [==============================] - 21s 88us/step - loss: 0.0266 - val_loss: 0.0282\n",
      "Epoch 18/100\n",
      "242064/242064 [==============================] - 21s 87us/step - loss: 0.0264 - val_loss: 0.0286\n",
      "Epoch 19/100\n",
      "242064/242064 [==============================] - 21s 89us/step - loss: 0.0261 - val_loss: 0.0271\n",
      "Epoch 20/100\n",
      "242064/242064 [==============================] - 21s 88us/step - loss: 0.0258 - val_loss: 0.0277\n",
      "Epoch 21/100\n",
      "242064/242064 [==============================] - 21s 88us/step - loss: 0.0256 - val_loss: 0.0278\n",
      "Epoch 22/100\n",
      "242064/242064 [==============================] - 22s 91us/step - loss: 0.0254 - val_loss: 0.0270\n",
      "Epoch 23/100\n",
      "242064/242064 [==============================] - 22s 90us/step - loss: 0.0252 - val_loss: 0.0270\n",
      "Epoch 24/100\n",
      "242064/242064 [==============================] - 23s 93us/step - loss: 0.0250 - val_loss: 0.0268\n",
      "Epoch 25/100\n",
      "242064/242064 [==============================] - 21s 86us/step - loss: 0.0249 - val_loss: 0.0261\n",
      "Epoch 26/100\n",
      "242064/242064 [==============================] - 21s 87us/step - loss: 0.0246 - val_loss: 0.0262\n",
      "Epoch 27/100\n",
      "242064/242064 [==============================] - 21s 88us/step - loss: 0.0244 - val_loss: 0.0263\n",
      "Epoch 28/100\n",
      "242064/242064 [==============================] - 21s 87us/step - loss: 0.0242 - val_loss: 0.0260\n",
      "Epoch 29/100\n",
      "242064/242064 [==============================] - 21s 88us/step - loss: 0.0241 - val_loss: 0.0257\n",
      "Epoch 30/100\n",
      "242064/242064 [==============================] - 21s 88us/step - loss: 0.0240 - val_loss: 0.0258\n",
      "Epoch 31/100\n",
      "242064/242064 [==============================] - 21s 87us/step - loss: 0.0239 - val_loss: 0.0260\n",
      "Epoch 32/100\n",
      "242064/242064 [==============================] - 21s 87us/step - loss: 0.0236 - val_loss: 0.0258\n",
      "Epoch 33/100\n",
      "242064/242064 [==============================] - 21s 88us/step - loss: 0.0237 - val_loss: 0.0255\n",
      "Epoch 34/100\n",
      "242064/242064 [==============================] - 20s 84us/step - loss: 0.0234 - val_loss: 0.0257\n",
      "Epoch 35/100\n",
      "242064/242064 [==============================] - 21s 88us/step - loss: 0.0234 - val_loss: 0.0254\n",
      "Epoch 36/100\n",
      "242064/242064 [==============================] - 21s 88us/step - loss: 0.0234 - val_loss: 0.0254\n",
      "Epoch 37/100\n",
      "242064/242064 [==============================] - 21s 86us/step - loss: 0.0232 - val_loss: 0.0257\n",
      "Epoch 38/100\n",
      "242064/242064 [==============================] - 19s 79us/step - loss: 0.0230 - val_loss: 0.0259\n",
      "Epoch 39/100\n",
      "242064/242064 [==============================] - 20s 82us/step - loss: 0.0230 - val_loss: 0.0251\n",
      "Epoch 40/100\n",
      "242064/242064 [==============================] - 20s 82us/step - loss: 0.0230 - val_loss: 0.0249\n",
      "Epoch 41/100\n",
      "242064/242064 [==============================] - 20s 83us/step - loss: 0.0229 - val_loss: 0.0250\n",
      "Epoch 42/100\n",
      "242064/242064 [==============================] - 20s 84us/step - loss: 0.0228 - val_loss: 0.0250\n",
      "Epoch 43/100\n",
      "242064/242064 [==============================] - 22s 90us/step - loss: 0.0227 - val_loss: 0.0251\n",
      "Epoch 44/100\n",
      "242064/242064 [==============================] - 19s 78us/step - loss: 0.0226 - val_loss: 0.0251\n",
      "perc100SubjectF1andFold2\n",
      "289711\n",
      "95710\n",
      "Train on 105358 samples, validate on 33370 samples\n",
      "Epoch 1/100\n",
      "105358/105358 [==============================] - 14s 136us/step - loss: 0.0600 - val_loss: 0.0465\n",
      "Epoch 2/100\n",
      "105358/105358 [==============================] - 9s 84us/step - loss: 0.0448 - val_loss: 0.0426\n",
      "Epoch 3/100\n",
      "105358/105358 [==============================] - 9s 90us/step - loss: 0.0401 - val_loss: 0.0377\n",
      "Epoch 4/100\n",
      "105358/105358 [==============================] - 9s 85us/step - loss: 0.0368 - val_loss: 0.0351\n",
      "Epoch 5/100\n",
      "105358/105358 [==============================] - 10s 98us/step - loss: 0.0342 - val_loss: 0.0336\n",
      "Epoch 6/100\n",
      "105358/105358 [==============================] - 11s 101us/step - loss: 0.0320 - val_loss: 0.0318\n",
      "Epoch 7/100\n",
      "105358/105358 [==============================] - 12s 115us/step - loss: 0.0304 - val_loss: 0.0306\n",
      "Epoch 8/100\n",
      "105358/105358 [==============================] - 13s 125us/step - loss: 0.0291 - val_loss: 0.0309\n",
      "Epoch 9/100\n",
      "105358/105358 [==============================] - 13s 126us/step - loss: 0.0282 - val_loss: 0.0282\n",
      "Epoch 10/100\n",
      "105358/105358 [==============================] - 12s 113us/step - loss: 0.0274 - val_loss: 0.0286\n",
      "Epoch 11/100\n",
      "105358/105358 [==============================] - 11s 107us/step - loss: 0.0266 - val_loss: 0.0288\n",
      "Epoch 12/100\n",
      "105358/105358 [==============================] - 10s 91us/step - loss: 0.0258 - val_loss: 0.0299\n",
      "Epoch 13/100\n",
      "105358/105358 [==============================] - 9s 84us/step - loss: 0.0253 - val_loss: 0.0268\n",
      "Epoch 14/100\n",
      "105358/105358 [==============================] - 9s 87us/step - loss: 0.0247 - val_loss: 0.0288\n",
      "Epoch 15/100\n",
      "105358/105358 [==============================] - 9s 83us/step - loss: 0.0242 - val_loss: 0.0270\n",
      "Epoch 16/100\n",
      "105358/105358 [==============================] - 9s 83us/step - loss: 0.0237 - val_loss: 0.0281\n",
      "Epoch 17/100\n",
      "105358/105358 [==============================] - 9s 86us/step - loss: 0.0234 - val_loss: 0.0265\n",
      "Epoch 18/100\n",
      "105358/105358 [==============================] - 9s 84us/step - loss: 0.0231 - val_loss: 0.0260\n",
      "Epoch 19/100\n",
      "105358/105358 [==============================] - 9s 85us/step - loss: 0.0228 - val_loss: 0.0258\n",
      "Epoch 20/100\n",
      "105358/105358 [==============================] - 10s 96us/step - loss: 0.0224 - val_loss: 0.0258\n",
      "Epoch 21/100\n",
      "105358/105358 [==============================] - 10s 98us/step - loss: 0.0220 - val_loss: 0.0255\n",
      "Epoch 22/100\n",
      "105358/105358 [==============================] - 11s 100us/step - loss: 0.0218 - val_loss: 0.0248\n",
      "Epoch 23/100\n",
      "105358/105358 [==============================] - 11s 105us/step - loss: 0.0215 - val_loss: 0.0261\n",
      "Epoch 24/100\n",
      "105358/105358 [==============================] - 10s 99us/step - loss: 0.0213 - val_loss: 0.0258\n",
      "Epoch 25/100\n",
      "105358/105358 [==============================] - 9s 87us/step - loss: 0.0210 - val_loss: 0.0252\n",
      "Epoch 26/100\n",
      "105358/105358 [==============================] - 8s 75us/step - loss: 0.0206 - val_loss: 0.0242\n",
      "Epoch 27/100\n",
      "105358/105358 [==============================] - 9s 83us/step - loss: 0.0206 - val_loss: 0.0244\n",
      "Epoch 28/100\n",
      "105358/105358 [==============================] - 9s 84us/step - loss: 0.0204 - val_loss: 0.0248\n",
      "Epoch 29/100\n",
      "105358/105358 [==============================] - 9s 84us/step - loss: 0.0201 - val_loss: 0.0249\n",
      "Epoch 30/100\n",
      "105358/105358 [==============================] - 9s 82us/step - loss: 0.0200 - val_loss: 0.0260\n",
      "perc100SubjectF1andFold3\n",
      "222639\n",
      "73363\n",
      "Train on 198253 samples, validate on 65210 samples\n",
      "Epoch 1/100\n",
      "198253/198253 [==============================] - 24s 122us/step - loss: 0.0526 - val_loss: 0.0448\n",
      "Epoch 2/100\n",
      "198253/198253 [==============================] - 19s 94us/step - loss: 0.0426 - val_loss: 0.0388\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198253/198253 [==============================] - 20s 100us/step - loss: 0.0401 - val_loss: 0.0359\n",
      "Epoch 4/100\n",
      "198253/198253 [==============================] - 20s 99us/step - loss: 0.0385 - val_loss: 0.0349\n",
      "Epoch 5/100\n",
      "198253/198253 [==============================] - 19s 95us/step - loss: 0.0373 - val_loss: 0.0341\n",
      "Epoch 6/100\n",
      "198253/198253 [==============================] - 19s 95us/step - loss: 0.0361 - val_loss: 0.0339\n",
      "Epoch 7/100\n",
      "198253/198253 [==============================] - 19s 95us/step - loss: 0.0351 - val_loss: 0.0322\n",
      "Epoch 8/100\n",
      "198253/198253 [==============================] - 19s 98us/step - loss: 0.0343 - val_loss: 0.0306\n",
      "Epoch 9/100\n",
      "198253/198253 [==============================] - 19s 95us/step - loss: 0.0335 - val_loss: 0.0318\n",
      "Epoch 10/100\n",
      "198253/198253 [==============================] - 19s 94us/step - loss: 0.0328 - val_loss: 0.0310\n",
      "Epoch 11/100\n",
      "198253/198253 [==============================] - 19s 98us/step - loss: 0.0322 - val_loss: 0.0320\n",
      "Epoch 12/100\n",
      "198253/198253 [==============================] - 19s 94us/step - loss: 0.0317 - val_loss: 0.0297\n",
      "Epoch 13/100\n",
      "198253/198253 [==============================] - 18s 93us/step - loss: 0.0312 - val_loss: 0.0310\n",
      "Epoch 14/100\n",
      "198253/198253 [==============================] - 19s 96us/step - loss: 0.0306 - val_loss: 0.0295\n",
      "Epoch 15/100\n",
      "198253/198253 [==============================] - 19s 95us/step - loss: 0.0303 - val_loss: 0.0292\n",
      "Epoch 16/100\n",
      "198253/198253 [==============================] - 18s 93us/step - loss: 0.0300 - val_loss: 0.0294\n",
      "Epoch 17/100\n",
      "198253/198253 [==============================] - 19s 94us/step - loss: 0.0295 - val_loss: 0.0297\n",
      "Epoch 18/100\n",
      "198253/198253 [==============================] - 21s 107us/step - loss: 0.0291 - val_loss: 0.0283\n",
      "Epoch 19/100\n",
      "198253/198253 [==============================] - 21s 107us/step - loss: 0.0289 - val_loss: 0.0267\n",
      "Epoch 20/100\n",
      "198253/198253 [==============================] - 22s 109us/step - loss: 0.0285 - val_loss: 0.0269\n",
      "Epoch 21/100\n",
      "198253/198253 [==============================] - 22s 112us/step - loss: 0.0283 - val_loss: 0.0266\n",
      "Epoch 22/100\n",
      "198253/198253 [==============================] - 22s 111us/step - loss: 0.0280 - val_loss: 0.0268\n",
      "Epoch 23/100\n",
      "198253/198253 [==============================] - 22s 111us/step - loss: 0.0278 - val_loss: 0.0269\n",
      "Epoch 24/100\n",
      "198253/198253 [==============================] - 21s 106us/step - loss: 0.0276 - val_loss: 0.0280\n",
      "Epoch 25/100\n",
      "198253/198253 [==============================] - 20s 99us/step - loss: 0.0274 - val_loss: 0.0277\n",
      "perc100SubjectF1andFold4\n",
      "225256\n",
      "75573\n",
      "Train on 111542 samples, validate on 36959 samples\n",
      "Epoch 1/100\n",
      "111542/111542 [==============================] - 16s 144us/step - loss: 0.0531 - val_loss: 0.0422\n",
      "Epoch 2/100\n",
      "111542/111542 [==============================] - 10s 90us/step - loss: 0.0406 - val_loss: 0.0391\n",
      "Epoch 3/100\n",
      "111542/111542 [==============================] - 9s 85us/step - loss: 0.0370 - val_loss: 0.0361\n",
      "Epoch 4/100\n",
      "111542/111542 [==============================] - 10s 88us/step - loss: 0.0343 - val_loss: 0.0340\n",
      "Epoch 5/100\n",
      "111542/111542 [==============================] - 9s 84us/step - loss: 0.0326 - val_loss: 0.0332\n",
      "Epoch 6/100\n",
      "111542/111542 [==============================] - 10s 87us/step - loss: 0.0313 - val_loss: 0.0320\n",
      "Epoch 7/100\n",
      "111542/111542 [==============================] - 10s 90us/step - loss: 0.0301 - val_loss: 0.0300\n",
      "Epoch 8/100\n",
      "111542/111542 [==============================] - 10s 91us/step - loss: 0.0290 - val_loss: 0.0305\n",
      "Epoch 9/100\n",
      "111542/111542 [==============================] - 10s 86us/step - loss: 0.0283 - val_loss: 0.0285\n",
      "Epoch 10/100\n",
      "111542/111542 [==============================] - 12s 108us/step - loss: 0.0276 - val_loss: 0.0301\n",
      "Epoch 11/100\n",
      "111542/111542 [==============================] - 12s 110us/step - loss: 0.0268 - val_loss: 0.0274\n",
      "Epoch 12/100\n",
      "111542/111542 [==============================] - 14s 122us/step - loss: 0.0262 - val_loss: 0.0276\n",
      "Epoch 13/100\n",
      "111542/111542 [==============================] - 15s 130us/step - loss: 0.0255 - val_loss: 0.0273\n",
      "Epoch 14/100\n",
      "111542/111542 [==============================] - 13s 113us/step - loss: 0.0251 - val_loss: 0.0264\n",
      "Epoch 15/100\n",
      "111542/111542 [==============================] - 14s 126us/step - loss: 0.0248 - val_loss: 0.0257\n",
      "Epoch 16/100\n",
      "111542/111542 [==============================] - 15s 131us/step - loss: 0.0245 - val_loss: 0.0255\n",
      "Epoch 17/100\n",
      "111542/111542 [==============================] - 13s 117us/step - loss: 0.0241 - val_loss: 0.0262\n",
      "Epoch 18/100\n",
      "111542/111542 [==============================] - 12s 109us/step - loss: 0.0236 - val_loss: 0.0255\n",
      "Epoch 19/100\n",
      "111542/111542 [==============================] - 13s 112us/step - loss: 0.0233 - val_loss: 0.0253\n",
      "Epoch 20/100\n",
      "111542/111542 [==============================] - 13s 116us/step - loss: 0.0229 - val_loss: 0.0250\n",
      "Epoch 21/100\n",
      "111542/111542 [==============================] - 13s 113us/step - loss: 0.0229 - val_loss: 0.0243\n",
      "Epoch 22/100\n",
      "111542/111542 [==============================] - 12s 108us/step - loss: 0.0226 - val_loss: 0.0243\n",
      "Epoch 23/100\n",
      "111542/111542 [==============================] - 11s 100us/step - loss: 0.0224 - val_loss: 0.0239\n",
      "Epoch 24/100\n",
      "111542/111542 [==============================] - 12s 106us/step - loss: 0.0220 - val_loss: 0.0239\n",
      "Epoch 25/100\n",
      "111542/111542 [==============================] - 12s 105us/step - loss: 0.0218 - val_loss: 0.0236\n",
      "Epoch 26/100\n",
      "111542/111542 [==============================] - 12s 106us/step - loss: 0.0216 - val_loss: 0.0239\n",
      "Epoch 27/100\n",
      "111542/111542 [==============================] - 12s 107us/step - loss: 0.0215 - val_loss: 0.0233\n",
      "Epoch 28/100\n",
      "111542/111542 [==============================] - 12s 107us/step - loss: 0.0212 - val_loss: 0.0231\n",
      "Epoch 29/100\n",
      "111542/111542 [==============================] - 11s 103us/step - loss: 0.0210 - val_loss: 0.0227\n",
      "Epoch 30/100\n",
      "111542/111542 [==============================] - 12s 105us/step - loss: 0.0210 - val_loss: 0.0232\n",
      "Epoch 31/100\n",
      "111542/111542 [==============================] - 12s 107us/step - loss: 0.0206 - val_loss: 0.0234\n",
      "Epoch 32/100\n",
      "111542/111542 [==============================] - 12s 105us/step - loss: 0.0205 - val_loss: 0.0228\n",
      "Epoch 33/100\n",
      "111542/111542 [==============================] - 12s 107us/step - loss: 0.0202 - val_loss: 0.0227\n",
      "Epoch 34/100\n",
      "111542/111542 [==============================] - 12s 106us/step - loss: 0.0201 - val_loss: 0.0221\n",
      "Epoch 35/100\n",
      "111542/111542 [==============================] - 11s 100us/step - loss: 0.0201 - val_loss: 0.0224\n",
      "Epoch 36/100\n",
      "111542/111542 [==============================] - 12s 107us/step - loss: 0.0198 - val_loss: 0.0217\n",
      "Epoch 37/100\n",
      "111542/111542 [==============================] - 12s 109us/step - loss: 0.0199 - val_loss: 0.0224\n",
      "Epoch 38/100\n",
      "111542/111542 [==============================] - 11s 102us/step - loss: 0.0196 - val_loss: 0.0222\n",
      "Epoch 39/100\n",
      "111542/111542 [==============================] - 12s 109us/step - loss: 0.0196 - val_loss: 0.0222\n",
      "Epoch 40/100\n",
      "111542/111542 [==============================] - 12s 109us/step - loss: 0.0194 - val_loss: 0.0218\n",
      "perc100SubjectF2andFold1\n",
      "234546\n",
      "75733\n",
      "Train on 143933 samples, validate on 46564 samples\n",
      "Epoch 1/100\n",
      "143933/143933 [==============================] - 23s 158us/step - loss: 0.0517 - val_loss: 0.0387\n",
      "Epoch 2/100\n",
      "143933/143933 [==============================] - 18s 122us/step - loss: 0.0406 - val_loss: 0.0377\n",
      "Epoch 3/100\n",
      "143933/143933 [==============================] - 17s 118us/step - loss: 0.0386 - val_loss: 0.0360\n",
      "Epoch 4/100\n",
      "143933/143933 [==============================] - 16s 112us/step - loss: 0.0375 - val_loss: 0.0347\n",
      "Epoch 5/100\n",
      "143933/143933 [==============================] - 17s 115us/step - loss: 0.0365 - val_loss: 0.0345\n",
      "Epoch 6/100\n",
      "143933/143933 [==============================] - 18s 126us/step - loss: 0.0357 - val_loss: 0.0337\n",
      "Epoch 7/100\n",
      "143933/143933 [==============================] - 16s 112us/step - loss: 0.0348 - val_loss: 0.0335\n",
      "Epoch 8/100\n",
      "143933/143933 [==============================] - 16s 113us/step - loss: 0.0343 - val_loss: 0.0323\n",
      "Epoch 9/100\n",
      "143933/143933 [==============================] - 16s 113us/step - loss: 0.0337 - val_loss: 0.0315\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143933/143933 [==============================] - 16s 112us/step - loss: 0.0330 - val_loss: 0.0313\n",
      "Epoch 11/100\n",
      "143933/143933 [==============================] - 16s 110us/step - loss: 0.0326 - val_loss: 0.0312\n",
      "Epoch 12/100\n",
      "143933/143933 [==============================] - 16s 113us/step - loss: 0.0322 - val_loss: 0.0310\n",
      "Epoch 13/100\n",
      "143933/143933 [==============================] - 16s 111us/step - loss: 0.0318 - val_loss: 0.0304\n",
      "Epoch 14/100\n",
      "143933/143933 [==============================] - 16s 111us/step - loss: 0.0315 - val_loss: 0.0305\n",
      "Epoch 15/100\n",
      "143933/143933 [==============================] - 16s 110us/step - loss: 0.0311 - val_loss: 0.0298\n",
      "Epoch 16/100\n",
      "143933/143933 [==============================] - 16s 113us/step - loss: 0.0308 - val_loss: 0.0309\n",
      "Epoch 17/100\n",
      "143933/143933 [==============================] - 16s 113us/step - loss: 0.0304 - val_loss: 0.0304\n",
      "Epoch 18/100\n",
      "143933/143933 [==============================] - 16s 108us/step - loss: 0.0300 - val_loss: 0.0295\n",
      "Epoch 19/100\n",
      "143933/143933 [==============================] - 16s 110us/step - loss: 0.0298 - val_loss: 0.0290\n",
      "Epoch 20/100\n",
      "143933/143933 [==============================] - 16s 112us/step - loss: 0.0295 - val_loss: 0.0293\n",
      "Epoch 21/100\n",
      "143933/143933 [==============================] - 16s 111us/step - loss: 0.0294 - val_loss: 0.0291\n",
      "Epoch 22/100\n",
      "143933/143933 [==============================] - 15s 106us/step - loss: 0.0291 - val_loss: 0.0284\n",
      "Epoch 23/100\n",
      "143933/143933 [==============================] - 16s 114us/step - loss: 0.0289 - val_loss: 0.0282\n",
      "Epoch 24/100\n",
      "143933/143933 [==============================] - 16s 114us/step - loss: 0.0288 - val_loss: 0.0281\n",
      "Epoch 25/100\n",
      "143933/143933 [==============================] - 16s 111us/step - loss: 0.0285 - val_loss: 0.0275\n",
      "Epoch 26/100\n",
      "143933/143933 [==============================] - 16s 108us/step - loss: 0.0284 - val_loss: 0.0281\n",
      "Epoch 27/100\n",
      "143933/143933 [==============================] - 16s 113us/step - loss: 0.0282 - val_loss: 0.0282\n",
      "Epoch 28/100\n",
      "143933/143933 [==============================] - 16s 111us/step - loss: 0.0281 - val_loss: 0.0276\n",
      "Epoch 29/100\n",
      "143933/143933 [==============================] - 16s 112us/step - loss: 0.0278 - val_loss: 0.0280\n",
      "perc100SubjectF2andFold2\n",
      "274150\n",
      "93361\n",
      "Train on 165880 samples, validate on 57218 samples\n",
      "Epoch 1/100\n",
      "165880/165880 [==============================] - 25s 150us/step - loss: 0.0486 - val_loss: 0.0368\n",
      "Epoch 2/100\n",
      "165880/165880 [==============================] - 19s 114us/step - loss: 0.0389 - val_loss: 0.0356\n",
      "Epoch 3/100\n",
      "165880/165880 [==============================] - 20s 118us/step - loss: 0.0371 - val_loss: 0.0346\n",
      "Epoch 4/100\n",
      "165880/165880 [==============================] - 19s 112us/step - loss: 0.0362 - val_loss: 0.0334\n",
      "Epoch 5/100\n",
      "165880/165880 [==============================] - 19s 112us/step - loss: 0.0352 - val_loss: 0.0327\n",
      "Epoch 6/100\n",
      "165880/165880 [==============================] - 20s 121us/step - loss: 0.0344 - val_loss: 0.0326\n",
      "Epoch 7/100\n",
      "165880/165880 [==============================] - 21s 130us/step - loss: 0.0336 - val_loss: 0.0319\n",
      "Epoch 8/100\n",
      "165880/165880 [==============================] - 23s 140us/step - loss: 0.0331 - val_loss: 0.0312\n",
      "Epoch 9/100\n",
      "165880/165880 [==============================] - 21s 125us/step - loss: 0.0324 - val_loss: 0.0303\n",
      "Epoch 10/100\n",
      "165880/165880 [==============================] - 22s 134us/step - loss: 0.0319 - val_loss: 0.0299\n",
      "Epoch 11/100\n",
      "165880/165880 [==============================] - 21s 124us/step - loss: 0.0315 - val_loss: 0.0294\n",
      "Epoch 12/100\n",
      "165880/165880 [==============================] - 21s 129us/step - loss: 0.0311 - val_loss: 0.0293\n",
      "Epoch 13/100\n",
      "165880/165880 [==============================] - 22s 130us/step - loss: 0.0307 - val_loss: 0.0287\n",
      "Epoch 14/100\n",
      "165880/165880 [==============================] - 21s 124us/step - loss: 0.0302 - val_loss: 0.0288\n",
      "Epoch 15/100\n",
      "165880/165880 [==============================] - 20s 121us/step - loss: 0.0299 - val_loss: 0.0282\n",
      "Epoch 16/100\n",
      "165880/165880 [==============================] - 22s 132us/step - loss: 0.0295 - val_loss: 0.0282\n",
      "Epoch 17/100\n",
      "165880/165880 [==============================] - 25s 149us/step - loss: 0.0292 - val_loss: 0.0282\n",
      "Epoch 18/100\n",
      "165880/165880 [==============================] - 22s 132us/step - loss: 0.0290 - val_loss: 0.0275\n",
      "Epoch 19/100\n",
      "165880/165880 [==============================] - 21s 127us/step - loss: 0.0287 - val_loss: 0.0276\n",
      "Epoch 20/100\n",
      "165880/165880 [==============================] - 21s 129us/step - loss: 0.0283 - val_loss: 0.0276\n",
      "Epoch 21/100\n",
      "165880/165880 [==============================] - 22s 131us/step - loss: 0.0283 - val_loss: 0.0268\n",
      "Epoch 22/100\n",
      "165880/165880 [==============================] - 22s 135us/step - loss: 0.0280 - val_loss: 0.0267\n",
      "Epoch 23/100\n",
      "165880/165880 [==============================] - 22s 134us/step - loss: 0.0278 - val_loss: 0.0269\n",
      "Epoch 24/100\n",
      "165880/165880 [==============================] - 25s 149us/step - loss: 0.0275 - val_loss: 0.0265\n",
      "Epoch 25/100\n",
      "165880/165880 [==============================] - 23s 137us/step - loss: 0.0275 - val_loss: 0.0264\n",
      "Epoch 26/100\n",
      "165880/165880 [==============================] - 22s 131us/step - loss: 0.0273 - val_loss: 0.0266\n",
      "Epoch 27/100\n",
      "165880/165880 [==============================] - 22s 131us/step - loss: 0.0271 - val_loss: 0.0262\n",
      "Epoch 28/100\n",
      "165880/165880 [==============================] - 22s 132us/step - loss: 0.0270 - val_loss: 0.0257\n",
      "Epoch 29/100\n",
      "165880/165880 [==============================] - 22s 135us/step - loss: 0.0268 - val_loss: 0.0259\n",
      "Epoch 30/100\n",
      "165880/165880 [==============================] - 21s 126us/step - loss: 0.0267 - val_loss: 0.0258\n",
      "Epoch 31/100\n",
      "165880/165880 [==============================] - 22s 133us/step - loss: 0.0265 - val_loss: 0.0257\n",
      "Epoch 32/100\n",
      "165880/165880 [==============================] - 22s 131us/step - loss: 0.0264 - val_loss: 0.0258\n",
      "perc100SubjectF2andFold3\n",
      "225898\n",
      "73184\n",
      "Train on 139865 samples, validate on 44995 samples\n",
      "Epoch 1/100\n",
      "139865/139865 [==============================] - 26s 182us/step - loss: 0.0531 - val_loss: 0.0398\n",
      "Epoch 2/100\n",
      "139865/139865 [==============================] - 18s 131us/step - loss: 0.0424 - val_loss: 0.0370\n",
      "Epoch 3/100\n",
      "139865/139865 [==============================] - 18s 126us/step - loss: 0.0410 - val_loss: 0.0368\n",
      "Epoch 4/100\n",
      "139865/139865 [==============================] - 19s 134us/step - loss: 0.0400 - val_loss: 0.0356\n",
      "Epoch 5/100\n",
      "139865/139865 [==============================] - 20s 140us/step - loss: 0.0391 - val_loss: 0.0357\n",
      "Epoch 6/100\n",
      "139865/139865 [==============================] - 19s 135us/step - loss: 0.0385 - val_loss: 0.0344\n",
      "Epoch 7/100\n",
      "139865/139865 [==============================] - 19s 133us/step - loss: 0.0375 - val_loss: 0.0345\n",
      "Epoch 8/100\n",
      "139865/139865 [==============================] - 19s 134us/step - loss: 0.0369 - val_loss: 0.0332\n",
      "Epoch 9/100\n",
      "139865/139865 [==============================] - 18s 125us/step - loss: 0.0365 - val_loss: 0.0326\n",
      "Epoch 10/100\n",
      "139865/139865 [==============================] - 19s 134us/step - loss: 0.0359 - val_loss: 0.0314\n",
      "Epoch 11/100\n",
      "139865/139865 [==============================] - 19s 139us/step - loss: 0.0356 - val_loss: 0.0310\n",
      "Epoch 12/100\n",
      "139865/139865 [==============================] - 22s 155us/step - loss: 0.0351 - val_loss: 0.0315\n",
      "Epoch 13/100\n",
      "139865/139865 [==============================] - 20s 145us/step - loss: 0.0347 - val_loss: 0.0313\n",
      "Epoch 14/100\n",
      "139865/139865 [==============================] - 19s 135us/step - loss: 0.0342 - val_loss: 0.0310\n",
      "Epoch 15/100\n",
      "139865/139865 [==============================] - 17s 125us/step - loss: 0.0338 - val_loss: 0.0300\n",
      "Epoch 16/100\n",
      "139865/139865 [==============================] - 19s 135us/step - loss: 0.0336 - val_loss: 0.0303\n",
      "Epoch 17/100\n",
      "139865/139865 [==============================] - 18s 130us/step - loss: 0.0333 - val_loss: 0.0298\n",
      "Epoch 18/100\n",
      "139865/139865 [==============================] - 18s 131us/step - loss: 0.0329 - val_loss: 0.0295\n",
      "Epoch 19/100\n",
      "139865/139865 [==============================] - 18s 130us/step - loss: 0.0325 - val_loss: 0.0298\n",
      "Epoch 20/100\n",
      "139865/139865 [==============================] - 19s 133us/step - loss: 0.0324 - val_loss: 0.0289\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139865/139865 [==============================] - 18s 131us/step - loss: 0.0322 - val_loss: 0.0294\n",
      "Epoch 22/100\n",
      "139865/139865 [==============================] - 20s 143us/step - loss: 0.0320 - val_loss: 0.0283\n",
      "Epoch 23/100\n",
      "139865/139865 [==============================] - 20s 140us/step - loss: 0.0319 - val_loss: 0.0288\n",
      "Epoch 24/100\n",
      "139865/139865 [==============================] - 20s 142us/step - loss: 0.0315 - val_loss: 0.0295\n",
      "Epoch 25/100\n",
      "139865/139865 [==============================] - 20s 140us/step - loss: 0.0314 - val_loss: 0.0296\n",
      "Epoch 26/100\n",
      "139865/139865 [==============================] - 20s 144us/step - loss: 0.0311 - val_loss: 0.0291\n",
      "perc100SubjectF2andFold4\n",
      "210055\n",
      "71816\n",
      "Train on 124346 samples, validate on 41774 samples\n",
      "Epoch 1/100\n",
      "124346/124346 [==============================] - 24s 195us/step - loss: 0.0486 - val_loss: 0.0383\n",
      "Epoch 2/100\n",
      "124346/124346 [==============================] - 18s 145us/step - loss: 0.0369 - val_loss: 0.0366\n",
      "Epoch 3/100\n",
      "124346/124346 [==============================] - 18s 143us/step - loss: 0.0352 - val_loss: 0.0357\n",
      "Epoch 4/100\n",
      "124346/124346 [==============================] - 18s 144us/step - loss: 0.0343 - val_loss: 0.0363\n",
      "Epoch 5/100\n",
      "124346/124346 [==============================] - 18s 146us/step - loss: 0.0333 - val_loss: 0.0341\n",
      "Epoch 6/100\n",
      "124346/124346 [==============================] - 19s 155us/step - loss: 0.0327 - val_loss: 0.0330\n",
      "Epoch 7/100\n",
      "124346/124346 [==============================] - 18s 142us/step - loss: 0.0321 - val_loss: 0.0328\n",
      "Epoch 8/100\n",
      "124346/124346 [==============================] - 18s 146us/step - loss: 0.0315 - val_loss: 0.0327\n",
      "Epoch 9/100\n",
      "124346/124346 [==============================] - 18s 146us/step - loss: 0.0309 - val_loss: 0.0318\n",
      "Epoch 10/100\n",
      "124346/124346 [==============================] - 18s 145us/step - loss: 0.0303 - val_loss: 0.0317\n",
      "Epoch 11/100\n",
      "124346/124346 [==============================] - 17s 140us/step - loss: 0.0299 - val_loss: 0.0311\n",
      "Epoch 12/100\n",
      "124346/124346 [==============================] - 17s 140us/step - loss: 0.0296 - val_loss: 0.0313\n",
      "Epoch 13/100\n",
      "124346/124346 [==============================] - 17s 139us/step - loss: 0.0291 - val_loss: 0.0307\n",
      "Epoch 14/100\n",
      "124346/124346 [==============================] - 17s 138us/step - loss: 0.0288 - val_loss: 0.0305\n",
      "Epoch 15/100\n",
      "124346/124346 [==============================] - 17s 135us/step - loss: 0.0284 - val_loss: 0.0298\n",
      "Epoch 16/100\n",
      "124346/124346 [==============================] - 18s 146us/step - loss: 0.0281 - val_loss: 0.0297\n",
      "Epoch 17/100\n",
      "124346/124346 [==============================] - 17s 139us/step - loss: 0.0278 - val_loss: 0.0293\n",
      "Epoch 18/100\n",
      "124346/124346 [==============================] - 17s 141us/step - loss: 0.0276 - val_loss: 0.0291\n",
      "Epoch 19/100\n",
      "124346/124346 [==============================] - 17s 138us/step - loss: 0.0273 - val_loss: 0.0290\n",
      "Epoch 20/100\n",
      "124346/124346 [==============================] - 17s 139us/step - loss: 0.0271 - val_loss: 0.0288\n",
      "Epoch 21/100\n",
      "124346/124346 [==============================] - 17s 138us/step - loss: 0.0268 - val_loss: 0.0283\n",
      "Epoch 22/100\n",
      "124346/124346 [==============================] - 17s 139us/step - loss: 0.0267 - val_loss: 0.0286\n",
      "Epoch 23/100\n",
      "124346/124346 [==============================] - 16s 133us/step - loss: 0.0264 - val_loss: 0.0287\n",
      "Epoch 24/100\n",
      "124346/124346 [==============================] - 18s 142us/step - loss: 0.0262 - val_loss: 0.0285\n",
      "Epoch 25/100\n",
      "124346/124346 [==============================] - 17s 134us/step - loss: 0.0260 - val_loss: 0.0278\n",
      "Epoch 26/100\n",
      "124346/124346 [==============================] - 17s 138us/step - loss: 0.0258 - val_loss: 0.0279\n",
      "Epoch 27/100\n",
      "124346/124346 [==============================] - 17s 140us/step - loss: 0.0257 - val_loss: 0.0282\n",
      "Epoch 28/100\n",
      "124346/124346 [==============================] - 17s 140us/step - loss: 0.0255 - val_loss: 0.0282\n",
      "Epoch 29/100\n",
      "124346/124346 [==============================] - 17s 141us/step - loss: 0.0253 - val_loss: 0.0279\n",
      "perc100SubjectM1andFold1\n",
      "312801\n",
      "104641\n",
      "Train on 263856 samples, validate on 88904 samples\n",
      "Epoch 1/100\n",
      "263856/263856 [==============================] - 42s 160us/step - loss: 0.0483 - val_loss: 0.0429\n",
      "Epoch 2/100\n",
      "263856/263856 [==============================] - 36s 135us/step - loss: 0.0399 - val_loss: 0.0389\n",
      "Epoch 3/100\n",
      "263856/263856 [==============================] - 36s 137us/step - loss: 0.0379 - val_loss: 0.0355\n",
      "Epoch 4/100\n",
      "263856/263856 [==============================] - 35s 134us/step - loss: 0.0368 - val_loss: 0.0345\n",
      "Epoch 5/100\n",
      "263856/263856 [==============================] - 35s 134us/step - loss: 0.0358 - val_loss: 0.0339\n",
      "Epoch 6/100\n",
      "263856/263856 [==============================] - 35s 134us/step - loss: 0.0350 - val_loss: 0.0332\n",
      "Epoch 7/100\n",
      "263856/263856 [==============================] - 37s 139us/step - loss: 0.0343 - val_loss: 0.0325\n",
      "Epoch 8/100\n",
      "263856/263856 [==============================] - 37s 139us/step - loss: 0.0338 - val_loss: 0.0328\n",
      "Epoch 9/100\n",
      "263856/263856 [==============================] - 37s 138us/step - loss: 0.0333 - val_loss: 0.0317\n",
      "Epoch 10/100\n",
      "263856/263856 [==============================] - 36s 138us/step - loss: 0.0328 - val_loss: 0.0311\n",
      "Epoch 11/100\n",
      "263856/263856 [==============================] - 36s 135us/step - loss: 0.0324 - val_loss: 0.0335\n",
      "Epoch 12/100\n",
      "263856/263856 [==============================] - 36s 135us/step - loss: 0.0320 - val_loss: 0.0304\n",
      "Epoch 13/100\n",
      "263856/263856 [==============================] - 36s 136us/step - loss: 0.0316 - val_loss: 0.0299\n",
      "Epoch 14/100\n",
      "263856/263856 [==============================] - 36s 136us/step - loss: 0.0313 - val_loss: 0.0302\n",
      "Epoch 15/100\n",
      "263856/263856 [==============================] - 35s 132us/step - loss: 0.0310 - val_loss: 0.0299\n",
      "Epoch 16/100\n",
      "263856/263856 [==============================] - 35s 133us/step - loss: 0.0308 - val_loss: 0.0299\n",
      "Epoch 17/100\n",
      "263856/263856 [==============================] - 36s 135us/step - loss: 0.0304 - val_loss: 0.0295\n",
      "Epoch 18/100\n",
      "263856/263856 [==============================] - 36s 136us/step - loss: 0.0302 - val_loss: 0.0287\n",
      "Epoch 19/100\n",
      "263856/263856 [==============================] - 35s 132us/step - loss: 0.0300 - val_loss: 0.0291\n",
      "Epoch 20/100\n",
      "263856/263856 [==============================] - 35s 133us/step - loss: 0.0298 - val_loss: 0.0286\n",
      "Epoch 21/100\n",
      "263856/263856 [==============================] - 36s 135us/step - loss: 0.0295 - val_loss: 0.0287\n",
      "Epoch 22/100\n",
      "263856/263856 [==============================] - 36s 136us/step - loss: 0.0294 - val_loss: 0.0286\n",
      "Epoch 23/100\n",
      "263856/263856 [==============================] - 38s 145us/step - loss: 0.0292 - val_loss: 0.0282\n",
      "Epoch 24/100\n",
      "263856/263856 [==============================] - 36s 138us/step - loss: 0.0291 - val_loss: 0.0279\n",
      "Epoch 25/100\n",
      "263856/263856 [==============================] - 36s 137us/step - loss: 0.0289 - val_loss: 0.0280\n",
      "Epoch 26/100\n",
      "263856/263856 [==============================] - 36s 137us/step - loss: 0.0287 - val_loss: 0.0281\n",
      "Epoch 27/100\n",
      "263856/263856 [==============================] - 36s 138us/step - loss: 0.0286 - val_loss: 0.0276\n",
      "Epoch 28/100\n",
      "263856/263856 [==============================] - 35s 133us/step - loss: 0.0285 - val_loss: 0.0273\n",
      "Epoch 29/100\n",
      "263856/263856 [==============================] - 37s 138us/step - loss: 0.0283 - val_loss: 0.0270\n",
      "Epoch 30/100\n",
      "263856/263856 [==============================] - 36s 138us/step - loss: 0.0282 - val_loss: 0.0278\n",
      "Epoch 31/100\n",
      "263856/263856 [==============================] - 36s 138us/step - loss: 0.0281 - val_loss: 0.0272\n",
      "Epoch 32/100\n",
      "263856/263856 [==============================] - 31s 118us/step - loss: 0.0280 - val_loss: 0.0273\n",
      "Epoch 33/100\n",
      "263856/263856 [==============================] - 33s 124us/step - loss: 0.0278 - val_loss: 0.0271\n",
      "perc100SubjectM1andFold2\n",
      "321200\n",
      "106683\n",
      "Train on 137732 samples, validate on 44322 samples\n",
      "Epoch 1/100\n",
      "137732/137732 [==============================] - 23s 168us/step - loss: 0.0561 - val_loss: 0.0377\n",
      "Epoch 2/100\n",
      "137732/137732 [==============================] - 17s 122us/step - loss: 0.0372 - val_loss: 0.0347\n",
      "Epoch 3/100\n",
      "137732/137732 [==============================] - 17s 123us/step - loss: 0.0341 - val_loss: 0.0330\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137732/137732 [==============================] - 17s 126us/step - loss: 0.0323 - val_loss: 0.0309\n",
      "Epoch 5/100\n",
      "137732/137732 [==============================] - 19s 137us/step - loss: 0.0309 - val_loss: 0.0327\n",
      "Epoch 6/100\n",
      "137732/137732 [==============================] - 16s 118us/step - loss: 0.0298 - val_loss: 0.0290\n",
      "Epoch 7/100\n",
      "137732/137732 [==============================] - 18s 127us/step - loss: 0.0286 - val_loss: 0.0276\n",
      "Epoch 8/100\n",
      "137732/137732 [==============================] - 18s 132us/step - loss: 0.0276 - val_loss: 0.0266\n",
      "Epoch 9/100\n",
      "137732/137732 [==============================] - 18s 128us/step - loss: 0.0271 - val_loss: 0.0256\n",
      "Epoch 10/100\n",
      "137732/137732 [==============================] - 17s 125us/step - loss: 0.0265 - val_loss: 0.0248\n",
      "Epoch 11/100\n",
      "137732/137732 [==============================] - 17s 127us/step - loss: 0.0258 - val_loss: 0.0247\n",
      "Epoch 12/100\n",
      "137732/137732 [==============================] - 16s 116us/step - loss: 0.0253 - val_loss: 0.0250\n",
      "Epoch 13/100\n",
      "137732/137732 [==============================] - 17s 121us/step - loss: 0.0250 - val_loss: 0.0243\n",
      "Epoch 14/100\n",
      "137732/137732 [==============================] - 17s 125us/step - loss: 0.0245 - val_loss: 0.0236 loss:\n",
      "Epoch 15/100\n",
      "137732/137732 [==============================] - 17s 123us/step - loss: 0.0240 - val_loss: 0.0238\n",
      "Epoch 16/100\n",
      "137732/137732 [==============================] - 17s 124us/step - loss: 0.0239 - val_loss: 0.0232\n",
      "Epoch 17/100\n",
      "137732/137732 [==============================] - 17s 123us/step - loss: 0.0235 - val_loss: 0.0226\n",
      "Epoch 18/100\n",
      "137732/137732 [==============================] - 16s 114us/step - loss: 0.0231 - val_loss: 0.0229\n",
      "Epoch 19/100\n",
      "137732/137732 [==============================] - 17s 123us/step - loss: 0.0229 - val_loss: 0.0231\n",
      "Epoch 20/100\n",
      "137732/137732 [==============================] - 17s 126us/step - loss: 0.0226 - val_loss: 0.0220\n",
      "Epoch 21/100\n",
      "137732/137732 [==============================] - 18s 132us/step - loss: 0.0222 - val_loss: 0.0219\n",
      "Epoch 22/100\n",
      "137732/137732 [==============================] - 18s 128us/step - loss: 0.0222 - val_loss: 0.0219\n",
      "Epoch 23/100\n",
      "137732/137732 [==============================] - 17s 121us/step - loss: 0.0219 - val_loss: 0.0222\n",
      "Epoch 24/100\n",
      "137732/137732 [==============================] - 16s 119us/step - loss: 0.0216 - val_loss: 0.0219\n",
      "Epoch 25/100\n",
      "137732/137732 [==============================] - 17s 123us/step - loss: 0.0215 - val_loss: 0.0213\n",
      "Epoch 26/100\n",
      "137732/137732 [==============================] - 17s 125us/step - loss: 0.0214 - val_loss: 0.0216\n",
      "Epoch 27/100\n",
      "137732/137732 [==============================] - 18s 129us/step - loss: 0.0210 - val_loss: 0.0211\n",
      "Epoch 28/100\n",
      "137732/137732 [==============================] - 18s 132us/step - loss: 0.0212 - val_loss: 0.0208\n",
      "Epoch 29/100\n",
      "137732/137732 [==============================] - 16s 116us/step - loss: 0.0209 - val_loss: 0.0212\n",
      "Epoch 30/100\n",
      "137732/137732 [==============================] - 17s 123us/step - loss: 0.0207 - val_loss: 0.0208\n",
      "Epoch 31/100\n",
      "137732/137732 [==============================] - 17s 125us/step - loss: 0.0206 - val_loss: 0.0208\n",
      "Epoch 32/100\n",
      "137732/137732 [==============================] - 17s 124us/step - loss: 0.0205 - val_loss: 0.0201\n",
      "Epoch 33/100\n",
      "137732/137732 [==============================] - 17s 126us/step - loss: 0.0203 - val_loss: 0.0199\n",
      "Epoch 34/100\n",
      "137732/137732 [==============================] - 17s 123us/step - loss: 0.0202 - val_loss: 0.0201\n",
      "Epoch 35/100\n",
      "137732/137732 [==============================] - 16s 116us/step - loss: 0.0202 - val_loss: 0.0199\n",
      "Epoch 36/100\n",
      "137732/137732 [==============================] - 17s 124us/step - loss: 0.0201 - val_loss: 0.0211\n",
      "Epoch 37/100\n",
      "137732/137732 [==============================] - 17s 124us/step - loss: 0.0200 - val_loss: 0.0203\n",
      "perc100SubjectM1andFold3\n",
      "272944\n",
      "89656\n",
      "Train on 169162 samples, validate on 52658 samples\n",
      "Epoch 1/100\n",
      "169162/169162 [==============================] - 28s 168us/step - loss: 0.0494 - val_loss: 0.0340\n",
      "Epoch 2/100\n",
      "169162/169162 [==============================] - 22s 129us/step - loss: 0.0377 - val_loss: 0.0302\n",
      "Epoch 3/100\n",
      "169162/169162 [==============================] - 21s 124us/step - loss: 0.0348 - val_loss: 0.0277\n",
      "Epoch 4/100\n",
      "169162/169162 [==============================] - 20s 119us/step - loss: 0.0329 - val_loss: 0.0267\n",
      "Epoch 5/100\n",
      "169162/169162 [==============================] - 22s 129us/step - loss: 0.0315 - val_loss: 0.0255\n",
      "Epoch 6/100\n",
      "169162/169162 [==============================] - 22s 129us/step - loss: 0.0303 - val_loss: 0.0241\n",
      "Epoch 7/100\n",
      "169162/169162 [==============================] - 22s 131us/step - loss: 0.0294 - val_loss: 0.0239\n",
      "Epoch 8/100\n",
      "169162/169162 [==============================] - 22s 132us/step - loss: 0.0286 - val_loss: 0.0240\n",
      "Epoch 9/100\n",
      "169162/169162 [==============================] - 23s 137us/step - loss: 0.0281 - val_loss: 0.0229\n",
      "Epoch 10/100\n",
      "169162/169162 [==============================] - 22s 129us/step - loss: 0.0276 - val_loss: 0.0227\n",
      "Epoch 11/100\n",
      "169162/169162 [==============================] - 22s 131us/step - loss: 0.0271 - val_loss: 0.0221\n",
      "Epoch 12/100\n",
      "169162/169162 [==============================] - 21s 126us/step - loss: 0.0268 - val_loss: 0.0223\n",
      "Epoch 13/100\n",
      "169162/169162 [==============================] - 22s 129us/step - loss: 0.0265 - val_loss: 0.0219\n",
      "Epoch 14/100\n",
      "169162/169162 [==============================] - 22s 132us/step - loss: 0.0262 - val_loss: 0.0225\n",
      "Epoch 15/100\n",
      "169162/169162 [==============================] - 22s 130us/step - loss: 0.0259 - val_loss: 0.0216\n",
      "Epoch 16/100\n",
      "169162/169162 [==============================] - 22s 130us/step - loss: 0.0257 - val_loss: 0.0216\n",
      "Epoch 17/100\n",
      "169162/169162 [==============================] - 21s 123us/step - loss: 0.0255 - val_loss: 0.0213\n",
      "Epoch 18/100\n",
      "169162/169162 [==============================] - 22s 130us/step - loss: 0.0254 - val_loss: 0.0218\n",
      "Epoch 19/100\n",
      "169162/169162 [==============================] - 22s 131us/step - loss: 0.0252 - val_loss: 0.0211\n",
      "Epoch 20/100\n",
      "169162/169162 [==============================] - 22s 131us/step - loss: 0.0250 - val_loss: 0.0221\n",
      "Epoch 21/100\n",
      "169162/169162 [==============================] - 21s 122us/step - loss: 0.0249 - val_loss: 0.0213\n",
      "Epoch 22/100\n",
      "169162/169162 [==============================] - 22s 130us/step - loss: 0.0247 - val_loss: 0.0204\n",
      "Epoch 23/100\n",
      "169162/169162 [==============================] - 22s 130us/step - loss: 0.0246 - val_loss: 0.0213\n",
      "Epoch 24/100\n",
      "169162/169162 [==============================] - 22s 131us/step - loss: 0.0243 - val_loss: 0.0212\n",
      "Epoch 25/100\n",
      "169162/169162 [==============================] - 21s 125us/step - loss: 0.0243 - val_loss: 0.0206\n",
      "Epoch 26/100\n",
      "169162/169162 [==============================] - 22s 132us/step - loss: 0.0243 - val_loss: 0.0208\n",
      "perc100SubjectM1andFold4\n",
      "283394\n",
      "94027\n",
      "Train on 158852 samples, validate on 51591 samples\n",
      "Epoch 1/100\n",
      "158852/158852 [==============================] - 29s 181us/step - loss: 0.0460 - val_loss: 0.0324\n",
      "Epoch 2/100\n",
      "158852/158852 [==============================] - 23s 143us/step - loss: 0.0340 - val_loss: 0.0299\n",
      "Epoch 3/100\n",
      "158852/158852 [==============================] - 21s 129us/step - loss: 0.0313 - val_loss: 0.0273\n",
      "Epoch 4/100\n",
      "158852/158852 [==============================] - 21s 131us/step - loss: 0.0295 - val_loss: 0.0268\n",
      "Epoch 5/100\n",
      "158852/158852 [==============================] - 21s 131us/step - loss: 0.0286 - val_loss: 0.0257\n",
      "Epoch 6/100\n",
      "158852/158852 [==============================] - 21s 133us/step - loss: 0.0276 - val_loss: 0.0249\n",
      "Epoch 7/100\n",
      "158852/158852 [==============================] - 21s 132us/step - loss: 0.0269 - val_loss: 0.0247\n",
      "Epoch 8/100\n",
      "158852/158852 [==============================] - 21s 132us/step - loss: 0.0262 - val_loss: 0.0237\n",
      "Epoch 9/100\n",
      "158852/158852 [==============================] - 20s 124us/step - loss: 0.0257 - val_loss: 0.0242\n",
      "Epoch 10/100\n",
      "158852/158852 [==============================] - 21s 130us/step - loss: 0.0251 - val_loss: 0.0227\n",
      "Epoch 11/100\n",
      "158852/158852 [==============================] - 21s 131us/step - loss: 0.0247 - val_loss: 0.0228\n",
      "Epoch 12/100\n",
      "158852/158852 [==============================] - 21s 130us/step - loss: 0.0244 - val_loss: 0.0227\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158852/158852 [==============================] - 21s 132us/step - loss: 0.0239 - val_loss: 0.0233\n",
      "Epoch 14/100\n",
      "158852/158852 [==============================] - 21s 131us/step - loss: 0.0236 - val_loss: 0.0222\n",
      "Epoch 15/100\n",
      "158852/158852 [==============================] - 21s 130us/step - loss: 0.0234 - val_loss: 0.0221\n",
      "Epoch 16/100\n",
      "158852/158852 [==============================] - 20s 128us/step - loss: 0.0232 - val_loss: 0.0231\n",
      "Epoch 17/100\n",
      "158852/158852 [==============================] - 21s 131us/step - loss: 0.0229 - val_loss: 0.0213\n",
      "Epoch 18/100\n",
      "158852/158852 [==============================] - 21s 132us/step - loss: 0.0227 - val_loss: 0.0208\n",
      "Epoch 19/100\n",
      "158852/158852 [==============================] - 21s 131us/step - loss: 0.0225 - val_loss: 0.0208\n",
      "Epoch 20/100\n",
      "158852/158852 [==============================] - 21s 132us/step - loss: 0.0223 - val_loss: 0.0213\n",
      "Epoch 21/100\n",
      "158852/158852 [==============================] - 21s 131us/step - loss: 0.0221 - val_loss: 0.0210\n",
      "Epoch 22/100\n",
      "158852/158852 [==============================] - 21s 130us/step - loss: 0.0220 - val_loss: 0.0208\n",
      "perc100SubjectM2andFold1\n",
      "264565\n",
      "83443\n",
      "Train on 237993 samples, validate on 75830 samples\n",
      "Epoch 1/100\n",
      "237993/237993 [==============================] - 38s 162us/step - loss: 0.0550 - val_loss: 0.0439\n",
      "Epoch 2/100\n",
      "237993/237993 [==============================] - 31s 130us/step - loss: 0.0446 - val_loss: 0.0413\n",
      "Epoch 3/100\n",
      "237993/237993 [==============================] - 31s 131us/step - loss: 0.0423 - val_loss: 0.0392\n",
      "Epoch 4/100\n",
      "237993/237993 [==============================] - 30s 127us/step - loss: 0.0407 - val_loss: 0.0385\n",
      "Epoch 5/100\n",
      "237993/237993 [==============================] - 32s 133us/step - loss: 0.0393 - val_loss: 0.0372\n",
      "Epoch 6/100\n",
      "237993/237993 [==============================] - 31s 130us/step - loss: 0.0381 - val_loss: 0.0360\n",
      "Epoch 7/100\n",
      "237993/237993 [==============================] - 31s 131us/step - loss: 0.0372 - val_loss: 0.0354\n",
      "Epoch 8/100\n",
      "237993/237993 [==============================] - 30s 127us/step - loss: 0.0365 - val_loss: 0.0346\n",
      "Epoch 9/100\n",
      "237993/237993 [==============================] - 31s 130us/step - loss: 0.0357 - val_loss: 0.0347\n",
      "Epoch 10/100\n",
      "237993/237993 [==============================] - 31s 131us/step - loss: 0.0351 - val_loss: 0.0337\n",
      "Epoch 11/100\n",
      "237993/237993 [==============================] - 33s 137us/step - loss: 0.0346 - val_loss: 0.0336\n",
      "Epoch 12/100\n",
      "237993/237993 [==============================] - 31s 131us/step - loss: 0.0342 - val_loss: 0.0327\n",
      "Epoch 13/100\n",
      "237993/237993 [==============================] - 33s 137us/step - loss: 0.0337 - val_loss: 0.0321\n",
      "Epoch 14/100\n",
      "237993/237993 [==============================] - 32s 135us/step - loss: 0.0333 - val_loss: 0.0330\n",
      "Epoch 15/100\n",
      "237993/237993 [==============================] - 32s 136us/step - loss: 0.0330 - val_loss: 0.0334\n",
      "Epoch 16/100\n",
      "237993/237993 [==============================] - 31s 128us/step - loss: 0.0326 - val_loss: 0.0323\n",
      "Epoch 17/100\n",
      "237993/237993 [==============================] - 31s 132us/step - loss: 0.0323 - val_loss: 0.0316\n",
      "Epoch 18/100\n",
      "237993/237993 [==============================] - 33s 138us/step - loss: 0.0321 - val_loss: 0.0313\n",
      "Epoch 19/100\n",
      "237993/237993 [==============================] - 31s 132us/step - loss: 0.0318 - val_loss: 0.0315\n",
      "Epoch 20/100\n",
      "237993/237993 [==============================] - 30s 127us/step - loss: 0.0314 - val_loss: 0.0310\n",
      "Epoch 21/100\n",
      "237993/237993 [==============================] - 32s 134us/step - loss: 0.0312 - val_loss: 0.0306\n",
      "Epoch 22/100\n",
      "237993/237993 [==============================] - 33s 139us/step - loss: 0.0310 - val_loss: 0.0301\n",
      "Epoch 23/100\n",
      "237993/237993 [==============================] - 32s 134us/step - loss: 0.0309 - val_loss: 0.0309\n",
      "Epoch 24/100\n",
      "237993/237993 [==============================] - 31s 130us/step - loss: 0.0306 - val_loss: 0.0306\n",
      "Epoch 25/100\n",
      "237993/237993 [==============================] - 31s 132us/step - loss: 0.0305 - val_loss: 0.0301\n",
      "Epoch 26/100\n",
      "237993/237993 [==============================] - 32s 133us/step - loss: 0.0303 - val_loss: 0.0299\n",
      "Epoch 27/100\n",
      "237993/237993 [==============================] - 31s 132us/step - loss: 0.0301 - val_loss: 0.0295\n",
      "Epoch 28/100\n",
      "237993/237993 [==============================] - 32s 133us/step - loss: 0.0299 - val_loss: 0.0301\n",
      "Epoch 29/100\n",
      "237993/237993 [==============================] - 33s 138us/step - loss: 0.0298 - val_loss: 0.0296\n",
      "Epoch 30/100\n",
      "237993/237993 [==============================] - 33s 137us/step - loss: 0.0297 - val_loss: 0.0298\n",
      "Epoch 31/100\n",
      "237993/237993 [==============================] - 32s 135us/step - loss: 0.0297 - val_loss: 0.0293\n",
      "Epoch 32/100\n",
      "237993/237993 [==============================] - 30s 127us/step - loss: 0.0293 - val_loss: 0.0290\n",
      "Epoch 33/100\n",
      "237993/237993 [==============================] - 32s 136us/step - loss: 0.0292 - val_loss: 0.0292\n",
      "Epoch 34/100\n",
      "237993/237993 [==============================] - 34s 143us/step - loss: 0.0291 - val_loss: 0.0288\n",
      "Epoch 35/100\n",
      "237993/237993 [==============================] - 31s 131us/step - loss: 0.0289 - val_loss: 0.0283\n",
      "Epoch 36/100\n",
      "237993/237993 [==============================] - 31s 130us/step - loss: 0.0289 - val_loss: 0.0287\n",
      "Epoch 37/100\n",
      "237993/237993 [==============================] - 31s 132us/step - loss: 0.0289 - val_loss: 0.0291\n",
      "Epoch 38/100\n",
      "237993/237993 [==============================] - 32s 134us/step - loss: 0.0287 - val_loss: 0.0290\n",
      "Epoch 39/100\n",
      "237993/237993 [==============================] - 31s 130us/step - loss: 0.0287 - val_loss: 0.0286\n",
      "perc100SubjectM2andFold2\n",
      "270416\n",
      "90933\n",
      "Train on 168980 samples, validate on 55311 samples\n",
      "Epoch 1/100\n",
      "168980/168980 [==============================] - 29s 173us/step - loss: 0.0500 - val_loss: 0.0405\n",
      "Epoch 2/100\n",
      "168980/168980 [==============================] - 23s 135us/step - loss: 0.0378 - val_loss: 0.0368\n",
      "Epoch 3/100\n",
      "168980/168980 [==============================] - 23s 134us/step - loss: 0.0347 - val_loss: 0.0340\n",
      "Epoch 4/100\n",
      "168980/168980 [==============================] - 22s 127us/step - loss: 0.0324 - val_loss: 0.0344\n",
      "Epoch 5/100\n",
      "168980/168980 [==============================] - 22s 133us/step - loss: 0.0306 - val_loss: 0.0308\n",
      "Epoch 6/100\n",
      "168980/168980 [==============================] - 23s 134us/step - loss: 0.0293 - val_loss: 0.0296\n",
      "Epoch 7/100\n",
      "168980/168980 [==============================] - 23s 136us/step - loss: 0.0282 - val_loss: 0.0300\n",
      "Epoch 8/100\n",
      "168980/168980 [==============================] - 23s 136us/step - loss: 0.0275 - val_loss: 0.0280\n",
      "Epoch 9/100\n",
      "168980/168980 [==============================] - 21s 126us/step - loss: 0.0265 - val_loss: 0.0271\n",
      "Epoch 10/100\n",
      "168980/168980 [==============================] - 23s 134us/step - loss: 0.0260 - val_loss: 0.0267\n",
      "Epoch 11/100\n",
      "168980/168980 [==============================] - 23s 138us/step - loss: 0.0253 - val_loss: 0.0275\n",
      "Epoch 12/100\n",
      "168980/168980 [==============================] - 26s 155us/step - loss: 0.0249 - val_loss: 0.0261\n",
      "Epoch 13/100\n",
      "168980/168980 [==============================] - 21s 127us/step - loss: 0.0243 - val_loss: 0.0252\n",
      "Epoch 14/100\n",
      "168980/168980 [==============================] - 20s 121us/step - loss: 0.0240 - val_loss: 0.0250\n",
      "Epoch 15/100\n",
      "168980/168980 [==============================] - 24s 141us/step - loss: 0.0235 - val_loss: 0.0246\n",
      "Epoch 16/100\n",
      "168980/168980 [==============================] - 24s 142us/step - loss: 0.0233 - val_loss: 0.0242\n",
      "Epoch 17/100\n",
      "168980/168980 [==============================] - 20s 118us/step - loss: 0.0229 - val_loss: 0.0239\n",
      "Epoch 18/100\n",
      "168980/168980 [==============================] - 20s 119us/step - loss: 0.0227 - val_loss: 0.0243\n",
      "Epoch 19/100\n",
      "168980/168980 [==============================] - 20s 121us/step - loss: 0.0224 - val_loss: 0.0237\n",
      "Epoch 20/100\n",
      "168980/168980 [==============================] - 20s 117us/step - loss: 0.0222 - val_loss: 0.0231\n",
      "Epoch 21/100\n",
      "168980/168980 [==============================] - 22s 128us/step - loss: 0.0219 - val_loss: 0.0237\n",
      "Epoch 22/100\n",
      "168980/168980 [==============================] - 20s 120us/step - loss: 0.0218 - val_loss: 0.0229\n",
      "Epoch 23/100\n",
      "168980/168980 [==============================] - 20s 119us/step - loss: 0.0216 - val_loss: 0.0224\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168980/168980 [==============================] - 20s 119us/step - loss: 0.0214 - val_loss: 0.0227\n",
      "Epoch 25/100\n",
      "168980/168980 [==============================] - 20s 118us/step - loss: 0.0212 - val_loss: 0.0224\n",
      "Epoch 26/100\n",
      "168980/168980 [==============================] - 19s 113us/step - loss: 0.0210 - val_loss: 0.0222\n",
      "Epoch 27/100\n",
      "168980/168980 [==============================] - 20s 116us/step - loss: 0.0209 - val_loss: 0.0224\n",
      "Epoch 28/100\n",
      "168980/168980 [==============================] - 20s 117us/step - loss: 0.0207 - val_loss: 0.0214\n",
      "Epoch 29/100\n",
      "168980/168980 [==============================] - 19s 113us/step - loss: 0.0207 - val_loss: 0.0229\n",
      "Epoch 30/100\n",
      "168980/168980 [==============================] - 20s 116us/step - loss: 0.0205 - val_loss: 0.0223\n",
      "Epoch 31/100\n",
      "168980/168980 [==============================] - 20s 121us/step - loss: 0.0204 - val_loss: 0.0215\n",
      "Epoch 32/100\n",
      "168980/168980 [==============================] - 19s 112us/step - loss: 0.0203 - val_loss: 0.0213\n",
      "Epoch 33/100\n",
      "168980/168980 [==============================] - 20s 119us/step - loss: 0.0201 - val_loss: 0.0216\n",
      "Epoch 34/100\n",
      "168980/168980 [==============================] - 20s 115us/step - loss: 0.0201 - val_loss: 0.0216\n",
      "Epoch 35/100\n",
      "168980/168980 [==============================] - 20s 116us/step - loss: 0.0200 - val_loss: 0.0214\n",
      "Epoch 36/100\n",
      "168980/168980 [==============================] - 20s 119us/step - loss: 0.0197 - val_loss: 0.0212\n",
      "Epoch 37/100\n",
      "168980/168980 [==============================] - 20s 115us/step - loss: 0.0197 - val_loss: 0.0213\n",
      "Epoch 38/100\n",
      "168980/168980 [==============================] - 20s 119us/step - loss: 0.0197 - val_loss: 0.0211\n",
      "Epoch 39/100\n",
      "168980/168980 [==============================] - 19s 114us/step - loss: 0.0196 - val_loss: 0.0214\n",
      "Epoch 40/100\n",
      "168980/168980 [==============================] - 20s 117us/step - loss: 0.0196 - val_loss: 0.0210\n",
      "Epoch 41/100\n",
      "168980/168980 [==============================] - 20s 119us/step - loss: 0.0194 - val_loss: 0.0210\n",
      "Epoch 42/100\n",
      "168980/168980 [==============================] - 20s 121us/step - loss: 0.0192 - val_loss: 0.0207\n",
      "Epoch 43/100\n",
      "168980/168980 [==============================] - 22s 132us/step - loss: 0.0191 - val_loss: 0.0210\n",
      "Epoch 44/100\n",
      "168980/168980 [==============================] - 19s 115us/step - loss: 0.0192 - val_loss: 0.0209\n",
      "Epoch 45/100\n",
      "168980/168980 [==============================] - 20s 117us/step - loss: 0.0191 - val_loss: 0.0202\n",
      "Epoch 46/100\n",
      "168980/168980 [==============================] - 19s 113us/step - loss: 0.0190 - val_loss: 0.0205\n",
      "Epoch 47/100\n",
      "168980/168980 [==============================] - 22s 128us/step - loss: 0.0189 - val_loss: 0.0210\n",
      "Epoch 48/100\n",
      "168980/168980 [==============================] - 22s 129us/step - loss: 0.0189 - val_loss: 0.0203\n",
      "Epoch 49/100\n",
      "168980/168980 [==============================] - 20s 116us/step - loss: 0.0189 - val_loss: 0.0202\n",
      "perc100SubjectM2andFold3\n",
      "244885\n",
      "81132\n",
      "Train on 161645 samples, validate on 53841 samples\n",
      "Epoch 1/100\n",
      "161645/161645 [==============================] - 27s 164us/step - loss: 0.0573 - val_loss: 0.0426\n",
      "Epoch 2/100\n",
      "161645/161645 [==============================] - 20s 123us/step - loss: 0.0455 - val_loss: 0.0404\n",
      "Epoch 3/100\n",
      "161645/161645 [==============================] - 22s 135us/step - loss: 0.0427 - val_loss: 0.0377\n",
      "Epoch 4/100\n",
      "161645/161645 [==============================] - 20s 126us/step - loss: 0.0406 - val_loss: 0.0351\n",
      "Epoch 5/100\n",
      "161645/161645 [==============================] - 20s 124us/step - loss: 0.0385 - val_loss: 0.0344\n",
      "Epoch 6/100\n",
      "161645/161645 [==============================] - 20s 125us/step - loss: 0.0371 - val_loss: 0.0342\n",
      "Epoch 7/100\n",
      "161645/161645 [==============================] - 20s 121us/step - loss: 0.0357 - val_loss: 0.0318\n",
      "Epoch 8/100\n",
      "161645/161645 [==============================] - 20s 121us/step - loss: 0.0347 - val_loss: 0.0317\n",
      "Epoch 9/100\n",
      "161645/161645 [==============================] - 20s 124us/step - loss: 0.0340 - val_loss: 0.0303\n",
      "Epoch 10/100\n",
      "161645/161645 [==============================] - 20s 121us/step - loss: 0.0334 - val_loss: 0.0321\n",
      "Epoch 11/100\n",
      "161645/161645 [==============================] - 20s 124us/step - loss: 0.0327 - val_loss: 0.0300\n",
      "Epoch 12/100\n",
      "161645/161645 [==============================] - 20s 123us/step - loss: 0.0322 - val_loss: 0.0297\n",
      "Epoch 13/100\n",
      "161645/161645 [==============================] - 20s 123us/step - loss: 0.0317 - val_loss: 0.0286\n",
      "Epoch 14/100\n",
      "161645/161645 [==============================] - 20s 124us/step - loss: 0.0312 - val_loss: 0.0288\n",
      "Epoch 15/100\n",
      "161645/161645 [==============================] - 20s 123us/step - loss: 0.0310 - val_loss: 0.0279\n",
      "Epoch 16/100\n",
      "161645/161645 [==============================] - 20s 121us/step - loss: 0.0305 - val_loss: 0.0281\n",
      "Epoch 17/100\n",
      "161645/161645 [==============================] - 20s 124us/step - loss: 0.0302 - val_loss: 0.0283\n",
      "Epoch 18/100\n",
      "161645/161645 [==============================] - 20s 123us/step - loss: 0.0301 - val_loss: 0.0270\n",
      "Epoch 19/100\n",
      "161645/161645 [==============================] - 20s 121us/step - loss: 0.0297 - val_loss: 0.0291\n",
      "Epoch 20/100\n",
      "161645/161645 [==============================] - 20s 124us/step - loss: 0.0294 - val_loss: 0.0275\n",
      "Epoch 21/100\n",
      "161645/161645 [==============================] - 20s 124us/step - loss: 0.0292 - val_loss: 0.0274\n",
      "Epoch 22/100\n",
      "161645/161645 [==============================] - 19s 120us/step - loss: 0.0289 - val_loss: 0.0276\n",
      "perc100SubjectM2andFold4\n",
      "240870\n",
      "79616\n",
      "Train on 161361 samples, validate on 52403 samples\n",
      "Epoch 1/100\n",
      "161361/161361 [==============================] - 27s 167us/step - loss: 0.0526 - val_loss: 0.0377\n",
      "Epoch 2/100\n",
      "161361/161361 [==============================] - 19s 120us/step - loss: 0.0414 - val_loss: 0.0359\n",
      "Epoch 3/100\n",
      "161361/161361 [==============================] - 20s 124us/step - loss: 0.0383 - val_loss: 0.0325\n",
      "Epoch 4/100\n",
      "161361/161361 [==============================] - 20s 125us/step - loss: 0.0361 - val_loss: 0.0306\n",
      "Epoch 5/100\n",
      "161361/161361 [==============================] - 21s 128us/step - loss: 0.0341 - val_loss: 0.0316\n",
      "Epoch 6/100\n",
      "161361/161361 [==============================] - 22s 137us/step - loss: 0.0330 - val_loss: 0.0280\n",
      "Epoch 7/100\n",
      "161361/161361 [==============================] - 20s 123us/step - loss: 0.0317 - val_loss: 0.0284\n",
      "Epoch 8/100\n",
      "161361/161361 [==============================] - 19s 120us/step - loss: 0.0309 - val_loss: 0.0277\n",
      "Epoch 9/100\n",
      "161361/161361 [==============================] - 20s 124us/step - loss: 0.0301 - val_loss: 0.0271\n",
      "Epoch 10/100\n",
      "161361/161361 [==============================] - 20s 122us/step - loss: 0.0293 - val_loss: 0.0262\n",
      "Epoch 11/100\n",
      "161361/161361 [==============================] - 19s 117us/step - loss: 0.0286 - val_loss: 0.0265\n",
      "Epoch 12/100\n",
      "161361/161361 [==============================] - 20s 123us/step - loss: 0.0283 - val_loss: 0.0258\n",
      "Epoch 13/100\n",
      "161361/161361 [==============================] - 20s 127us/step - loss: 0.0278 - val_loss: 0.0247\n",
      "Epoch 14/100\n",
      "161361/161361 [==============================] - 20s 121us/step - loss: 0.0274 - val_loss: 0.0252\n",
      "Epoch 15/100\n",
      "161361/161361 [==============================] - 20s 122us/step - loss: 0.0271 - val_loss: 0.0244\n",
      "Epoch 16/100\n",
      "161361/161361 [==============================] - 21s 130us/step - loss: 0.0267 - val_loss: 0.0238\n",
      "Epoch 17/100\n",
      "161361/161361 [==============================] - 19s 121us/step - loss: 0.0264 - val_loss: 0.0238\n",
      "Epoch 18/100\n",
      "161361/161361 [==============================] - 19s 120us/step - loss: 0.0260 - val_loss: 0.0248\n",
      "Epoch 19/100\n",
      "161361/161361 [==============================] - 20s 123us/step - loss: 0.0257 - val_loss: 0.0232\n",
      "Epoch 20/100\n",
      "161361/161361 [==============================] - 19s 120us/step - loss: 0.0255 - val_loss: 0.0232\n",
      "Epoch 21/100\n",
      "161361/161361 [==============================] - 19s 119us/step - loss: 0.0252 - val_loss: 0.0237\n",
      "Epoch 22/100\n",
      "161361/161361 [==============================] - 20s 126us/step - loss: 0.0251 - val_loss: 0.0228\n",
      "Epoch 23/100\n",
      "161361/161361 [==============================] - 19s 120us/step - loss: 0.0250 - val_loss: 0.0233\n",
      "Epoch 24/100\n",
      "161361/161361 [==============================] - 20s 123us/step - loss: 0.0248 - val_loss: 0.0230\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161361/161361 [==============================] - 20s 121us/step - loss: 0.0246 - val_loss: 0.0227\n",
      "Epoch 26/100\n",
      "161361/161361 [==============================] - 19s 120us/step - loss: 0.0244 - val_loss: 0.0228\n",
      "Epoch 27/100\n",
      "161361/161361 [==============================] - 20s 122us/step - loss: 0.0241 - val_loss: 0.0224\n",
      "Epoch 28/100\n",
      "161361/161361 [==============================] - 20s 121us/step - loss: 0.0241 - val_loss: 0.0225\n",
      "Epoch 29/100\n",
      "161361/161361 [==============================] - 20s 127us/step - loss: 0.0240 - val_loss: 0.0231\n",
      "Epoch 30/100\n",
      "161361/161361 [==============================] - 20s 124us/step - loss: 0.0238 - val_loss: 0.0228\n",
      "Epoch 31/100\n",
      "161361/161361 [==============================] - 19s 120us/step - loss: 0.0238 - val_loss: 0.0220\n",
      "Epoch 32/100\n",
      "161361/161361 [==============================] - 21s 130us/step - loss: 0.0235 - val_loss: 0.0231\n",
      "Epoch 33/100\n",
      "161361/161361 [==============================] - 20s 123us/step - loss: 0.0234 - val_loss: 0.0221\n",
      "Epoch 34/100\n",
      "161361/161361 [==============================] - 20s 121us/step - loss: 0.0235 - val_loss: 0.0227\n",
      "Epoch 35/100\n",
      "161361/161361 [==============================] - 20s 122us/step - loss: 0.0231 - val_loss: 0.0220\n",
      "Epoch 36/100\n",
      "161361/161361 [==============================] - 20s 125us/step - loss: 0.0231 - val_loss: 0.0226\n",
      "Epoch 37/100\n",
      "161361/161361 [==============================] - 20s 123us/step - loss: 0.0230 - val_loss: 0.0223\n",
      "Epoch 38/100\n",
      "161361/161361 [==============================] - 19s 119us/step - loss: 0.0229 - val_loss: 0.0213\n",
      "Epoch 39/100\n",
      "161361/161361 [==============================] - 20s 123us/step - loss: 0.0229 - val_loss: 0.0221\n",
      "Epoch 40/100\n",
      "161361/161361 [==============================] - 20s 124us/step - loss: 0.0227 - val_loss: 0.0219\n",
      "Epoch 41/100\n",
      "161361/161361 [==============================] - 19s 118us/step - loss: 0.0226 - val_loss: 0.0226\n",
      "Epoch 42/100\n",
      "161361/161361 [==============================] - 20s 123us/step - loss: 0.0225 - val_loss: 0.0214\n",
      "TRAINING COMPLETE!!\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from functions  import intensity_data\n",
    "from scipy.io import loadmat\n",
    "sub=['F1','F2','M1','M2']\n",
    "# sub = ['M2']\n",
    "fold=['Fold1','Fold2','Fold3','Fold4']\n",
    "# fold = ['Fold1']\n",
    "seg = 'Upper'\n",
    "a = list(range(98,100))\n",
    "b = [99.25,99.5,99.75,100]\n",
    "per = a + b\n",
    "for p in per:\n",
    "    for s in sub:\n",
    "        mat = loadmat('../DNN_Data_dist_DNN_Full/'+seg+'/'+s+'/'+\"pxl_np_\"+str(p)+\".mat\")\n",
    "        np_fold = mat['pxl_np']\n",
    "        for f in fold: \n",
    "            print('perc'+str(p)+'Subject'+s+'and'+f)\n",
    "            #dataset = pandas.read_csv(seg+'/'+s+'/'+f+'/'+\"Grid_Wise_Set_train_\"+str(p)+\".csv\", delimiter=\",\",header = None)\n",
    "            #dataset.replace(numpy.inf, numpy.nan)\n",
    "            #dataset[dataset==numpy.inf] = numpy.nan\n",
    "            #dataset.fillna(dataset.mean(), inplace=True)\n",
    "            #dataset = dataset.as_matrix(columns = None)\n",
    "            ind = fold.index(f)\n",
    "            np = np_fold[0,ind][1][0][0]\n",
    "            dataset = loadmat(seg+'/'+s+'/'+f+'/'+\"Intensity_Set_\"+str(p)+\".mat\")\n",
    "            a1= dataset['intensity_profile_frame']\n",
    "            l = a1.shape[1]\n",
    "            l1 = int(l/4)\n",
    "            a = numpy.array(a1[0][0:l-l1])\n",
    "            a = a.reshape(1,l-l1)\n",
    "            b = numpy.array(a1[0][l-l1:l])\n",
    "            b = b.reshape(1,l1)\n",
    "            a = intensity_data(a)\n",
    "            b = intensity_data(b)\n",
    "            print(len(a))\n",
    "            print(len(b))\n",
    "            X = a[:,0:np+1]\n",
    "            Xorg = X.copy()\n",
    "            X = X[~numpy.isnan(X).any(axis=1)]\n",
    "            Y = a[:,np+1]\n",
    "            Y = Y[~numpy.isnan(Xorg).any(axis=1)]\n",
    "            X1 = b[:,0:np+1]\n",
    "            X1org = X1.copy()\n",
    "            X1 = X1[~numpy.isnan(X1).any(axis=1)]\n",
    "            Y1 = b[:,np+1]\n",
    "            Y1 = Y1[~numpy.isnan(X1org).any(axis=1)]\n",
    "            if len(a)<=50000:\n",
    "                n1 = 64\n",
    "                n2 = 64\n",
    "                n3 = 64\n",
    "                bs = 50\n",
    "            elif len(a)<=100000:\n",
    "                n1 = 128\n",
    "                n2 = 128\n",
    "                n3 = 128\n",
    "                bs = 100\n",
    "            elif len(a)<=200000:\n",
    "                n1 = 256\n",
    "                n2 = 128\n",
    "                n3 = 128\n",
    "                bs = 150\n",
    "            elif len(a)<=300000:\n",
    "                n1 = 256\n",
    "                n2 = 256\n",
    "                n3 = 128\n",
    "                bs = 200\n",
    "            elif len(a)<=400000:\n",
    "                n1 = 256\n",
    "                n2 = 256\n",
    "                n3 = 256\n",
    "                bs = 250\n",
    "            else:\n",
    "                n1 = 512\n",
    "                n2 = 256\n",
    "                n3 = 256\n",
    "                bs = 300\n",
    "#             if len(a)<=40000:\n",
    "#                 n1 = 64\n",
    "#                 n2 = 64\n",
    "#                 n3 = 64\n",
    "#             else:\n",
    "#                 n1 = 128\n",
    "#                 n2 = 128\n",
    "#                 n3 = 128\n",
    "            def base_model():\n",
    "                model = Sequential()\n",
    "                model.add(Dense(n1,activation=\"relu\", kernel_initializer=\"normal\", input_dim=np+1))\n",
    "                model.add(Dropout(0.15))\n",
    "#                 if l > 20000:\n",
    "                model.add(Dense(n2, activation=\"relu\", kernel_initializer=\"normal\"))\n",
    "                model.add(Dropout(0.15))\n",
    "#                 if l > 50000:\n",
    "                model.add(Dense(n3, activation=\"relu\", kernel_initializer=\"normal\"))\n",
    "                model.add(Dropout(0.15))  \n",
    "                model.add(Dense(1, activation=\"relu\", kernel_initializer=\"normal\"))\n",
    "                model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "                return model\n",
    "            fname=(seg+'/'+s+'/'+f+'/'+'Model_GridWise_dev_' + str(p) + '.hdf5')\n",
    "            callbacks = [EarlyStopping(monitor='val_loss', patience=4, min_delta = 0.00001), ModelCheckpoint(fname, monitor='val_loss', verbose=0, save_best_only=True, mode='auto', period=1)]\n",
    "            estimator = KerasRegressor( build_fn = base_model)\n",
    "            estimator.fit(X, Y, validation_data=(X1,Y1), epochs=100, batch_size=bs, callbacks=callbacks)\n",
    "            a = []\n",
    "            b = []\n",
    "            X1 = []\n",
    "            Y1 = []\n",
    "            X1org = []\n",
    "            Xorg = []\n",
    "            X = []\n",
    "            Y = []\n",
    "            a1 = []\n",
    "            dataset = []            \n",
    "print(\"TRAINING COMPLETE!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12957, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "X = X[~numpy.isnan(X).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12048, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.isnan(X).any(axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
